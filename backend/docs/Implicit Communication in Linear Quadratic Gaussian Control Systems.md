# Implicit Communication in Linear Quadratic Gaussian Control Systems

Report issue for preceding element

Gongpu Chen Â  and Deniz Gunduz The authors are with the Department of Electrical and Electronic Engineering, Imperial College London, London SW7 2AZ, UK (e-mails:{gongpu.chen, d.gunduz}@imperial.ac.uk).

Report issue for preceding element

###### Abstract

Report issue for preceding element

This paper studies implicit communication in linear quadratic Gaussian control systems. We show that the control system itself can serve as an implicit communication channel, enabling the controller to transmit messages through its inputs to a receiver that observes the system state. This communication is considered implicit because (i) no explicit communication channels are needed; and (ii) information is transmitted while simultaneously fulfilling the controllerâ€™s primary objectiveâ€”maintaining the control cost within a specified level. As a result, there exists an inherent trade-off between control and communication performance. This trade-off is formalized through the notion of implicit channel capacity, which characterizes the supremum reliable communication rate subject to a constraint on control performance. We characterize the implicit channel capacity in three settings. When both the controller and the receiver have noiseless observations of the system state, the channel capacity admits a closed-form expression. When only the controller has noiseless observations, the channel capacity is given by the solution of a convex optimization. When both the controller and the receiver have noisy observations, we establish a lower bound on the implicit capacity. Surprisingly, when the controller has noiseless observations, the capacity-achieving input policy adheres to a separation principle, allowing the control and channel coding tasks to be addressed independently, without loss of optimality. Moreover, under this capacity-achieving input policy, the implicit channel can be equivalently translated into a Gaussian MIMO channel, enabling the use of existing channel codes to achieve implicit communication.

Report issue for preceding element

## I Introduction

Report issue for preceding element

Implicit communication is widespread in nature and human society, with examples including coordination and signaling in starling murmurations \[[1](https://arxiv.org/html/2509.16146v1#bib.bib1)\], fish schooling \[[2](https://arxiv.org/html/2509.16146v1#bib.bib2)\], human body language \[[3](https://arxiv.org/html/2509.16146v1#bib.bib3), [4](https://arxiv.org/html/2509.16146v1#bib.bib4)\], and more \[[5](https://arxiv.org/html/2509.16146v1#bib.bib5), [6](https://arxiv.org/html/2509.16146v1#bib.bib6), [7](https://arxiv.org/html/2509.16146v1#bib.bib7)\]. These phenomena demonstrate that information can be conveyed through observable actions and behaviors, without relying on explicit communication channels. This concept is also appealing in artificial systems, particularly in scenarios where explicit communication is unavailable or where implicit communication can serve as an effective complement. For instance, in autonomous driving \[[8](https://arxiv.org/html/2509.16146v1#bib.bib8), [9](https://arxiv.org/html/2509.16146v1#bib.bib9)\], a vehicle may need to express its intentâ€”such as parking in a specific spot, changing lanes, or dropping off a passengerâ€”to surrounding vehicles to enable safe and coordinated interactions. In humanâ€“robot interactions \[[10](https://arxiv.org/html/2509.16146v1#bib.bib10), [11](https://arxiv.org/html/2509.16146v1#bib.bib11), [12](https://arxiv.org/html/2509.16146v1#bib.bib12)\], a robot may need to signal its intent to facilitate smoother cooperation. In swarm robotics \[[13](https://arxiv.org/html/2509.16146v1#bib.bib13), [14](https://arxiv.org/html/2509.16146v1#bib.bib14), [15](https://arxiv.org/html/2509.16146v1#bib.bib15)\], robots often need to exchange information to coordinate their actions, much like birds in flocks or insects in swarms. Implicit communication through actions and behaviors is a promising approach in all of these scenarios, as it mirrors the strategies naturally employed by humans and animals.

Report issue for preceding element

From an information-theoretic perspective, all communicationâ€”whether explicit or implicitâ€”requires a channel: an inputâ€“output system that allows the receiver to infer, from the observed outputs, the message that is encoded into the inputs by the transmitter. In this sense, existing studies often lack a rigorous definition of implicit communication \[[15](https://arxiv.org/html/2509.16146v1#bib.bib15), [16](https://arxiv.org/html/2509.16146v1#bib.bib16), [17](https://arxiv.org/html/2509.16146v1#bib.bib17)\]. What constitutes the channel in implicit communication? How is information transmitted through this channel? To address these questions, we first propose the following definitions: An explicit communication channel is an input-output system dedicated solely to communication between a transmitter and a receiver. In contrast, an implicit communication channel is a system in which the inputs and outputs serve a primary functional role (e.g., control or decision-making) and simultaneously transmit information that can be decoded by a receiver observing the system outputs. In such cases, communication emerges as a byproduct of the systemâ€™s operation through slight but purposeful modifications of the inputs and outputsâ€”without the need for an external signaling mechanism.

Report issue for preceding element

This paper investigates implicit communication in linear quadratic Gaussian (LQG) control systems, where a linear system driven by Gaussian noise evolves under the influence of the controllerâ€™s inputs. While the system is primarily designed to perform a control task, we show that it can also function as an implicit communication channel, allowing the controller to transmit messages to a receiver that can observe the system state, without relying on explicit channels. Specifically, the controller can encode the message into the control inputs, and the receiver then decodes the message from its observations of the system stateâ€”either noiseless or noisy. However, there is no free lunchâ€”the implicit communication comes at the cost of some degradation in control performance. This is natural, as encoding messages into control inputs typically requires the controller to deviate from the optimal control policy. As a result, there exists a fundamental trade-off between control and communication performance.

Report issue for preceding element

We define the implicit communication channel within this framework using standard information-theoretic principles and formulate the implicit communication problem as a co-design of channel coding and control. The trade-off between control and communication is then characterized by the capacity of the implicit channel, subject to a constraint on the control performance. Our main contributions are theoretical characterizations of the implicit channel capacity in three settings, as summarized below:

Report issue for preceding element

*   1.
    
    We begin by analyzing the case where both the controller and the receiver have noiseless observations of the system state, and we derive a closed-form expression for the implicit channel capacity. The expression coincides with that of the memoryless Gaussian MIMO channel capacity. We show that, under the capacity-achieving input policy, the implicit channel is equivalent to a memoryless Gaussian MIMO channel whose noise is exactly the process noise, and the control constraint translates into a power constraint on the channel input. Moreover, in the case of scalar systems, the implicit channel capacity admits an explicit expression as a function of the optimal control cost and the tolerable control loss, clearly revealing the trade-off between control and communication.
    
    Report issue for preceding element
    
*   2.
    
    We then generalize to the setting in which the controller has noiseless observations while the receiver observes the system state through noise. In this case, we characterize the implicit channel capacity as the solution to a finite-dimensional convex optimization problem. Under the capacity-achieving input policy, the implicit channel can be equivalently translated into a Gaussian MIMO channel with memory, where the noise process forms a hidden Markov chain.
    
    Report issue for preceding element
    
*   3.
    
    Finally, we consider the most general setting, in which both the controller and the receiver have noisy observations. This case is particularly challenging, and we establish only a lower bound on the implicit channel capacity. This bound is achievable using a linear input policy that follows a separation principle, under which the implicit channel can be translated into a Gaussian MIMO channel with memory.
    
    Report issue for preceding element
    

A surprising finding is the emergence of a separation principle in the structure of the optimal input policy when the controller has noiseless observationsâ€”the two settings in which we can fully characterize the channel capacity. In these cases, we show that the capacity-achieving input policy is given by the sum of the optimal LQG control input and a Gaussian random variable. Since the optimal control input is fixed by the LQG control objective, implicit communication is achieved by encoding the message into the Gaussian component, which we refer to as the communication signal. In other words, in an LQG control system, implicit communication can be achieved by simply adding a communication signal to the optimal control input. This separation principle significantly simplifies the problem, as it implies that the control and channel coding tasks can be addressed independently, without loss of optimality.

Report issue for preceding element

Whether this separation principle continues to hold in the setting with noisy observations at the controller remains an open question. However, the lower bound we derive corresponds exactly to the maximum rate achievable by the input policies that adhere to this separation structure, making the bound of significant practical relevance.

Report issue for preceding element

The rest of the paper is organized as follows. Section [II](https://arxiv.org/html/2509.16146v1#S2 "II Related Work â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") reviews the related work. Section [III](https://arxiv.org/html/2509.16146v1#S3 "III System Model and Preliminaries â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") introduces preliminaries on LQG control and formulates the implicit communication problem in the noiseless setting. Section [IV](https://arxiv.org/html/2509.16146v1#S4 "IV Noiseless Observations at the Controller and the Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") presents the implicit channel capacity and the achievability proof for the noiseless case. Section [V](https://arxiv.org/html/2509.16146v1#S5 "V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") addresses the setting with noisy observations at the receiver. Section [VI](https://arxiv.org/html/2509.16146v1#S6 "VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") establishes a lower bound on the channel capacity when both the controller and the receiver have noisy observations. Section [VII](https://arxiv.org/html/2509.16146v1#S7 "VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") presents the proofs of the main theorems. Finally, Section [VIII](https://arxiv.org/html/2509.16146v1#S8 "VIII Conclusion and Future Work â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") concludes this paper and discusses possible directions of future work.

Report issue for preceding element

### I-A Notations

Report issue for preceding element

For any sequence {xt:tâ‰¥1}\\{x\_{t}:t\\geq 1\\}, we will use xijx^{j}\_{i} to denote the subsequence {xi,xi+1,â‹¯,xj}\\{x\_{i},x\_{i+1},\\cdots,x\_{j}\\}. Specially, x1jx\_{1}^{j} will be simple written as xjx^{j}. Given any positive integer nn, let \[n\]\={1,2,â‹¯,n}\[n\]=\\{1,2,\\cdots,n\\} be the set of integers between 11 and nn. For any matrix BB, Bâ€ B^{\\dagger} denotes the Mooreâ€“Penrose inverse of BB such that Bâ€‹Bâ€ \=IBB^{\\dagger}=I. For a square matrix AA, Trâ€‹(A)\\text{Tr}(A) and det(A)\\det(A) denote its trace and determinant, respectively. Positive definite (PD) and positive semi-definite (PSD) matrices are denoted by Aâ‰»0A\\succ 0 and Aâª°0A\\succeq 0, respectively.

Report issue for preceding element

## II Related Work

Report issue for preceding element

Implicit communication has been studied across various fields \[[18](https://arxiv.org/html/2509.16146v1#bib.bib18), [19](https://arxiv.org/html/2509.16146v1#bib.bib19), [20](https://arxiv.org/html/2509.16146v1#bib.bib20), [21](https://arxiv.org/html/2509.16146v1#bib.bib21)\], with the most relevant to our work being research in control-related domains such as multi-agent systems \[[22](https://arxiv.org/html/2509.16146v1#bib.bib22), [23](https://arxiv.org/html/2509.16146v1#bib.bib23), [24](https://arxiv.org/html/2509.16146v1#bib.bib24)\] and humanâ€“robot interactions \[[25](https://arxiv.org/html/2509.16146v1#bib.bib25), [26](https://arxiv.org/html/2509.16146v1#bib.bib26), [27](https://arxiv.org/html/2509.16146v1#bib.bib27)\], where the transmitter is an agent engaged in a control task. Most of these studies are experimental in nature and often rely on machine learning methods, lacking a clear formulation of communication and a fundamental understanding of the complex relationship between control and communication.

Report issue for preceding element

One exception is the work in \[[28](https://arxiv.org/html/2509.16146v1#bib.bib28)\], which models the environment of a Markov decision process (MDP) as a finite-state channel and analyzes the trade-off between the MDP reward and channel coding rate. The channel capacity under a reward constraint is characterized as the solution to a convex optimization problem, where the objective function is the conditional mutual information Iâ€‹(A;Sâ€²|S)I(A;S^{\\prime}|S), with AA denoting the action, and SS and Sâ€²S^{\\prime} representing the current and the next states, respectively. The limitation of \[[28](https://arxiv.org/html/2509.16146v1#bib.bib28)\] is that it focuses on MDPs with finite state and action spaces, and only consider the setting with noiseless observations. In contrast, the present work addresses LQG control systems with noisy observations, where the state, observation, and action spaces are all continuous.

Report issue for preceding element

The work in \[[29](https://arxiv.org/html/2509.16146v1#bib.bib29)\] studies a class of finite-state channels in which the previous output serves as the current channel state, referred to as POST channels. The authors present a surprising result: for certain POST channels, feedback does not increase channel capacity. This work is relevant to ours because, to some extent, the implicit communication channel in an LQG control system with noiseless observations can also be viewed as a POST channel. At each time step, the system is in some state xtx\_{t}, which can be interpreted as the channel state. The transmitter (i.e., the controller) applies an input utu\_{t}, resulting a new system state xt+1x\_{t+1}, which can be viewed as the channel input and output, respectively. The current output xt+1x\_{t+1} then becomes the channel state at the next time step. The key differences between the work in \[[29](https://arxiv.org/html/2509.16146v1#bib.bib29)\] and ours are twofold: (i) they focus on channels with finite state and input alphabets; and (ii) their setting does not impose any constraints, whereas our formulation includes a control performance constraint, which is effectively a joint constraint on both inputs and outputs.

Report issue for preceding element

Another line of research relevant to our work is the capacity of Gaussian MIMO channels, which has been extensively studied in the literature \[[30](https://arxiv.org/html/2509.16146v1#bib.bib30), [31](https://arxiv.org/html/2509.16146v1#bib.bib31), [32](https://arxiv.org/html/2509.16146v1#bib.bib32), [33](https://arxiv.org/html/2509.16146v1#bib.bib33)\]. Our analysis shows that, under a linear input policyâ€”which is proved to be capacity-achieving when the controller has noiseless observationsâ€”the implicit channel can be equivalently translated into a Gaussian MIMO channel without channel state. In the case where both the controller and the receiver have noiseless observations, the equivalent channel is a memoryless Gaussian MIMO channel, whose capacity is known to admit a closed-form expression, as derived in \[[34](https://arxiv.org/html/2509.16146v1#bib.bib34)\] via the water-filling algorithm. Our achievability proof in this setting builds on this result, with additional analysis related to the control constraint.

Report issue for preceding element

In the more general setting where the receiver has noisy observations, the equivalent channel under the capacity-achieving input policy becomes a Gaussian MIMO channel with memory, in which the noise process forms a hidden Markov chain. The feedback capacity of such channels is studied in \[[35](https://arxiv.org/html/2509.16146v1#bib.bib35)\] and is characterized as the solution to a finite-dimensional convex optimization problem. However, there is no feedback in our setting. To the best of our knowledge, the capacity of this type of Gaussian MIMO channel with memory but without feedback has not been presented in the literature; only some simulation-based algorithms for computing the information rate are available \[[36](https://arxiv.org/html/2509.16146v1#bib.bib36), [37](https://arxiv.org/html/2509.16146v1#bib.bib37)\]. Hence our achievability proof in this setting is of independent interestâ€”at least for linear-Gaussian systems. It is also worth noting that the equivalent channel in our problem does not fall into the category of Gaussian channels with inter-symbol interference (ISI) \[[38](https://arxiv.org/html/2509.16146v1#bib.bib38), [39](https://arxiv.org/html/2509.16146v1#bib.bib39), [40](https://arxiv.org/html/2509.16146v1#bib.bib40)\], as the memory arises solely from the hidden Markov structure of the noise process.

Report issue for preceding element

At the intersection of control and communication, extensive research has been conducted on control under communication constraints \[[41](https://arxiv.org/html/2509.16146v1#bib.bib41), [42](https://arxiv.org/html/2509.16146v1#bib.bib42), [43](https://arxiv.org/html/2509.16146v1#bib.bib43)\], which is also known as networked control \[[44](https://arxiv.org/html/2509.16146v1#bib.bib44)\]. These studies typically assume the presence of an explicit communication channelâ€”often between the sensor and the controllerâ€”to enable information exchange within the control loop. The focus of analysis has been on understanding how the communication constraint affects the control performance. For example, the work in \[[45](https://arxiv.org/html/2509.16146v1#bib.bib45)\] analyzes the trade-off between control cost and the information rate over an explicit channel from the sensor to the controller. In contrast, our study introduces implicit communication as a new direction in integrating control and communication. In this framework, no explicit communication channel is assumed; rather, the control system itself serves as the medium for information exchange. From an information-theoretic perspective, implicit communication can be viewed as communication under control constraints, effectively reversing the conventional lens of networked control.

Report issue for preceding element

## III System Model and Preliminaries

Report issue for preceding element

This section begins with an introduction to linear quadratic-Gaussian control systems. We then define implicit communication in this setting, illustrating how communication can occur as a byproduct of LQG control. Finally, we formulate the trade-off between communication and control performance.

Report issue for preceding element

### III-A Linear Quadratic-Gaussian (LQG) Control Systems

Report issue for preceding element

Consider a discrete-time linear control system

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | xt+1\=Aâ€‹xt+Bâ€‹ut+wt,\\displaystyle x\_{t+1}=Ax\_{t}+Bu\_{t}+w\_{t}, |     | (1) |

where xtâˆˆâ„d1x\_{t}\\in\\mathbb{R}^{d\_{1}} and utâˆˆâ„d2u\_{t}\\in\\mathbb{R}^{d\_{2}} are the state and control input at time tt, respectively, wtâˆˆâ„d1w\_{t}\\in\\mathbb{R}^{d\_{1}} is an additive zero-mean white Gaussian noise with covariance matrix Î¨wâ‰»0\\Psi\_{w}\\succ 0, and Aâˆˆâ„d1Ã—d1A\\in\\mathbb{R}^{d\_{1}\\times d\_{1}} and Bâˆˆâ„d1Ã—d2B\\in\\mathbb{R}^{d\_{1}\\times d\_{2}} are fixed matrices. We assume the noise is independent of the state and input. In addition, {wt}\\{w\_{t}\\} is an independent and identically distributed (i.i.d.) sequence, i.e., wtw\_{t} is independent of wkw\_{k} for any tâ‰ kt\\neq k. The initial state x1x\_{1} is randomly sampled from a Gaussian distribution ğ’©â€‹(0,Î¨x)\\mathcal{N}(0,\\Psi\_{x}). Finally, we make the usual assumption that the pair (A,B)(A,B) is controllable.

Report issue for preceding element

At each time tt, the controller observes the state xtx\_{t} and computes an input utu\_{t} to control the system. The objective of control over a time horizon of length nn is to minimize the average quadratic cost, defined as

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | min{ut}â¡Jnâ‰œ1nâ€‹ğ”¼â€‹\[âˆ‘t\=1n(xtâŠ¤â€‹Fâ€‹xt+utâŠ¤â€‹Gâ€‹ut)+xn+1âŠ¤â€‹Fâ€‹xn+1\],\\displaystyle\\min\_{\\{u\_{t}\\}}\\ J\_{n}\\triangleq\\frac{1}{n}\\mathbb{E}\\left\[\\sum\_{t=1}^{n}\\left(x^{\\top}\_{t}Fx\_{t}+u^{\\top}\_{t}Gu\_{t}\\right)+x^{\\top}\_{n+1}Fx\_{n+1}\\right\], |     | (2) |

where Fâˆˆâ„d1Ã—d1F\\in\\mathbb{R}^{d\_{1}\\times d\_{1}} and Gâˆˆâ„d2Ã—d2G\\in\\mathbb{R}^{d\_{2}\\times d\_{2}} are PSD matrices. The system is referred to as an LQG control system because it has linear dynamics, a quadratic cost function, and a Gaussian process noise. We next introduce some well-known results on LQG control, which will be useful in the following sections.

Report issue for preceding element

Let Jnâˆ—:=minâ¡JnJ^{\*}\_{n}:=\\min J\_{n} denote the minimum cost of the nn\-step LQG control problem. The optimal control policy that achieves Jnâˆ—J^{\*}\_{n} is linear and takes the form ut\=âˆ’Ktâ€‹xtu\_{t}=-K\_{t}x\_{t}, where the feedback gain KtK\_{t} is given by

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Kt\=(G+BâŠ¤â€‹Î“tâ€‹B)âˆ’1â€‹BâŠ¤â€‹Î“tâ€‹A.\\displaystyle K\_{t}=(G+B^{\\top}\\Gamma\_{t}B)^{-1}B^{\\top}\\Gamma\_{t}A. |     | (3) |

Here, Î“t\\Gamma\_{t} is a PSD matrix determined by the following Riccati difference equation that runs backward in time:

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Î“t\=F+AâŠ¤â€‹(Î“t+1âˆ’Î“t+1â€‹Bâ€‹(G+BâŠ¤â€‹Î“t+1â€‹B)âˆ’1â€‹BâŠ¤â€‹Î“t+1)â€‹A, 1â‰¤tâ‰¤n,\\displaystyle\\Gamma\_{t}=F+A^{\\top}(\\Gamma\_{t+1}-\\Gamma\_{t+1}B(G+B^{\\top}\\Gamma\_{t+1}B)^{-1}B^{\\top}\\Gamma\_{t+1})A,\\ 1\\leq t\\leq n, |     | (4) |

where Î“n+1\=F\\Gamma\_{n+1}=F. Under the optimal control policy, the minimum cost Jnâˆ—J^{\*}\_{n} is given by

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Jnâˆ—\=1nâ€‹\[Trâ€‹(Î¨xâ€‹Î“1)+âˆ‘t\=1nTrâ€‹(Î¨wâ€‹Î“t+1)\].\\displaystyle J^{\*}\_{n}=\\frac{1}{n}\\left\[\\text{Tr}(\\Psi\_{x}\\Gamma\_{1})+\\sum\_{t=1}^{n}\\text{Tr}(\\Psi\_{w}\\Gamma\_{t+1})\\right\]. |     | (5) |

We refer to ([2](https://arxiv.org/html/2509.16146v1#S3.E2 "In III-A Linear Quadratic-Gaussian (LQG) Control Systems â€£ III System Model and Preliminaries â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) as the nn\-step LQG control problem when nn is finite. For an infinite time horizon, the control objective is to minimize the long-term average quadratic cost, defined as:

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Jâ‰œlimnâ†’âˆJn\=limnâ†’âˆ1nâ€‹âˆ‘t\=1n\[xtâŠ¤â€‹Fâ€‹xt+utâŠ¤â€‹Gâ€‹ut\].\\displaystyle J\\triangleq\\lim\_{n\\to\\infty}J\_{n}=\\lim\_{n\\to\\infty}\\frac{1}{n}\\sum\_{t=1}^{n}\\left\[x^{\\top}\_{t}Fx\_{t}+u^{\\top}\_{t}Gu\_{t}\\right\]. |     | (6) |

Denote by Jâˆ—\=minâ¡JJ^{\*}=\\min J the minimum cost of the infinite time LQG control. The optimal control policy that achieves Jâˆ—J^{\*} is stationary linear and takes the form ut\=âˆ’Kâ€‹xtu\_{t}=-Kx\_{t}, where the feedback gain is

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | K\=(G+BâŠ¤â€‹Î“â€‹B)âˆ’1â€‹BâŠ¤â€‹Î“â€‹A.\\displaystyle K=(G+B^{\\top}\\Gamma B)^{-1}B^{\\top}\\Gamma A. |     | (7) |

Matrix Î“\\Gamma is the solution to the discrete-time algebraic Riccati equation (DARE):

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Î“\=F+AâŠ¤â€‹(Î“âˆ’Î“â€‹Bâ€‹(G+BâŠ¤â€‹Î“â€‹B)âˆ’1â€‹BâŠ¤â€‹Î“)â€‹A.\\displaystyle\\Gamma=F+A^{\\top}(\\Gamma-\\Gamma B(G+B^{\\top}\\Gamma B)^{-1}B^{\\top}\\Gamma)A. |     | (8) |

Since the system is time-invariantâ€”i.e., A,B,FA,B,F and GG are constant matrices over time, and {wt}\\{w\_{t}\\} is a stationary noise processâ€”there is a well-established relationship between finite-horizon and infinite-horizon LQG control problems. Specifically, as nâ†’âˆn\\to\\infty, the finite-horizon optimal cost converges to the infinite-horizon optimal cost, i.e., Jnâˆ—â†’Jâˆ—J^{\*}\_{n}\\to J^{\*}. Moreover, the feedback gain and Riccati solution stabilize, such that Kt\=K,Î“t\=Î“K\_{t}=K,\\Gamma\_{t}=\\Gamma for all tt. It follows immediately that the minimum average cost of the infinite-horizon control is given by Jâˆ—\=Trâ€‹(Î“â€‹Î¨w)J^{\*}=\\text{Tr}(\\Gamma\\Psi\_{w}).

Report issue for preceding element

### III-B Implicit Communication in LQG Control Systems

Report issue for preceding element

This paper studies implicit communication in LQG control systems, where the controller aims not only to minimize the average quadratic cost but also to transmit messages to a receiver through its control inputs. We assume there is no dedicated communication channel between the controller and the receiver; instead, both parties can observe the system state. As such, the LQG control system itself can serve as a communication channel between the controller and receiver, which we refer to as the implicit channel. Communication via this implicit channel is called implicit communication because (i) no explicit channel exists between the transmitter (i.e., the controller) and the receiver, and (ii) information transfer occurs as a â€œbyproductâ€ of specifically designed control inputs.

Report issue for preceding element

![Refer to caption](x1.png)

Figure 1: Implicit communication in LQG control systems (noiseless observations at controller and receiver).

Report issue for preceding element

We begin with a simple setting in which both the controller and receiver have perfect access to the system state, as shown in Fig. [1](https://arxiv.org/html/2509.16146v1#S3.F1 "Figure 1 â€£ III-B Implicit Communication in LQG Control Systems â€£ III System Model and Preliminaries â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"). Extensions to more general scenarios, where observations are noisy for the receiver or for both parties, will be defined and addressed in later sections. To transmit a message mm, the controller acts as an encoder, selecting an input utu\_{t} at each time tt according to the message mm and the sequence of past and current states xtx^{t}. The receiver then observes the state sequences to decode the message mm. Suppose the message set â„³\=\[2nâ€‹R\]\\mathcal{M}=\[2^{nR}\] and each message mm is drawn uniformly from â„³\\mathcal{M}. Following standard definitions, a (2nâ€‹R,n)(2^{nR},n) code for the implicit channel comprises a pair of encoding and decoding mappings, used to transmit a message over nn time steps. In particular, let ğ’°\=â„d2\\mathcal{U}=\\mathbb{R}^{d\_{2}} and ğ’³\=â„d1\\mathcal{X}=\\mathbb{R}^{d\_{1}} denote the input and output alphabets, respectively. Then the encoderâ€™s mapping at time tt is denoted by

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | ut:â„³Ã—ğ’³tâ†’ğ’°.\\displaystyle u\_{t}:\\mathcal{M}\\times\\mathcal{X}^{t}\\to\\mathcal{U}. |     |

The decoder observes the initial state x1x\_{1} and the following nn states to decode the message, and uses the mapping

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | m^:ğ’³n+1â†’â„³.\\displaystyle\\hat{m}:\\mathcal{X}^{n+1}\\to\\mathcal{M}. |     |

The average probability of error is then defined as Pe(n)\=Pâ€‹(m^â‰ m)P^{(n)}\_{e}=P(\\hat{m}\\neq m). Effectively, we treat the LQG control system as a channel with state: at each time tt, an input utu\_{t} is applied in state xtx\_{t}, resulting an output xt+1x\_{t+1}, which then becomes the channel state at the next time step.

Report issue for preceding element

In general, communicating through the implicit channel requires the controller to deviate from the optimal control policy, resulting in a degradation of control performance. This leads to a fundamental trade-off between control and communication. A natural way to characterize this trade-off is by maximizing communication performance subject to a constraint on control cost. In particular, we say a (2nâ€‹R,n)(2^{nR},n) code is admissible if it satisfies the control constraint

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Jnâ‰¤Jnâˆ—+V,\\displaystyle J\_{n}\\leq J^{\*}\_{n}+V, |     |

where Jnâˆ—J^{\*}\_{n} is the optimal nn\-step control cost defined in ([5](https://arxiv.org/html/2509.16146v1#S3.E5 "In III-A Linear Quadratic-Gaussian (LQG) Control Systems â€£ III System Model and Preliminaries â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) and Vâ‰¥0V\\geq 0 quantifies the tolerable control loss. A rate RR is said to be achievable if there exists a sequence of admissible (2nâ€‹R,n)(2^{nR},n) codes with Pe(n)â†’0P^{(n)}\_{e}\\to 0 as nâ†’âˆn\\to\\infty. The implicit channel capacity Câ€‹(V)C(V) is then defined as the supremum of all achievable rates under the control constraint.

Report issue for preceding element

## IV Noiseless Observations at the Controller and the Receiver

Report issue for preceding element

This section presents the capacity of the implicit channel under a control constraint. Given that perfect state observations are available at both the controller and the receiver, the capacity admits a closed-form expression that coincides with a memoryless Gaussian MIMO channel. In the special case of scalar systems, capacity Câ€‹(V)C(V) reduces to an explicit function of the minimum control cost Jâˆ—J^{\*} and the tolerable control loss VV. We provide the achievability proof in this section, as it offers useful insights into the structure of the channel under the capacity-achieving input policy. The converse proof is lengthy and is therefore deferred to Section [VII](https://arxiv.org/html/2509.16146v1#S7 "VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems").

Report issue for preceding element

### IV-A Capacity

Report issue for preceding element

When both the controller and the receiver have noiseless state observations, the only source of noise in the implicit channel is the process noise wtw\_{t}. As a result, the noise covariance matrix Î¨w\\Psi\_{w} plays a central roleâ€”not only in control, where the optimal long-term average control cost is given by Jâˆ—\=Trâ€‹(Î“â€‹Î¨w)J^{\*}=\\text{Tr}(\\Gamma\\Psi\_{w}), but also in communication. Denote by Î»i\\lambda\_{i} the ii\-th eigenvalue of Î¨w\\Psi\_{w}. Since Î¨w\\Psi\_{w} is PD, we have Î»i\>0\\lambda\_{i}>0 for all iâˆˆ\[d1\]i\\in\[d\_{1}\]. In addition, Î¨w\\Psi\_{w} admits a diagonal decomposition Î¨w\=Uâ€‹Î›â€‹UâŠ¤\\Psi\_{w}=U\\Lambda U^{\\top}, where UU is a unitary matrix and Î›\=ğšğš’ğšŠğšâ€‹(Î»1,Î»2,â‹¯,Î»d1)\\Lambda=\\mathtt{diag}(\\lambda\_{1},\\lambda\_{2},\\cdots,\\lambda\_{d\_{1}}) is a diagonal matrix of eigenvalues. We first highlight a key property of a matrix that is related to the capacity.

Report issue for preceding element

###### Lemma 1

Report issue for preceding element

For the LQG control system ([1](https://arxiv.org/html/2509.16146v1#S3.E1 "In III-A Linear Quadratic-Gaussian (LQG) Control Systems â€£ III System Model and Preliminaries â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) with noise covariance matrix Î¨w\=Uâ€‹Î›â€‹UâŠ¤\\Psi\_{w}=U\\Lambda U^{\\top}, define matrices G^â‰œ(Bâ€ )âŠ¤â€‹Gâ€‹Bâ€ \\hat{G}\\triangleq(B^{\\dagger})^{\\top}GB^{\\dagger} and Î“^â‰œUâŠ¤â€‹\[Î“+G^\]â€‹U\\hat{\\Gamma}\\triangleq U^{\\top}\[\\Gamma+\\hat{G}\]U. Then Î“^\\hat{\\Gamma} has non-negative diagonal entries, i.e., Î“^â€‹(i,i)â‰¥0\\hat{\\Gamma}(i,i)\\geq 0 for all ii.

Report issue for preceding element

The proof of this lemma is straightforward. Since Î“\\Gamma is a solution to the DARE defined in ([8](https://arxiv.org/html/2509.16146v1#S3.E8 "In III-A Linear Quadratic-Gaussian (LQG) Control Systems â€£ III System Model and Preliminaries â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), it is guaranteed to be PSD. By definition, GG is also PSD. Hence Î“^\\hat{\\Gamma} must be PSD, which implies that all its diagonal entries are non-negative. Nevertheless, we provide an alternative and more insightful proof in the Appendix. This alternative argument shows if Î“^â€‹(i,i)\=0\\hat{\\Gamma}(i,i)=0 for some ii, then it is possible to make the power of input utu\_{t} unbounded in a certain direction without increasing the control cost. As will be elaborated later, this leads to an unbounded capacity, i.e., Câ€‹(V)\=âˆC(V)=\\infty. This special case can be ruled out by imposing a slightly stronger condition on GG: if GG is PD, then Î“^\\hat{\\Gamma} is also PD, ensuring that Î“^â€‹(i,i)\>0\\hat{\\Gamma}(i,i)>0 for all ii.

Report issue for preceding element

We now present the capacity of the implicit channel when both the controller and the receiver have noiseless observations.

Report issue for preceding element

###### Theorem 1

Report issue for preceding element

For any Vâ‰¥0V\\geq 0, the capacity of the implicit channel under the control constraint Jâ‰¤Jâˆ—+VJ\\leq J^{\*}+V is given by

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Câ€‹(V)\=12â€‹âˆ‘i\=1d1logâ¡(1+Ï•iÎ»i),\\displaystyle C(V)=\\frac{1}{2}\\sum\_{i=1}^{d\_{1}}\\log\\left(1+\\frac{\\phi\_{i}}{\\lambda\_{i}}\\right), |     |

where Ï•i\=âˆ{\\phi}\_{i}=\\infty if Î“^â€‹(i,i)\=0\\hat{\\Gamma}(i,i)=0; otherwise,

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Ï•i\=maxâ¡(Î±Î“^â€‹(i,i)âˆ’Î»i,0),\\displaystyle{\\phi}\_{i}=\\max\\left(\\frac{\\alpha}{\\hat{\\Gamma}(i,i)}-{\\lambda\_{i}},0\\right), |     |

with Î±\\alpha being chosen to satisfy

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | âˆ‘i:Î“^â€‹(i,i)\>0maxâ¡(Î±âˆ’Î»iâ€‹Î“^â€‹(i,i),0)\=V.\\displaystyle\\sum\_{i:\\hat{\\Gamma}(i,i)>0}\\max\\left({\\alpha}-{\\lambda\_{i}}{\\hat{\\Gamma}(i,i)},0\\right)=V. |     |

The optimal input that achieves the capacity is ut\=âˆ’Kâ€‹xt+Bâ€ â€‹stu\_{t}=-Kx\_{t}+B^{\\dagger}s\_{t}, where KK is the optimal feedback gain defined in ([7](https://arxiv.org/html/2509.16146v1#S3.E7 "In III-A Linear Quadratic-Gaussian (LQG) Control Systems â€£ III System Model and Preliminaries â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) and stâˆ¼ğ’©â€‹(0,Î¦)s\_{t}\\sim\\mathcal{N}(0,\\Phi) is independent of wtw\_{t} and xtx\_{t}, with Î¦\=Uâ€‹Î¦^â€‹UâŠ¤\\Phi=U\\hat{\\Phi}U^{\\top} and Î¦^\=ğšğš’ğšŠğšâ€‹(Ï•1,Ï•2,â‹¯,Ï•d1)\\hat{\\Phi}=\\mathtt{diag}(\\phi\_{1},\\phi\_{2},\\cdots,\\phi\_{d\_{1}}).

Report issue for preceding element

Theorem [1](https://arxiv.org/html/2509.16146v1#Thmtheorem1 "Theorem 1 â€£ IV-A Capacity â€£ IV Noiseless Observations at the Controller and the Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") provides key insights into implicit communication in LQG control systems. First, the expression of the capacity matches that of Gaussian MIMO channels. As will be demonstrated clearly in the achievability proof, under the capacity-achieving input policy, the implicit channel effectively reduces to a memoryless Gaussian MIMO channel of the form yt\=st+wty\_{t}=s\_{t}+w\_{t}.

Report issue for preceding element

Second, Theorem [1](https://arxiv.org/html/2509.16146v1#Thmtheorem1 "Theorem 1 â€£ IV-A Capacity â€£ IV Noiseless Observations at the Controller and the Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") reveals a separation principle: the control input and the communication input can be designed independently, without loss of optimality. Specifically, the capacity-achieving input consists of two components: the term âˆ’Kâ€‹xt\-Kx\_{t}, which is exactly the optimal control input for minimizing the quadratic control cost, and the term Bâ€ â€‹stB^{\\dagger}s\_{t}, a Gaussian random variable independent of âˆ’Kâ€‹xt\-Kx\_{t}. While the first term is fully determined by the control objective, communication is achieved by encoding information into the second term. Hence we refer to sts\_{t} as the communication signal. As a consequence of this separation structure, given a tolerable control loss VV, the task of maximizing communication performance under the control constraint can be decomposed into two subproblems: (i) computing the optimal LQG control policy; and then (ii) designing the channel code for a Gaussian MIMO channel. This decomposition greatly simplifies the implicit communication problem, as both subproblems are well studied and solvable using existing methods.

Report issue for preceding element

From a control perspective, the communication signal Bâ€ â€‹stB^{\\dagger}s\_{t} can be viewed as an additional noise injected into the process by the controller, thereby incurring an extra control cost. The exact value of this additional cost is given in the following lemma:

Report issue for preceding element

###### Lemma 2

Report issue for preceding element

For the LQG control system ([1](https://arxiv.org/html/2509.16146v1#S3.E1 "In III-A Linear Quadratic-Gaussian (LQG) Control Systems â€£ III System Model and Preliminaries â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), under the input policy ut\=âˆ’Kâ€‹xt+Bâ€ â€‹stu\_{t}=-Kx\_{t}+B^{\\dagger}s\_{t}, where stâˆ¼ğ’©â€‹(0,Î¦)s\_{t}\\sim\\mathcal{N}(0,\\Phi) is independent of xtx\_{t} and wtw\_{t}, the long-term average control cost is given by J\=Jâˆ—+Trâ€‹((Î“+G^)â€‹Î¦)J=J^{\*}+\\text{Tr}((\\Gamma+\\hat{G})\\Phi).

Report issue for preceding element

###### Proof:

Report issue for preceding element

See Appendix A. âˆ

Report issue for preceding element

By the definition in ([6](https://arxiv.org/html/2509.16146v1#S3.E6 "In III-A Linear Quadratic-Gaussian (LQG) Control Systems â€£ III System Model and Preliminaries â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), the control cost comprises two components: a penalty for the stateâ€™s deviation from 0 and an input cost. The communication signal not only raise the input cost by Trâ€‹(Gâ€‹Bâ€ â€‹Î¦â€‹(Bâ€ )âŠ¤)\=Trâ€‹(G^â€‹Î¦)\\text{Tr}(GB^{\\dagger}\\Phi(B^{\\dagger})^{\\top})=\\text{Tr}(\\hat{G}\\Phi), but also increase the state covariance in the steady-state, resulting in an additional cost of Trâ€‹(Î“â€‹Î¦)\\text{Tr}(\\Gamma\\Phi).

Report issue for preceding element

Theorem [1](https://arxiv.org/html/2509.16146v1#Thmtheorem1 "Theorem 1 â€£ IV-A Capacity â€£ IV Noiseless Observations at the Controller and the Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") can be specialized to scalar systems, resulting in a capacity expression that is an explicit function of the optimal control cost Jâˆ—J^{\*} and tolerable control loss VV.

Report issue for preceding element

###### Theorem 2

Report issue for preceding element

For a scalar LQG system (i.e., d1\=d2\=1d\_{1}=d\_{2}=1), the capacity of the implicit channel under the control constraint Jâ‰¤Jâˆ—+VJ\\leq J^{\*}+V is given by

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Câ€‹(V)\=12â€‹logâ¡(1+VJâˆ—+Bâˆ’2â€‹Gâ€‹Î¨w).\\displaystyle C(V)=\\frac{1}{2}\\log\\left(1+\\frac{V}{J^{\*}+B^{-2}G\\Psi\_{w}}\\right). |     |

The optimal input is ut\=âˆ’Kâ€‹xt+Bâˆ’1â€‹stu\_{t}=-Kx\_{t}+B^{-1}s\_{t}, where KK is the optimal feedback gain defined in ([7](https://arxiv.org/html/2509.16146v1#S3.E7 "In III-A Linear Quadratic-Gaussian (LQG) Control Systems â€£ III System Model and Preliminaries â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) and stâˆ¼ğ’©â€‹(0,V/(Î“+Bâˆ’2â€‹G))s\_{t}\\sim\\mathcal{N}(0,V/(\\Gamma+B^{-2}G)) is independent of wtw\_{t} and xtx\_{t}.

Report issue for preceding element

###### Proof:

Report issue for preceding element

See Appendix A. âˆ

Report issue for preceding element

The expression in Theorem [2](https://arxiv.org/html/2509.16146v1#Thmtheorem2 "Theorem 2 â€£ IV-A Capacity â€£ IV Noiseless Observations at the Controller and the Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") can be interpreted as follows. As discussed above, the term Bâˆ’2â€‹Gâ€‹Î¨wB^{-2}G\\Psi\_{w} is equal to the input cost of a signal Bâˆ’1â€‹wtB^{-1}w\_{t}â€”as if the process noise were injected by the control input itself. Therefore, the quantity Jâˆ—+Bâˆ’2â€‹Gâ€‹Î¨wJ^{\*}+B^{-2}G\\Psi\_{w} can be viewed as the overall control cost when the noise wtw\_{t} originates from the controller rather than the environment. The capacity is then determined by the ratio of control costs in two scenarios: (i) the controller injects both wtw\_{t} and sts\_{t} into the process, and (ii) the controller injects only wtw\_{t}.

Report issue for preceding element

### IV-B Achievability Proof

Report issue for preceding element

We now present the achievability proof for Theorem [1](https://arxiv.org/html/2509.16146v1#Thmtheorem1 "Theorem 1 â€£ IV-A Capacity â€£ IV Noiseless Observations at the Controller and the Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"), showing that any rate Râ‰¤Câ€‹(V)R\\leq C(V) can be achieved by the input policy ut\=âˆ’Kâ€‹xt+Bâ€ â€‹stu\_{t}=-Kx\_{t}+B^{\\dagger}s\_{t}, where stâˆ¼ğ’©â€‹(0,Î¦)s\_{t}\\sim\\mathcal{N}(0,\\Phi) is independent of xtx\_{t} and wtw\_{t}. Under this policy, the state evolves as follows:

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | xt+1\=(Aâˆ’Bâ€‹K)â€‹xt+st+wt.\\displaystyle x\_{t+1}=(A-BK)x\_{t}+s\_{t}+w\_{t}. |     | (9) |

Define ytâ‰œxt+1âˆ’(Aâˆ’Bâ€‹K)â€‹xty\_{t}\\triangleq x\_{t+1}-(A-BK)x\_{t}, then the above process becomes

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | yt\=st+wt.\\displaystyle y\_{t}=s\_{t}+w\_{t}. |     | (10) |

This forms a classic Gaussian MIMO channel with input sts\_{t}, output yty\_{t}, and additive white Gaussian noise wtw\_{t}. The capacity of such a channel under an average input power constraint is well established. Hence the key step in our achievability proof is to show that, under the proposed policy, the control constraint can be equivalently translated into a constraint on the power of signal sts\_{t}. This result is established in Lemma [2](https://arxiv.org/html/2509.16146v1#Thmlemma2 "Lemma 2 â€£ IV-A Capacity â€£ IV Noiseless Observations at the Controller and the Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"). In particular, under the input policy ut\=âˆ’Kâ€‹xt+Bâ€ â€‹stu\_{t}=-Kx\_{t}+B^{\\dagger}s\_{t}, the constraint Jâ‰¤Jâˆ—+VJ\\leq J^{\*}+V is equivalent to a weighted power constraint on sts\_{t}: Trâ€‹((Î“+G^)â€‹Î¦)\=ğ”¼â€‹\[sâŠ¤â€‹(Î“+G^)â€‹s\]â‰¤V\\text{Tr}((\\Gamma+\\hat{G})\\Phi)=\\mathbb{E}\[s^{\\top}(\\Gamma+\\hat{G})s\]\\leq V.

Report issue for preceding element

The remainder of the proof largely follows the standard procedure for Gaussian MIMO channels \[[34](https://arxiv.org/html/2509.16146v1#bib.bib34)\], with additional considerations related to the input power constraint, as matrix Î“+G^\\Gamma+\\hat{G} is not guaranteed to be positive definite. Specifically, we use the well-known result that the capacity of the equivalent Gaussian MIMO channel defined in ([10](https://arxiv.org/html/2509.16146v1#S4.E10 "In IV-B Achievability Proof â€£ IV Noiseless Observations at the Controller and the Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) is given by the maximum mutual information Iâ€‹(s;y)I(s;y), subject to the input constraint. Note that

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Iâ€‹(s;y)\=hâ€‹(y)âˆ’hâ€‹(w)\=12â€‹logâ¡det(Î¨w+Î¦)det(Î¨w)\=12â€‹logâ€‹det(I+Î¨wâˆ’1â€‹Î¦),\\displaystyle I(s;y)=h(y)-h(w)=\\frac{1}{2}\\log\\frac{\\det(\\Psi\_{w}+\\Phi)}{\\det(\\Psi\_{w})}=\\frac{1}{2}\\log\\det(I+\\Psi\_{w}^{-1}\\Phi), |     |

where we omitted the time index tt for notation simplicity. Since Î¨w\=Uâ€‹Î›â€‹UâŠ¤\\Psi\_{w}=U\\Lambda U^{\\top} is positive definite, so is Î¨wâˆ’1\\Psi\_{w}^{-1}. We thus can diagonalize Î¨wâˆ’1\\Psi\_{w}^{-1} as Î¨wâˆ’1\=Uâ€‹Î›âˆ’1â€‹UâŠ¤\\Psi\_{w}^{-1}=U\\Lambda^{-1}U^{\\top}, where Î›âˆ’1\=ğšğš’ğšŠğšâ€‹(Î»1âˆ’1,Î»2âˆ’1,â‹¯,Î»d1âˆ’1)\\Lambda^{-1}=\\mathtt{diag}(\\lambda\_{1}^{-1},\\lambda^{-1}\_{2},\\cdots,\\lambda\_{d\_{1}}^{-1}). We then have

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | logâ€‹det(I+Î¨wâˆ’1â€‹Î¦)\=logâ€‹det(I+Uâ€‹Î›âˆ’1â€‹UâŠ¤â€‹Î¦)\=logâ€‹det(I+Î›âˆ’12â€‹UâŠ¤â€‹Î¦â€‹Uâ€‹Î›âˆ’12).\\displaystyle\\log\\det(I+\\Psi\_{w}^{-1}\\Phi)=\\log\\det(I+U\\Lambda^{-1}U^{\\top}\\Phi)=\\log\\det(I+\\Lambda^{-\\frac{1}{2}}U^{\\top}\\Phi U\\Lambda^{-\\frac{1}{2}}). |     |

Let Î¦^\=UâŠ¤â€‹Î¦â€‹U\\hat{\\Phi}=U^{\\top}\\Phi U and Î“^\=UâŠ¤â€‹(Î“+G^)â€‹U\\hat{\\Gamma}=U^{\\top}(\\Gamma+\\hat{G})U, then Trâ€‹((Î“+G^)â€‹Î¦)\=Trâ€‹((Î“+G^)â€‹Uâ€‹Î¦^â€‹UâŠ¤)\=Trâ€‹(Î“^â€‹Î¦^)â‰¤V\\text{Tr}((\\Gamma+\\hat{G})\\Phi)=\\text{Tr}((\\Gamma+\\hat{G})U\\hat{\\Phi}U^{\\top})=\\text{Tr}(\\hat{\\Gamma}\\hat{\\Phi})\\leq V. Therefore, the capacity of channel ([10](https://arxiv.org/html/2509.16146v1#S4.E10 "In IV-B Achievability Proof â€£ IV Noiseless Observations at the Controller and the Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) is given by

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Câ€‹(V)\=maxÎ¦^â‰¥0\\displaystyle C(V)=\\max\_{\\hat{\\Phi}\\geq 0} | 12â€‹logâ€‹det(I+Î›âˆ’12â€‹Î¦^â€‹Î›âˆ’12)\\displaystyle\\ \\frac{1}{2}\\log\\det(I+\\Lambda^{-\\frac{1}{2}}\\hat{\\Phi}\\Lambda^{-\\frac{1}{2}}) |     |
|     | s.t. | Trâ€‹(Î“^â€‹Î¦^)â‰¤V.\\displaystyle\\ \\text{Tr}(\\hat{\\Gamma}\\hat{\\Phi})\\leq V. |     |

It is known that the optimal Î¦^\\hat{\\Phi} is a diagonal matrix, because

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | det(I+Î›âˆ’12â€‹Î¦^â€‹Î›âˆ’12)â‰¤âˆi\=1d1(1+Î»iâˆ’1â€‹Î¦^â€‹(i,i)),\\displaystyle\\det(I+\\Lambda^{-\\frac{1}{2}}\\hat{\\Phi}\\Lambda^{-\\frac{1}{2}})\\leq\\prod\_{i=1}^{d\_{1}}\\left(1+\\lambda\_{i}^{-1}\\hat{\\Phi}(i,i)\\right), |     |

with equality when Î¦^\\hat{\\Phi} is diagonal. According to Lemma [1](https://arxiv.org/html/2509.16146v1#Thmlemma1 "Lemma 1 â€£ IV-A Capacity â€£ IV Noiseless Observations at the Controller and the Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"), the diagonal entries of Î“^\\hat{\\Gamma} are non-negative. If Î“^\\hat{\\Gamma} has positive diagonal entries, i.e., Î“^â€‹(i,i)\>0\\hat{\\Gamma}(i,i)>0 for all ii, then the above problem can be solved by the well-known water-filling algorithm. In particular, the optimal Î¦^\\hat{\\Phi} is a diagonal matrix with the ii\-th diagonal entry given by

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Î¦^â€‹(i,i)\=maxâ¡(Î±Î“^â€‹(i,i)âˆ’Î»i,0)\\displaystyle\\hat{\\Phi}(i,i)=\\max\\left(\\frac{\\alpha}{\\hat{\\Gamma}(i,i)}-{\\lambda\_{i}},0\\right) |     |

for all tt, where Î“^â€‹(i,i){\\hat{\\Gamma}(i,i)} is the ii\-th diagonal entry of Î“^\\hat{\\Gamma}, and Î±\\alpha is chosen to satisfy

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | âˆ‘i\=1d1maxâ¡(Î±âˆ’Î»iâ€‹Î“^â€‹(i,i),0)\=V.\\displaystyle\\sum\_{i=1}^{d\_{1}}\\max\\left({\\alpha}-{\\lambda\_{i}}{\\hat{\\Gamma}(i,i)},0\\right)=V. |     |

Hence the capacity is given by

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Câ€‹(V)\=12â€‹âˆ‘i\=1d1logâ¡(1+Î¦^â€‹(i,i)Î»i).\\displaystyle{C}(V)=\\frac{1}{2}\\sum\_{i=1}^{d\_{1}}\\log\\left(1+\\frac{\\hat{\\Phi}(i,i)}{\\lambda\_{i}}\\right). |     |

On the other hand, if Î“^\\hat{\\Gamma} has zero-valued diagonal entries, the channel capacity is infinity. Without loss of generality, assume that the first kk diagonal entries are zero, and the remaining diagonal entries are positive. Then for diagonal Î¦^\\hat{\\Phi}, the constraint can be written as

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Trâ€‹(Î“^â€‹Î¦^)\=âˆ‘i\=1d1Î“^â€‹(i,i)â€‹Î¦^â€‹(i,i)\=âˆ‘i\=k+1d1Î“^â€‹(i,i)â€‹Î¦^â€‹(i,i)â‰¤V.\\displaystyle\\text{Tr}(\\hat{\\Gamma}\\hat{\\Phi})=\\sum\_{i=1}^{d\_{1}}\\hat{\\Gamma}(i,i)\\hat{\\Phi}(i,i)=\\sum\_{i=k+1}^{d\_{1}}\\hat{\\Gamma}(i,i)\\hat{\\Phi}(i,i)\\leq V. |     |

In other words, if Î“^â€‹(i,i)\=0\\hat{\\Gamma}(i,i)=0, then there is no constraint on Î¦^â€‹(i,i)\\hat{\\Phi}(i,i). We thus can make Câ€‹(V)C(V) unbounded by choosing Î¦^â€‹(i,i)\=âˆ\\hat{\\Phi}(i,i)=\\infty. Once this occurs, the values of Î¦^â€‹(i,i)\\hat{\\Phi}(i,i) for i\>ki>k become non-essential, as the capacity is already infinite. Nevertheless, for completeness and consistency, these remaining values can still be selected according to the water-filling principle. The only difference is that Î±\\alpha is now chosen to satisfy

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | âˆ‘i\=k+1d1maxâ¡(Î±âˆ’Î»iâ€‹Î“^â€‹(i,i),0)\=V.\\displaystyle\\sum\_{i=k+1}^{d\_{1}}\\max\\left({\\alpha}-{\\lambda\_{i}}{\\hat{\\Gamma}(i,i)},0\\right)=V. |     |

This completes the achievability proof.

Report issue for preceding element

By restricting attention to linear input policies, the achievability proof is significantly simplified via the channel translation. In contrast, the converse proof is more involved, as general input policies may render the system neither linear nor Gaussian. Fortunately, it can be shown that the mutual information Iâ€‹(m;xn+1)I(m;x^{n+1}) is maximized by linear policies. On this basis, we prove the converse to the capacity theorem by Fanoâ€™s inequality. Please refer to Section [VII-A](https://arxiv.org/html/2509.16146v1#S7.SS1 "VII-A Converse Proof of Theorem 1 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") for the converse proof.

Report issue for preceding element

## V Noisy Observations at Receiver

Report issue for preceding element

In this section, we extend the implicit communication problem introduced in Section [III](https://arxiv.org/html/2509.16146v1#S3 "III System Model and Preliminaries â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") to a more general setting in which the receiver only has noisy observation of the system state. In particular, at each time tt, instead of directly observing the state xtx\_{t}, the receiver has access to an observation given by

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | zt\=Dâ€‹xt+vt,\\displaystyle z\_{t}=Dx\_{t}+v\_{t}, |     | (11) |

where vtâˆˆâ„d1v\_{t}\\in\\mathbb{R}^{d\_{1}} is zero-mean white Gaussian noise with covariance matrix Î¨vâ‰»0\\Psi\_{v}\\succ 0, and Dâˆˆâ„d1Ã—d1D\\in\\mathbb{R}^{d\_{1}\\times d\_{1}} is the observation matrix. We assume that {vt}\\{v\_{t}\\} is an i.i.d. process, independent of both the process noise {wt}\\{w\_{t}\\} and state sequence {xt}\\{x\_{t}\\}. Additionally, we assume DD is invertible and the pair (A,D)(A,D) is observable.

Report issue for preceding element

![Refer to caption](x2.png)

Figure 2: Implicit communication in LQG control systems with noisy observations at receiver.

Report issue for preceding element

As illustrated in Fig. [2](https://arxiv.org/html/2509.16146v1#S5.F2 "Figure 2 â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"), the system can still function as an implicit channel between the controller and receiver. The difference is that the receiver now decodes the message based on the noisy observation sequence zn+1z^{n+1}, rather than the state sequence xn+1x^{n+1}. Therefore, the decoding mapping is now given by

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | m^:ğ’µn+1â†’â„³,\\displaystyle\\hat{m}:\\mathcal{Z}^{n+1}\\to\\mathcal{M}, |     |

where ğ’µ\=â„d1\\mathcal{Z}=\\mathbb{R}^{d\_{1}}. The definitions of average probability of error, coding rate, and channel capacity remain the same as in Section [III](https://arxiv.org/html/2509.16146v1#S3 "III System Model and Preliminaries â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"). We denote the capacity of this implicit channel under a control constraint Jâ‰¤Jâˆ—+VJ\\leq J^{\*}+V by Cnorâ€‹(V)C\_{\\text{nor}}(V).

Report issue for preceding element

In the remainder of this section, we first present the implicit channel capacity, characterized as the solution to an optimization problem. Then we introduce the Kalman filter and smoother, which play a key role in the capacity analysis. On this basis, we provide the achievability proof, showing that under the capacity-achieving input policy, the implicit channel is equivalent to a Gaussian MIMO channel with memory. The converse proof is deferred to Section [VII-B](https://arxiv.org/html/2509.16146v1#S7.SS2 "VII-B Converse Proof of Theorem 3 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems").

Report issue for preceding element

### V-A Capacity

Report issue for preceding element

When both the controller and the receiver have noiseless observations, the receiverâ€™s next observation xt+1x\_{t+1} is conditionally independent of all the past observations and inputs given the current state xtx\_{t} and input utu\_{t}. This Markov property enables the implicit channel to be transformed into a memoryless Gaussian channel, where the output at time tt is a function of xt+1x\_{t+1} and xtx\_{t}. In contrast, when the receiver observes the state through noise, its observation sequence forms a hidden Markov process, and the implicit channel becomes one with memory. Consequently, the channel capacity no longer admits a closed-form expression. Instead, we can only characterize it as the solution to an optimization problem.

Report issue for preceding element

###### Theorem 3

Report issue for preceding element

For any Vâ‰¥0V\\geq 0, with noisy observations at the receiver, the capacity of the implicit channel under the control constraint Jâ‰¤Jâˆ—+VJ\\leq J^{\*}+V is given by the optimization problem

Report issue for preceding element

|     |     |     |     |     |
| --- | --- | --- | --- | --- |
|     | Cnorâ€‹(V):=maxÎ¦âª°0\\displaystyle C\_{\\text{nor}}(V):=\\max\_{\\Phi\\succeq 0}\\ | 12â€‹logâ€‹det(Î¨v+Dâ€‹Î£â€‹DâŠ¤)âˆ’12â€‹logâ€‹det(Î¨v+Dâ€‹Î¨Ïƒâ€‹DâŠ¤)\\displaystyle\\frac{1}{2}\\log{\\det(\\Psi\_{v}+D\\Sigma D^{\\top})}-\\frac{1}{2}\\log{\\det(\\Psi\_{v}+D\\Psi\_{\\sigma}D^{\\top})} |     | (12) |
|     | s.t. | Trâ€‹((Î“+G^)â€‹Î¦)â‰¤V\\displaystyle\\text{Tr}((\\Gamma+\\hat{G})\\Phi)\\leq V |     | (13) |
|     |     | Î£\=AÂ¯â€‹(Î£âˆ’Î£â€‹DâŠ¤â€‹(Dâ€‹Î£â€‹DâŠ¤+Î¨v)âˆ’1â€‹Dâ€‹Î£)â€‹AÂ¯âŠ¤+Î¨w+Î¦,\\displaystyle\\Sigma=\\bar{A}\\left(\\Sigma-\\Sigma D^{\\top}(D\\Sigma D^{\\top}+\\Psi\_{v})^{-1}D\\Sigma\\right)\\bar{A}^{\\top}+\\Psi\_{{w}}+\\Phi, |     | (14) |

where AÂ¯\=Aâˆ’Bâ€‹K\\bar{A}=A-BK and Î¨Ïƒ\\Psi\_{\\sigma} is determined by the discrete-time algebraic Riccati equation:

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Î¨Ïƒ\=AÂ¯â€‹(Î¨Ïƒâˆ’Î¨Ïƒâ€‹DâŠ¤â€‹(Dâ€‹Î¨Ïƒâ€‹DâŠ¤+Î¨v)âˆ’1â€‹Dâ€‹Î¨Ïƒ)â€‹AÂ¯+Î¨w.\\displaystyle\\Psi\_{\\sigma}=\\bar{A}(\\Psi\_{\\sigma}-\\Psi\_{\\sigma}D^{\\top}(D\\Psi\_{\\sigma}D^{\\top}+\\Psi\_{v})^{-1}D\\Psi\_{\\sigma})\\bar{A}+\\Psi\_{w}. |     |

The optimal input is ut\=âˆ’Kâ€‹xt+Bâ€ â€‹stu\_{t}=-Kx\_{t}+B^{\\dagger}s\_{t}, where KK is the optimal feedback gain defined in ([7](https://arxiv.org/html/2509.16146v1#S3.E7 "In III-A Linear Quadratic-Gaussian (LQG) Control Systems â€£ III System Model and Preliminaries â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) and stâˆ¼ğ’©â€‹(0,Î¦âˆ—)s\_{t}\\sim\\mathcal{N}(0,\\Phi^{\*}) is independent of {wi}\\{w\_{i}\\}, {vi}\\{v\_{i}\\} and {xi}\\{x\_{i}\\}, with Î¦âˆ—\\Phi^{\*} being the optimal solution to the above optimization problem.

Report issue for preceding element

Theorem [3](https://arxiv.org/html/2509.16146v1#Thmtheorem3 "Theorem 3 â€£ V-A Capacity â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") shows that the capacity-achieving input policy in this setting remains linear and that the separation principle continues to hold. However, designing the channel code (i.e., the communication signal sts\_{t}) becomes more involved due to the presence of memory in the channel. In the achievability proof, we will show that under the optimal input policy, the implicit channel becomes a Gaussian channel of the form yÂ¯t\=Dâ€‹st+Îºt\\bar{y}\_{t}=Ds\_{t}+\\kappa\_{t}, where the noise process {Îºt}\\{\\kappa\_{t}\\} is a hidden Markov process.

Report issue for preceding element

Under the optimal input policy, the system state evolves linearly, enabling the receiver to estimate the state from its noisy observations using Kalman filter. The output yÂ¯t\\bar{y}\_{t} of the equivalent Gaussian channel is a function of the Kalman filterâ€™s estimate of state, ğ”¼â€‹\[xt+1|zt+1\]\\mathbb{E}\[x\_{t+1}|z^{t+1}\]. As will be elaborated in the following sections, Î£\\Sigma is the stabilizing estimation error covariance of ğ”¼â€‹\[xt+1|zt\]\\mathbb{E}\[x\_{t+1}|z^{t}\], as defined in ([16](https://arxiv.org/html/2509.16146v1#S5.E16 "In V-B Kalman Filter and Smoother â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), while Î¨Ïƒ\\Psi\_{\\sigma} is the corresponding estimation error covariance when the communication signal {st}\\{s\_{t}\\} is also available, i.e., for the estimate ğ”¼â€‹\[xt+1|zt,st\]\\mathbb{E}\[x\_{t+1}|z^{t},s^{t}\]. The objective function ([12](https://arxiv.org/html/2509.16146v1#S5.E12 "In Theorem 3 â€£ V-A Capacity â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) represents a difference in entropy rates of the process {yÂ¯t}\\{\\bar{y}\_{t}\\} with and without knowledge of the communication signal {st}\\{s\_{t}\\}. In the special case where the receiver has perfect state observations (i.e., D\=ID=I and Î¨v\=0\\Psi\_{v}=0), we have Î£\=Î¦+Î¨w\\Sigma=\\Phi+\\Psi\_{w} and Î¨Ïƒ\=Î¨w\\Psi\_{\\sigma}=\\Psi\_{w}. It is easy to verify that Cnorâ€‹(V)C\_{\\text{nor}}(V) in this case reduces to Câ€‹(V)C(V) presented in Theorem [1](https://arxiv.org/html/2509.16146v1#Thmtheorem1 "Theorem 1 â€£ IV-A Capacity â€£ IV Noiseless Observations at the Controller and the Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems").

Report issue for preceding element

The optimization problem in Theorem [3](https://arxiv.org/html/2509.16146v1#Thmtheorem3 "Theorem 3 â€£ V-A Capacity â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") appears difficult to solve, making capacity computation seemingly difficult. Fortunately, using the Schur complement, the problem can be reformulated as a convex optimization problem, which can be efficiently solved using standard methods \[[46](https://arxiv.org/html/2509.16146v1#bib.bib46), [47](https://arxiv.org/html/2509.16146v1#bib.bib47)\].

Report issue for preceding element

###### Proposition 1

Report issue for preceding element

For any Vâ‰¥0V\\geq 0, with noisy observations at the receiver, the capacity of the implicit channel under constraint Jâ‰¤Jâˆ—+VJ\\leq J^{\*}+V is given by the optimization problem

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Cnorâ€‹(V):=maxÎ¦,Î£\\displaystyle C\_{\\text{nor}}(V):=\\max\_{\\Phi,\\Sigma}\\ | 12â€‹logâ€‹det(Î¨v+Dâ€‹Î£â€‹DâŠ¤)âˆ’12â€‹logâ€‹det(Î¨v+Dâ€‹Î¨Ïƒâ€‹DâŠ¤)\\displaystyle\\frac{1}{2}\\log{\\det(\\Psi\_{v}+D\\Sigma D^{\\top})}-\\frac{1}{2}\\log{\\det(\\Psi\_{v}+D\\Psi\_{\\sigma}D^{\\top})} |     |
|     | s.t. | Trâ€‹((Î“+G^)â€‹Î¦)â‰¤V\\displaystyle\\text{Tr}((\\Gamma+\\hat{G})\\Phi)\\leq V |     |
|     |     | \[Dâ€‹Î£â€‹DâŠ¤+Î¨vDâ€‹Î£â€‹AÂ¯âŠ¤AÂ¯â€‹Î£â€‹DâŠ¤AÂ¯â€‹Î£â€‹AÂ¯âŠ¤+Î¨w+Î¦âˆ’Î£\]âª°0\\displaystyle\\begin{bmatrix}D\\Sigma D^{\\top}+\\Psi\_{v}&D\\Sigma\\bar{A}^{\\top}\\\\ \\bar{A}\\Sigma D^{\\top}&\\bar{A}\\Sigma\\bar{A}^{\\top}+\\Psi\_{w}+\\Phi-\\Sigma\\end{bmatrix}\\succeq 0 |     |
|     |     | Î£âª°0,Î¦âª°0.\\displaystyle\\Sigma\\succeq 0,\\Phi\\succeq 0. |     |

where Î¨Ïƒ\\Psi\_{\\sigma} is define in Theorem [3](https://arxiv.org/html/2509.16146v1#Thmtheorem3 "Theorem 3 â€£ V-A Capacity â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems").

Report issue for preceding element

###### Proof:

Report issue for preceding element

See Appendix. âˆ

Report issue for preceding element

To verify that the problem is a convex optimization \[[48](https://arxiv.org/html/2509.16146v1#bib.bib48)\], note that: (i) the second term of the objective is a constant and does not depend on the decision variables; (ii) the function logâ€‹det(â‹…)\\log\\det(\\cdot) is concave; (iii) all constraints are linear.

Report issue for preceding element

### V-B Kalman Filter and Smoother

Report issue for preceding element

Before presenting the achievability proof, we first introduce the Kalman filter and smoother, and define the associated matrices. They play a key role in constructing the equivalent Gaussian channel under the optimal input policy.

Report issue for preceding element

Consider the linear system ([1](https://arxiv.org/html/2509.16146v1#S3.E1 "In III-A Linear Quadratic-Gaussian (LQG) Control Systems â€£ III System Model and Preliminaries â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) and the observation process ([11](https://arxiv.org/html/2509.16146v1#S5.E11 "In V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")). To facilitate the introduction of the Kalman filter and smoother, we assume the input policy takes the form ut\=âˆ’Kâ€‹xt+Bâ€ â€‹stu\_{t}=-Kx\_{t}+B^{\\dagger}s\_{t}, where stâˆ¼ğ’©â€‹(0,Î¦)s\_{t}\\sim\\mathcal{N}(0,\\Phi) is independent of xt,wtx\_{t},w\_{t}, and vtv\_{t}. Under this policy, the system state evolves as follows:

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | xt+1\=AÂ¯â€‹xt+st+wt.\\displaystyle x\_{t+1}=\\bar{A}x\_{t}+s\_{t}+{w}\_{t}. |     |

Suppose that the receiver needs to estimate xtx\_{t} based on the observation sequence zkz^{k}. The optimal unbiased estimator in the minimum mean-square error (MMSE) sense is given by

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | x^t\|kâ‰œğ”¼â€‹\[xt\|zk\],\\displaystyle\\hat{x}\_{t\|k}\\triangleq\\mathbb{E}\[x\_{t}\|z^{k}\], |     |

with the corresponding estimation error covariance defined as Î£t|kâ‰œCovâ€‹(xtâˆ’x^t|k)\\Sigma\_{t|k}\\triangleq\\text{Cov}(x\_{t}-\\hat{x}\_{t|k}). The problem is referred to as the filtering problem when k\=tk=t and the smoothing problem when k\>tk>t. It is well-known that the Kalman filter \[[49](https://arxiv.org/html/2509.16146v1#bib.bib49)\] is the optimal solution to the filtering problem. Specifically, the Kalman filter consists of a prediction stage and a update stage. In the prediction stage, the filter computes a prediction of the state and its associated error covariance:

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | x^t+1\|t\\displaystyle\\hat{x}\_{t+1\|t} | \=AÂ¯â€‹x^t\|t,\\displaystyle=\\bar{A}\\hat{x}\_{t\|t}, |     |
|     | Î£t+1\|t\\displaystyle\\Sigma\_{t+1\|t} | \=AÂ¯â€‹Î£t\|tâ€‹AÂ¯âŠ¤+Î¦+Î¨w.\\displaystyle=\\bar{A}\\Sigma\_{t\|t}\\bar{A}^{\\top}+\\Phi+\\Psi\_{{w}}. |     |

Upon receiving the new observation zt+1z\_{t+1}, the state estimate is updated as:

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | x^t+1\|t+1\=x^t+1\|t+Lt+1â€‹(zt+1âˆ’Dâ€‹x^t+1\|t),\\displaystyle\\hat{x}\_{t+1\|t+1}=\\hat{x}\_{t+1\|t}+L\_{t+1}(z\_{t+1}-D\\hat{x}\_{t+1\|t}), |     | (15) |

where Lt+1L\_{t+1} is the filter gain given by

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Lt+1\=Î£t+1\|tâ€‹DâŠ¤â€‹(Dâ€‹Î£t+1\|tâ€‹DâŠ¤+Î¨v)âˆ’1.\\displaystyle L\_{t+1}=\\Sigma\_{t+1\|t}D^{\\top}\\left(D\\Sigma\_{t+1\|t}D^{\\top}+\\Psi\_{v}\\right)^{-1}. |     |

The estimate error covariance of x^t+1|t+1\\hat{x}\_{t+1|t+1} is then given by

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Î£t+1\|t+1\=(Iâˆ’Lt+1â€‹D)â€‹Î£t+1\|t.\\displaystyle\\Sigma\_{t+1\|t+1}=(I-L\_{t+1}D)\\Sigma\_{t+1\|t}. |     |

Since the LQG control system is controllable and observable, and KK is the optimal feedback gain, the matrix AÂ¯\=Aâˆ’Bâ€‹K\\bar{A}=A-BK must be stable. Consequently, it is a well-established result that both Î£t|t\\Sigma\_{t|t} and LtL\_{t} converge. In particular, Î£t+1|tâ†’Î£\\Sigma\_{t+1|t}\\to\\Sigma as tâ†’âˆt\\to\\infty, where Î£\\Sigma is the solution to the following discrete Riccati equation (see, e.g., \[[50](https://arxiv.org/html/2509.16146v1#bib.bib50)\]):

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Î£\=AÂ¯â€‹(Î£âˆ’Î£â€‹DâŠ¤â€‹(Dâ€‹Î£â€‹DâŠ¤+Î¨v)âˆ’1â€‹Dâ€‹Î£)â€‹AÂ¯âŠ¤+Î¦+Î¨w,\\displaystyle\\Sigma=\\bar{A}\\left(\\Sigma-\\Sigma D^{\\top}(D\\Sigma D^{\\top}+\\Psi\_{v})^{-1}D\\Sigma\\right)\\bar{A}^{\\top}+\\Phi+\\Psi\_{{w}}, |     | (16) |

and accordingly,

Report issue for preceding element

|     |     |     |     |     |
| --- | --- | --- | --- | --- |
|     |     | Lâ‰œlimtâ†’âˆLt\=Î£â€‹DâŠ¤â€‹(Dâ€‹Î£â€‹DâŠ¤+Î¨v)âˆ’1,\\displaystyle L\\triangleq\\lim\_{t\\to\\infty}L\_{t}=\\Sigma D^{\\top}\\left(D\\Sigma D^{\\top}+\\Psi\_{v}\\right)^{-1}, |     | (17) |
|     |     | Î£~â‰œlimtâ†’âˆÎ£t\|t\=(Iâˆ’Lâ€‹D)â€‹Î£.\\displaystyle\\tilde{\\Sigma}\\triangleq\\lim\_{t\\to\\infty}\\Sigma\_{t\|t}=(I-LD)\\Sigma. |     | (18) |

We are also interested in the smoothing problem with k\=t+1k=t+1. This problem can be solved by the Kalman smoother (also known as the Rauch-Tung-Striebel smoother \[[51](https://arxiv.org/html/2509.16146v1#bib.bib51)\]), which computes

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | x^t\|t+1\=x^t\|t+Qtâ€‹(x^t+1\|t+1âˆ’AÂ¯â€‹x^t\|t),\\displaystyle\\hat{x}\_{t\|t+1}=\\hat{x}\_{t\|t}+Q\_{t}\\left(\\hat{x}\_{t+1\|t+1}-\\bar{A}\\hat{x}\_{t\|t}\\right), |     | (19) |

where the smoother gain Qt\=Î£t|tâ€‹AÂ¯âŠ¤â€‹Î£t+1|tâˆ’1Q\_{t}=\\Sigma\_{t|t}\\bar{A}^{\\top}\\Sigma\_{t+1|t}^{-1}. The smoothed error covariance matrix is given by

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Î£t\|t+1\=Î£t\|t+Qtâ€‹(Î£t+1\|t+1âˆ’Î£t+1\|t)â€‹QtâŠ¤.\\displaystyle\\Sigma\_{t\|t+1}=\\Sigma\_{t\|t}+Q\_{t}\\left(\\Sigma\_{t+1\|t+1}-\\Sigma\_{t+1\|t}\\right)Q\_{t}^{\\top}. |     |

Since Î£t+1|t\\Sigma\_{t+1|t} and Î£t|t\\Sigma\_{t|t} converge, it is clear that QtQ\_{t} and Î£t|t+1\\Sigma\_{t|t+1} also converge as tâ†’âˆt\\to\\infty:

Report issue for preceding element

|     |     |     |     |     |
| --- | --- | --- | --- | --- |
|     |     | Qâ‰œlimtâ†’âˆQt\=(Iâˆ’Lâ€‹D)â€‹Î£â€‹AÂ¯âŠ¤â€‹Î£âˆ’1,\\displaystyle Q\\triangleq\\lim\_{t\\to\\infty}Q\_{t}=(I-LD)\\Sigma\\bar{A}^{\\top}\\Sigma^{-1}, |     | (20) |
|     |     | Î£^â‰œlimtâ†’âˆÎ£t\|t+1\=(Iâˆ’Lâ€‹D)â€‹Î£âˆ’Qâ€‹Lâ€‹Dâ€‹Î£â€‹QâŠ¤.\\displaystyle\\hat{\\Sigma}\\triangleq\\lim\_{t\\to\\infty}\\Sigma\_{t\|t+1}=(I-LD)\\Sigma-QLD\\Sigma Q^{\\top}. |     | (21) |

Now we are ready to present the achievability proof.

Report issue for preceding element

### V-C Achievability Proof

Report issue for preceding element

This section presents the achievability proof for Theorem [3](https://arxiv.org/html/2509.16146v1#Thmtheorem3 "Theorem 3 â€£ V-A Capacity â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"). As in Section [IV](https://arxiv.org/html/2509.16146v1#S4 "IV Noiseless Observations at the Controller and the Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"), we show that the capacity Cnorâ€‹(V)C\_{\\text{nor}}(V) can be achieved by input ut\=âˆ’Kâ€‹xt+Bâ€ â€‹stu\_{t}=-Kx\_{t}+B^{\\dagger}s\_{t}, where stâˆ¼ğ’©â€‹(0,Î¦)s\_{t}\\sim\\mathcal{N}(0,\\Phi) is independent of xtx\_{t} and wtw\_{t}. Recall that AÂ¯\=Aâˆ’Bâ€‹K\\bar{A}=A-BK, and under this policy:

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | xt+1\=AÂ¯â€‹xt+st+wt.\\displaystyle x\_{t+1}=\\bar{A}x\_{t}+s\_{t}+w\_{t}. |     |

Let ytâ‰œxt+1âˆ’AÂ¯â€‹xty\_{t}\\triangleq x\_{t+1}-\\bar{A}x\_{t}. At the end of time step tt (i.e., the beginning of time step t+1t+1 in continuous time), the receiver observes zt+1z^{t+1} and uses it to estimate yty\_{t}. From an estimation perspective, sts\_{t} can be viewed as an extra noise. Then the optimal estimator is given as follows:

Report issue for preceding element

|     |     |     |     |     |
| --- | --- | --- | --- | --- |
|     | y^t\\displaystyle\\hat{y}\_{t} | â‰œğ”¼â€‹\[xt+1âˆ’AÂ¯â€‹xt\|zt+1\]\\displaystyle\\triangleq\\mathbb{E}\[x\_{t+1}-\\bar{A}x\_{t}\|z^{t+1}\] |     |
|     |     | \=x^t+1\|t+1âˆ’AÂ¯â€‹x^t\|t+1\\displaystyle=\\hat{x}\_{t+1\|t+1}-\\bar{A}\\hat{x}\_{t\|t+1} |     |
|     |     | \=(Iâˆ’AÂ¯â€‹Q)â€‹Lâ€‹(zt+1âˆ’Dâ€‹AÂ¯â€‹x^t\|t).\\displaystyle=(I-\\bar{A}Q)L(z\_{t+1}-D\\bar{A}\\hat{x}\_{t\|t}). |     | (22) |

As defined in ([15](https://arxiv.org/html/2509.16146v1#S5.E15 "In V-B Kalman Filter and Smoother â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) and ([19](https://arxiv.org/html/2509.16146v1#S5.E19 "In V-B Kalman Filter and Smoother â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), x^t+1|t+1\\hat{x}\_{t+1|t+1} and x^t|t+1\\hat{x}\_{t|t+1} are the outcomes of Kalman filter and smoother, respectively. Under this definition, the receiver can construct an equivalent channel by treating y^t\\hat{y}\_{t} as the channel output, with the input-output relationship characterized in the following lemma:

Report issue for preceding element

###### Lemma 3

Report issue for preceding element

Let Ïƒtâ‰œxtâˆ’x^t|t\\sigma\_{t}\\triangleq x\_{t}-\\hat{x}\_{t|t} denote the estimation error of the Kalman filter. Then {Ïƒt:tâ‰¥1}\\{\\sigma\_{t}:t\\geq 1\\} forms a Markov chain that evolves according to

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Ïƒt+1\=(Iâˆ’Lâ€‹D)â€‹AÂ¯â€‹Ïƒtâˆ’Lâ€‹vt+1+(Iâˆ’Lâ€‹D)â€‹(st+wt).\\displaystyle\\sigma\_{t+1}=(I-LD)\\bar{A}\\sigma\_{t}-Lv\_{t+1}+(I-LD)(s\_{t}+w\_{t}). |     | (23) |

Moreover, for any tâ‰¥1t\\geq 1,

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | y^t\=(Iâˆ’AÂ¯â€‹Q)â€‹Lâ€‹\[Dâ€‹st+vt+1+Dâ€‹wt+Dâ€‹AÂ¯â€‹Ïƒt\],\\displaystyle\\hat{y}\_{t}=(I-\\bar{A}Q)L\[Ds\_{t}+v\_{t+1}+Dw\_{t}+D\\bar{A}\\sigma\_{t}\], |     |

where LL is the stabilizing Kalman filter gain defined in ([17](https://arxiv.org/html/2509.16146v1#S5.E17 "In V-B Kalman Filter and Smoother â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), and QQ is the stabilizing Kalman smoother gain defined in ([20](https://arxiv.org/html/2509.16146v1#S5.E20 "In V-B Kalman Filter and Smoother â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")).

Report issue for preceding element

Lemma [3](https://arxiv.org/html/2509.16146v1#Thmlemma3 "Lemma 3 â€£ V-C Achievability Proof â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") shows that, under the input policy ut\=âˆ’Kâ€‹xt+Bâ€ â€‹stu\_{t}=-Kx\_{t}+B^{\\dagger}s\_{t}, we can translate the implicit channel to a Gaussian channel with memory. This channel can be further simplified by observing that (Iâˆ’AÂ¯â€‹Q)â€‹L(I-\\bar{A}Q)L is invertible. First note that DD and Î£\\Sigma are invertible, hence L\=Î£â€‹DâŠ¤â€‹(Dâ€‹Î£â€‹DâŠ¤+Î¨v)âˆ’1L=\\Sigma D^{\\top}\\left(D\\Sigma D^{\\top}+\\Psi\_{v}\\right)^{-1} is also invertible. In addition, Iâˆ’AÂ¯â€‹QI-\\bar{A}Q is invertible because

Report issue for preceding element

|     |     |     |     |     |
| --- | --- | --- | --- | --- |
|     | Iâˆ’AÂ¯â€‹Q\\displaystyle I-\\bar{A}Q | \=Iâˆ’AÂ¯â€‹(Iâˆ’Lâ€‹D)â€‹Î£â€‹AÂ¯âŠ¤â€‹Î£âˆ’1\\displaystyle=I-\\bar{A}(I-LD)\\Sigma\\bar{A}^{\\top}\\Sigma^{-1} |     |
|     |     | \=Iâˆ’(Î£âˆ’Î¨w)â€‹Î£âˆ’1\=Î¨wâ€‹Î£âˆ’1.\\displaystyle=I-(\\Sigma-\\Psi\_{w})\\Sigma^{-1}=\\Psi\_{w}\\Sigma^{-1}. |     | (24) |

As a result, we obtain a Gaussian MIMO channel that is equivalent to the implicit channel:

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | yÂ¯tâ‰œ\[(Iâˆ’AÂ¯â€‹Q)â€‹L\]âˆ’1â€‹y^t\=Dâ€‹st+Îºt,\\displaystyle\\bar{y}\_{t}\\triangleq\[(I-\\bar{A}Q)L\]^{-1}\\hat{y}\_{t}=Ds\_{t}+\\kappa\_{t}, |     | (25) |

where Îºtâ‰œ(Dâ€‹wt+vt+1+Dâ€‹AÂ¯â€‹Ïƒt)\\kappa\_{t}\\triangleq(Dw\_{t}+v\_{t+1}+D\\bar{A}\\sigma\_{t}). Since {Ïƒt}\\{\\sigma\_{t}\\} is a Markov process, {Îºt}\\{\\kappa\_{t}\\} forms a hidden Markov process.

Report issue for preceding element

Before proceeding to compute the capacity of the above channel, we show that this translation does not loss any information about sns^{n}: Iâ€‹(sn;yÂ¯n)\=Iâ€‹(sn;zn+1)I(s^{n};\\bar{y}^{n})=I(s^{n};z^{n+1}). To see this, applying the chain rule of mutual information yields

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Iâ€‹(sn;zn+1,yÂ¯n)\=Iâ€‹(sn;yÂ¯n)+Iâ€‹(sn;zn+1\|yÂ¯n)\=Iâ€‹(sn;zn+1)+Iâ€‹(sn;yÂ¯n\|zn+1).\\displaystyle I(s^{n};z^{n+1},\\bar{y}^{n})=I(s^{n};\\bar{y}^{n})+I(s^{n};z^{n+1}\|\\bar{y}^{n})=I(s^{n};z^{n+1})+I(s^{n};\\bar{y}^{n}\|z^{n+1}). |     |

By definition, yÂ¯n\\bar{y}^{n} is a function of zn+1z^{n+1}, we thus have Iâ€‹(sn;yÂ¯n|zn+1)\=0I(s^{n};\\bar{y}^{n}|z^{n+1})=0. Furthermore, since (Iâˆ’AÂ¯â€‹Q)â€‹L(I-\\bar{A}Q)L is invertible, ([V-C](https://arxiv.org/html/2509.16146v1#S5.Ex32 "V-C Achievability Proof â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) implies that zt+1z\_{t+1} can be determined by yÂ¯t\\bar{y}\_{t} and ztz^{t}â€”as x^t|t\\hat{x}\_{t|t} is a function of ztz^{t}. Using this fact and the chain rule yields

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Iâ€‹(sn;zn+1\|yÂ¯n)\=Iâ€‹(sn;z1\|yÂ¯n)+âˆ‘t\=1nIâ€‹(sn;zt+1\|zt,yÂ¯n)\=0.\\displaystyle I(s^{n};z^{n+1}\|\\bar{y}^{n})=I(s^{n};z\_{1}\|\\bar{y}^{n})+\\sum\_{t=1}^{n}I(s^{n};z\_{t+1}\|z^{t},\\bar{y}^{n})=0. |     | (26) |

We thus have

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Iâ€‹(sn;zn+1,yÂ¯n)\=Iâ€‹(sn;yÂ¯n)\=Iâ€‹(sn;zn+1).\\displaystyle I(s^{n};z^{n+1},\\bar{y}^{n})=I(s^{n};\\bar{y}^{n})=I(s^{n};z^{n+1}). |     |

The capacity of the channel ([25](https://arxiv.org/html/2509.16146v1#S5.E25 "In V-C Achievability Proof â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) admits a well-known expression as follows:

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | C\=maxpâ€‹(sn)â€‹limnâ†’âˆ1nâ€‹Iâ€‹(sn;yÂ¯n),\\displaystyle C=\\max\_{p(s^{n})}\\lim\_{n\\to\\infty}\\frac{1}{n}I(s^{n};\\bar{y}^{n}), |     |

subject to the power constraint. Now,

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | 1nâ€‹Iâ€‹(sn;yÂ¯n)\=1nâ€‹Iâ€‹(sn;yÂ¯n,zn+1)\\displaystyle\\frac{1}{n}I(s^{n};\\bar{y}^{n})=\\frac{1}{n}I(s^{n};\\bar{y}^{n},z^{n+1}) | \=1nâ€‹\[hâ€‹(yÂ¯n,zn+1)âˆ’hâ€‹(yÂ¯n,zn+1\|sn)\]\\displaystyle=\\frac{1}{n}\[h(\\bar{y}^{n},z^{n+1})-h(\\bar{y}^{n},z^{n+1}\|s^{n})\] |     |
|     |     | \=1nâ€‹âˆ‘t\=1n\[hâ€‹(yÂ¯t,zt+1\|yÂ¯tâˆ’1,zt)âˆ’hâ€‹(yÂ¯t,zt+1\|yÂ¯tâˆ’1,zt,sn)\]\\displaystyle=\\frac{1}{n}\\sum\_{t=1}^{n}\\left\[h(\\bar{y}\_{t},z\_{t+1}\|\\bar{y}^{t-1},z^{t})-h(\\bar{y}\_{t},z\_{t+1}\|\\bar{y}^{t-1},z^{t},s^{n})\\right\] |     |
|     |     | \=1nâ€‹âˆ‘t\=1n\[hâ€‹(yÂ¯t\|zt)âˆ’hâ€‹(yÂ¯t\|zt,sn)\]\\displaystyle=\\frac{1}{n}\\sum\_{t=1}^{n}\\left\[h(\\bar{y}\_{t}\|z^{t})-h(\\bar{y}\_{t}\|z^{t},s^{n})\\right\] |     |
|     |     | \=1nâ€‹âˆ‘t\=1n\[hâ€‹(yÂ¯t\|zt)âˆ’hâ€‹(Îºt\|zt,sn)\].\\displaystyle=\\frac{1}{n}\\sum\_{t=1}^{n}\\left\[h(\\bar{y}\_{t}\|z^{t})-h({\\kappa}\_{t}\|z^{t},s^{n})\\right\]. |     |

Since the system is linear Gaussian, all the random variables are joint Gaussian, we thus have

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | hâ€‹(yÂ¯t\|zt)âˆ’hâ€‹(Îºt\|zt,sn)\=12â€‹logâ€‹det(Covâ€‹(yÂ¯tâˆ’y~t))âˆ’12â€‹logâ€‹det(Covâ€‹(Îºtâˆ’Îº~t)),\\displaystyle h(\\bar{y}\_{t}\|z^{t})-h({\\kappa}\_{t}\|z^{t},s^{n})=\\frac{1}{2}\\log\\det({\\text{Cov}}(\\bar{y}\_{t}-{\\tilde{y}}\_{t}))-\\frac{1}{2}\\log\\det({\\text{Cov}}({\\kappa}\_{t}-{\\tilde{\\kappa}}\_{t})), |     |

where y~tâ‰œğ”¼â€‹\[yÂ¯t|zt\]\\tilde{y}\_{t}\\triangleq\\mathbb{E}\[\\bar{y}\_{t}|z^{t}\] and Îº~tâ‰œğ”¼â€‹\[Îºt|zt,sn\]\=ğ”¼â€‹\[Îºt|zt,stâˆ’1\]\\tilde{\\kappa}\_{t}\\triangleq\\mathbb{E}\[{\\kappa}\_{t}|z^{t},s^{n}\]=\\mathbb{E}\[{\\kappa}\_{t}|z^{t},s^{t-1}\]. First, since x^t|t\=ğ”¼â€‹\[xt|zt\]\\hat{x}\_{t|t}=\\mathbb{E}\[x\_{t}|z^{t}\] is a function of ztz^{t}, we have

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | yÂ¯tâ‰œğ”¼â€‹\[yÂ¯t\|zt\]\\displaystyle\\bar{y}\_{t}\\triangleq\\mathbb{E}\[\\bar{y}\_{t}\|z^{t}\] | \=ğ”¼â€‹\[Dâ€‹st+vt+1+Dâ€‹wt+Dâ€‹AÂ¯â€‹Ïƒt\|zt\]\\displaystyle=\\mathbb{E}\[Ds\_{t}+v\_{t+1}+Dw\_{t}+D\\bar{A}\\sigma\_{t}\|z^{t}\] |     |
|     |     | \=Dâ€‹AÂ¯â€‹ğ”¼â€‹\[xtâˆ’x^t\|t\|zt\]\=0.\\displaystyle=D\\bar{A}\\mathbb{E}\[x\_{t}-\\hat{x}\_{t\|t}\|z^{t}\]=0. |     |

Since yÂ¯tâˆ’1\\bar{y}^{t-1} and Ïƒt\\sigma\_{t} are independent of Dâ€‹st+Dâ€‹wt+vt+1Ds\_{t}+Dw\_{t}+v\_{t+1} (they are correlated only with stâˆ’1,wtâˆ’1s^{t-1},w^{t-1} and vtv^{t}),

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Covâ€‹(yÂ¯tâˆ’y~t)\\displaystyle{\\text{Cov}}(\\bar{y}\_{t}-{\\tilde{y}}\_{t}) | \=Covâ€‹(Dâ€‹st+vt+1+Dâ€‹wt+Dâ€‹AÂ¯â€‹Ïƒt)\\displaystyle={\\text{Cov}}(Ds\_{t}+v\_{t+1}+Dw\_{t}+D\\bar{A}\\sigma\_{t}) |     |
|     |     | \=Dâ€‹(Î¦+Î¨w+AÂ¯â€‹Î£~â€‹AÂ¯âŠ¤)â€‹DâŠ¤+Î¨v\\displaystyle=D(\\Phi+\\Psi\_{w}+\\bar{A}\\tilde{\\Sigma}\\bar{A}^{\\top})D^{\\top}+\\Psi\_{v} |     |
|     |     | \=Dâ€‹Î£â€‹DâŠ¤+Î¨v.\\displaystyle=D\\Sigma D^{\\top}+\\Psi\_{v}. |     |

The last line follows from the identity in Kalman filter: Î£\=AÂ¯â€‹Î£~â€‹AÂ¯âŠ¤+Î¨w+Î¦\\Sigma=\\bar{A}\\tilde{\\Sigma}\\bar{A}^{\\top}+\\Psi\_{{w}}+\\Phi.

Report issue for preceding element

Similarly,

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Îº~tâ‰œğ”¼â€‹\[Îºt\|sn,zt\]\\displaystyle\\tilde{\\kappa}\_{t}\\triangleq\\mathbb{E}\[{\\kappa}\_{t}\|s^{n},z^{t}\] | \=ğ”¼â€‹\[vt+1+Dâ€‹wt+Dâ€‹AÂ¯â€‹Ïƒt\|stâˆ’1,zt\]\\displaystyle=\\mathbb{E}\[v\_{t+1}+Dw\_{t}+D\\bar{A}\\sigma\_{t}\|s^{t-1},z^{t}\] |     |
|     |     | \=Dâ€‹AÂ¯â€‹ğ”¼â€‹\[Ïƒt\|stâˆ’1,zt\]\\displaystyle=D\\bar{A}\\mathbb{E}\[\\sigma\_{t}\|s^{t-1},z^{t}\] |     |
|     |     | \=Dâ€‹AÂ¯â€‹(ğ”¼â€‹\[xt\|stâˆ’1,zt\]âˆ’x^t\|t).\\displaystyle=D\\bar{A}(\\mathbb{E}\[x\_{t}\|s^{t-1},z^{t}\]-\\hat{x}\_{t\|t}). |     |

Let xÂ¯t|t\=ğ”¼â€‹\[xt|stâˆ’1,zt\]\\bar{x}\_{t|t}=\\mathbb{E}\[x\_{t}|s^{t-1},z^{t}\] and ÏƒÂ¯t\=xtâˆ’xÂ¯t|t\\bar{\\sigma}\_{t}=x\_{t}-\\bar{x}\_{t|t}, we then have

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Covâ€‹(Îºtâˆ’Îº~t)\\displaystyle{\\text{Cov}}({\\kappa}\_{t}-{\\tilde{\\kappa}}\_{t}) | \=Covâ€‹(vt+1+Dâ€‹wt+Dâ€‹AÂ¯â€‹(xtâˆ’x^t\|tâˆ’xÂ¯t\|t+x^t\|t))\\displaystyle={\\text{Cov}}(v\_{t+1}+Dw\_{t}+D\\bar{A}(x\_{t}-\\hat{x}\_{t\|t}-\\bar{x}\_{t\|t}+\\hat{x}\_{t\|t})) |     |
|     |     | \=Dâ€‹(Î¨w+AÂ¯â€‹Covâ€‹(ÏƒÂ¯t)â€‹AÂ¯âŠ¤)â€‹DâŠ¤+Î¨v.\\displaystyle=D(\\Psi\_{w}+\\bar{A}{\\text{Cov}}(\\bar{\\sigma}\_{t})\\bar{A}^{\\top})D^{\\top}+\\Psi\_{v}. |     |

Note that xÂ¯t|t\\bar{x}\_{t|t} can be computed using the standard Kalman filter, with knowledge of the past input sequence stâˆ’1s^{t-1}. Consequently, we can easily verify that Covâ€‹(ÏƒÂ¯t){\\text{Cov}}(\\bar{\\sigma}\_{t}) converges to Î¨~Ïƒ\\tilde{\\Psi}\_{\\sigma} as tâ†’âˆt\\to\\infty, where

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Î¨~Ïƒ\=Î¨Ïƒâˆ’Î¨Ïƒâ€‹DâŠ¤â€‹(Dâ€‹Î¨Ïƒâ€‹DâŠ¤+Î¨v)âˆ’1â€‹Dâ€‹Î¨Ïƒ,\\displaystyle\\tilde{\\Psi}\_{\\sigma}=\\Psi\_{\\sigma}-\\Psi\_{\\sigma}D^{\\top}(D\\Psi\_{\\sigma}D^{\\top}+\\Psi\_{v})^{-1}D\\Psi\_{\\sigma}, |     | (27) |

and Î¨Ïƒ\\Psi\_{\\sigma} is determined by the following discrete Riccati equation:

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Î¨Ïƒ\=AÂ¯â€‹(Î¨Ïƒâˆ’Î¨Ïƒâ€‹DâŠ¤â€‹(Dâ€‹Î¨Ïƒâ€‹DâŠ¤+Î¨v)âˆ’1â€‹Dâ€‹Î¨Ïƒ)â€‹AÂ¯+Î¨w.\\displaystyle\\Psi\_{\\sigma}=\\bar{A}(\\Psi\_{\\sigma}-\\Psi\_{\\sigma}D^{\\top}(D\\Psi\_{\\sigma}D^{\\top}+\\Psi\_{v})^{-1}D\\Psi\_{\\sigma})\\bar{A}+\\Psi\_{w}. |     | (28) |

In addition, the following identity holds: Î¨Ïƒ\=AÂ¯â€‹Î¨~Ïƒâ€‹AÂ¯âŠ¤+Î¨w\\Psi\_{\\sigma}=\\bar{A}\\tilde{\\Psi}\_{\\sigma}\\bar{A}^{\\top}+\\Psi\_{w}. We thus have

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Covâ€‹(Îºtâˆ’Îº~t)â†’Dâ€‹Î¨Ïƒâ€‹DâŠ¤+Î¨vâ€‹Â asÂ â€‹tâ†’âˆ.\\displaystyle{\\text{Cov}}({\\kappa}\_{t}-{\\tilde{\\kappa}}\_{t})\\to D\\Psi\_{\\sigma}D^{\\top}+\\Psi\_{v}\\text{ as }t\\to\\infty. |     |

Combining the above discussions yields

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | limnâ†’âˆ1nâ€‹Iâ€‹(sn;yÂ¯n)\=12â€‹logâ¡det(Î¨v+Dâ€‹Î£â€‹DâŠ¤)det(Î¨v+Dâ€‹Î¨Ïƒâ€‹DâŠ¤).\\displaystyle\\lim\\limits\_{n\\to\\infty}\\frac{1}{n}I(s^{n};\\bar{y}^{n})=\\frac{1}{2}\\log\\frac{\\det(\\Psi\_{v}+D\\Sigma D^{\\top})}{\\det(\\Psi\_{v}+D\\Psi\_{\\sigma}D^{\\top})}. |     |

Under the input policy ut\=âˆ’Kâ€‹xt+Bâ€ â€‹stu\_{t}=-Kx\_{t}+B^{\\dagger}s\_{t}, the control constraint Jâ‰¤Jâˆ—+VJ\\leq J^{\*}+V is the same as that in Theorem [1](https://arxiv.org/html/2509.16146v1#Thmtheorem1 "Theorem 1 â€£ IV-A Capacity â€£ IV Noiseless Observations at the Controller and the Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"). That is, the constraint is equivalent to a power constraint on the input: Trâ€‹((Î“+G^)â€‹Î¦)â‰¤V\\text{Tr}((\\Gamma+\\hat{G})\\Phi)\\leq V, where G^\=(Bâ€ )âŠ¤â€‹Gâ€‹Bâ€ \\hat{G}=(B^{\\dagger})^{\\top}GB^{\\dagger}. Therefore, the channel capacity under the above constraint is given by the following optimization problem:

Report issue for preceding element

|     |     |     |     |     |
| --- | --- | --- | --- | --- |
|     | Cnorâ€‹(V):=maxÎ¦âª°0\\displaystyle C\_{\\text{nor}}(V):=\\max\_{\\Phi\\succeq 0}\\ | 12â€‹logâ¡det(Î¨v+Dâ€‹Î£â€‹DâŠ¤)det(Î¨v+Dâ€‹Î¨Ïƒâ€‹DâŠ¤)\\displaystyle\\frac{1}{2}\\log\\frac{\\det(\\Psi\_{v}+D\\Sigma D^{\\top})}{\\det(\\Psi\_{v}+D\\Psi\_{\\sigma}D^{\\top})} |     | (29) |
|     | s.t. | Trâ€‹((Î“+G^)â€‹Î¦)â‰¤V\\displaystyle\\text{Tr}((\\Gamma+\\hat{G})\\Phi)\\leq V |     | (30) |
|     |     | Î£\=AÂ¯â€‹(Î£âˆ’Î£â€‹DâŠ¤â€‹(Dâ€‹Î£â€‹DâŠ¤+Î¨v)âˆ’1â€‹Dâ€‹Î£)â€‹AÂ¯âŠ¤+Î¨w+Î¦,\\displaystyle\\Sigma=\\bar{A}\\left(\\Sigma-\\Sigma D^{\\top}(D\\Sigma D^{\\top}+\\Psi\_{v})^{-1}D\\Sigma\\right)\\bar{A}^{\\top}+\\Psi\_{{w}}+\\Phi, |     | (31) |

where Î¨Ïƒ\\Psi\_{\\sigma} is independent of Î¦\\Phi, as defined in ([28](https://arxiv.org/html/2509.16146v1#S5.E28 "In V-C Achievability Proof â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")). This completes the achievability proof.

Report issue for preceding element

###### Remark 1

Report issue for preceding element

In this Section, we assume that the receiverâ€™s observation matrix DD is square and invertible. Under this assumption, the transformation from the sequence zn+1z^{n+1} to yÂ¯n\\bar{y}^{n} preserves all information about the random sequence sns^{n} in the input (see the discussion around ([26](https://arxiv.org/html/2509.16146v1#S5.E26 "In V-C Achievability Proof â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"))). Consequently, under the input policy ut\=âˆ’Kâ€‹xt+Bâ€ â€‹stu\_{t}=-Kx\_{t}+B^{\\dagger}s\_{t}, the Gaussian channel yÂ¯t\=Dâ€‹st+Îºt\\bar{y}\_{t}=Ds\_{t}+\\kappa\_{t} is equivalent to the original implicit channel. In fact, this property also holds if DD is a full-rank fat matrix, but fails when DD is tall or rank-deficient. However, allowing DD to be a full-rank fat matrix would invalidate the converse proof. Wet thus restrict our attention to the case where DD is invertible.

Report issue for preceding element

## VI Noisy Observations at Controller and Receiver

Report issue for preceding element

In this section, we study implicit communication in LQG systems under the most general setting, where both the controller and the receiver have access only to noisy observations of the system state. The system model is illustrated in Fig. [3](https://arxiv.org/html/2509.16146v1#S6.F3 "Figure 3 â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"). Specifically, for the linear system defined in ([1](https://arxiv.org/html/2509.16146v1#S3.E1 "In III-A Linear Quadratic-Gaussian (LQG) Control Systems â€£ III System Model and Preliminaries â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), we assume the receiverâ€™s observation ztz\_{t} is given by ([11](https://arxiv.org/html/2509.16146v1#S5.E11 "In V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), while the controller observes otâˆˆâ„d3o\_{t}\\in\\mathbb{R}^{d\_{3}} given by

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | ot\=Dcâ€‹xt+qt,\\displaystyle o\_{t}=D\_{c}x\_{t}+q\_{t}, |     | (32) |

where Dcâˆˆâ„d3Ã—d1D\_{c}\\in\\mathbb{R}^{d\_{3}\\times d\_{1}} is the observation matrix, qtâˆ¼ğ’©â€‹(0,Î¨q)q\_{t}\\sim\\mathcal{N}(0,\\Psi\_{q}) is an observation noise independent of {xi}\\{x\_{i}\\}, {vi}\\{v\_{i}\\} and {wi}\\{w\_{i}\\}. We assume Î¨qâ‰»0\\Psi\_{q}\\succ 0, and that the pair (A,Dc)(A,D\_{c}) is observable.

Report issue for preceding element

![Refer to caption](x3.png)

Figure 3: Implicit communication in LQG control systems with noisy observations at controller and receiver.

Report issue for preceding element

In this setting, the controller computes input utu\_{t} based on its observation history oto^{t}, with an aim of balancing the control and communication performance. Therefore, the encoding mapping at time tt is denoted by

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | ut:â„³Ã—ğ’ªtâ†’ğ’°,\\displaystyle u\_{t}:\\mathcal{M}\\times\\mathcal{O}^{t}\\to\\mathcal{U}, |     |

where ğ’ª\=â„d3\\mathcal{O}=\\mathbb{R}^{d\_{3}} denotes the observation alphabet. Accordingly, the receiver decodes the message using the mapping:

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | m^:ğ’µn+1â†’â„³.\\displaystyle\\hat{m}:\\mathcal{Z}^{n+1}\\to\\mathcal{M}. |     |

The definitions of average probability of error and coding rate follow the standard conventions outlined in Section [III](https://arxiv.org/html/2509.16146v1#S3 "III System Model and Preliminaries â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"). We denote by Cnoâ€‹(V)C\_{\\text{no}}(V) the capacity of this implicit channel under a control constraint Jâ‰¤Jâˆ—âˆ—+VJ\\leq J^{\*\*}+V, where Jâˆ—âˆ—J^{\*\*} is the optimal control cost when the controllerâ€™s observations are noisy, as will be discussed shortly.

Report issue for preceding element

Noisy observations at the controller introduce substantial challenges in deriving the capacity of the implicit channel. As a result, we can only establish a lower bound on the capacity, which is achievable using linear input policies. Before presenting this bound, we first provide a brief discussion of control and state estimation in the presence of noisy controller observations.

Report issue for preceding element

### VI-A Optimal Control and Kalman Filtering

Report issue for preceding element

Without considering implicit communication, the optimal control policy that minimizes the long-term average quadratic cost defined in ([6](https://arxiv.org/html/2509.16146v1#S3.E6 "In III-A Linear Quadratic-Gaussian (LQG) Control Systems â€£ III System Model and Preliminaries â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) is given by ut\=âˆ’Kâ€‹xË‡t|tu\_{t}=-K\\check{x}\_{t|t}, where KK is the same feedback gain as in the perfect observation case, as defined in ([7](https://arxiv.org/html/2509.16146v1#S3.E7 "In III-A Linear Quadratic-Gaussian (LQG) Control Systems â€£ III System Model and Preliminaries â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), and xË‡t|tâ‰œğ”¼â€‹\[xt|ot,utâˆ’1\]\\check{x}\_{t|t}\\triangleq\\mathbb{E}\[x\_{t}|o^{t},u^{t-1}\] is the controllerâ€™s estimate of the state based on its observations and past inputs. Here, the estimate xË‡t|t\\check{x}\_{t|t} can also be computed using the Kalman filter introduced in Section [V](https://arxiv.org/html/2509.16146v1#S5 "V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"), with a minor difference that state prediction now incorporates the applied control: xË‡t+1|t\=Aâ€‹xË‡t|t+Bâ€‹ut\\check{x}\_{t+1|t}=A\\check{x}\_{t|t}+Bu\_{t}. As tâ†’âˆt\\to\\infty, the covariance of the estimation error xtâˆ’xË‡t+1|tx\_{t}-\\check{x}\_{t+1|t} converges to Î£c\\Sigma\_{c}, which is determined by the discrete-time algebraic Riccati equation:

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Î£c\=Aâ€‹(Î£câˆ’Î£câ€‹DcâŠ¤â€‹(Dcâ€‹Î£câ€‹DcâŠ¤+Î¨q)âˆ’1â€‹Dcâ€‹Î£c)â€‹AâŠ¤+Î¨w.\\displaystyle\\Sigma\_{c}=A\\left(\\Sigma\_{c}-\\Sigma\_{c}D\_{c}^{\\top}(D\_{c}\\Sigma\_{c}D\_{c}^{\\top}+\\Psi\_{q})^{-1}D\_{c}\\Sigma\_{c}\\right)A^{\\top}+\\Psi\_{w}. |     | (33) |

Note that, unlike Î£\\Sigma defined in ([16](https://arxiv.org/html/2509.16146v1#S5.E16 "In V-B Kalman Filter and Smoother â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), Î£c\\Sigma\_{c} is independent of the input policy, as the controller has full knowledge of the inputs. Upon receiving the new observation ot+1o\_{t+1}, the controller updates its state estimate using the standard Kalman filtering formula:

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | xË‡t+1\|t+1\=xË‡t+1\|t+LË‡t+1â€‹(ot+1âˆ’Dcâ€‹xË‡t+1\|t).\\displaystyle\\check{x}\_{t+1\|t+1}=\\check{x}\_{t+1\|t}+\\check{L}\_{t+1}(o\_{t+1}-D\_{c}\\check{x}\_{t+1\|t}). |     | (34) |

Let etâ‰œxtâˆ’xË‡t|te\_{t}\\triangleq x\_{t}-\\check{x}\_{t|t} denote the estimation error at time tt. As tâ†’âˆt\\to\\infty, the controllerâ€™s filter gain LË‡t\\check{L}\_{t} and estimation error covariance Covâ€‹(et)\\text{Cov}(e\_{t}) converge to steady-state values:

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Lcâ‰œlimtâ†’âˆLË‡t\=Î£câ€‹DcâŠ¤â€‹(Dcâ€‹Î£câ€‹DcâŠ¤+Î¨q)âˆ’1,\\displaystyle L\_{c}\\triangleq\\lim\_{t\\to\\infty}\\check{L}\_{t}=\\Sigma\_{c}D\_{c}^{\\top}\\left(D\_{c}\\Sigma\_{c}D\_{c}^{\\top}+\\Psi\_{q}\\right)^{-1}, |     | (35) |
|     | Î£~câ‰œlimtâ†’âˆCovâ€‹(et)\=(Iâˆ’Lcâ€‹Dc)â€‹Î£c.\\displaystyle\\tilde{\\Sigma}\_{c}\\triangleq\\lim\_{t\\to\\infty}\\text{Cov}(e\_{t})=(I-L\_{c}D\_{c})\\Sigma\_{c}. |     | (36) |

Under the policy ut\=âˆ’Kâ€‹x^t|tu\_{t}=-K\\hat{x}\_{t|t}, the optimal long-term average control cost is given by

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Jâˆ—âˆ—\=Trâ€‹(Fâ€‹Î£~c)+Trâ€‹(Î“â€‹(Î£câˆ’Î£~c)).\\displaystyle J^{\*\*}=\\text{Tr}(F\\tilde{\\Sigma}\_{c})+\\text{Tr}(\\Gamma(\\Sigma\_{c}-\\tilde{\\Sigma}\_{c})). |     | (37) |

### VI-B A Lower Bound on the Capacity

Report issue for preceding element

In the settings considered in the previous sections, the controller has noiseless observation of the system state. In such cases, the optimal input policy that achieves the implicit channel capacity adheres to a separation principleâ€”the communication signal can be designed independently and then simply added to the optimal control input of the LQG control problem. This separation greatly simplifies the implicit communication problem, making it more practical and implementable. Therefore, it is a natural desire for the input policy to retain this property even when the controllerâ€™s observations are noisy. Such motivated, we will focus on input policies that take the form

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | ut\=âˆ’Kâ€‹xË‡t\|t+Bâ€ â€‹st,stâˆ¼ğ’©â€‹(0,Î¦),\\displaystyle u\_{t}=-K\\check{x}\_{t\|t}+B^{\\dagger}s\_{t},\\quad s\_{t}\\sim\\mathcal{N}(0,\\Phi), |     | (38) |

and derive the maximum achievable rate within this class of policies. The result serves as a lower bound on the channel capacity.

Report issue for preceding element

We first analyse the control cost of the input policy ([38](https://arxiv.org/html/2509.16146v1#S6.E38 "In VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), which allows us to translate the control cost constraint into an equivalent constraint on the average power of sts\_{t}.

Report issue for preceding element

###### Lemma 4

Report issue for preceding element

For the linear system ([1](https://arxiv.org/html/2509.16146v1#S3.E1 "In III-A Linear Quadratic-Gaussian (LQG) Control Systems â€£ III System Model and Preliminaries â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) with an observation process ([32](https://arxiv.org/html/2509.16146v1#S6.E32 "In VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), the long-term average control cost of the policy ut\=âˆ’Kâ€‹xË‡t|t+Bâ€ â€‹stu\_{t}=-K\\check{x}\_{t|t}+B^{\\dagger}s\_{t}, where stâˆ¼ğ’©â€‹(0,Î¦)s\_{t}\\sim\\mathcal{N}(0,\\Phi), is given by

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | J\=Jâˆ—âˆ—+Trâ€‹((Î“+G^)â€‹Î¦),\\displaystyle J=J^{\*\*}+\\text{Tr}((\\Gamma+\\hat{G})\\Phi), |     |

where G^\=(Bâ€ )âŠ¤â€‹Gâ€‹Bâ€ \\hat{G}=(B^{\\dagger})^{\\top}GB^{\\dagger}.

Report issue for preceding element

###### Proof:

Report issue for preceding element

See Appendix C. âˆ

Report issue for preceding element

Lemma [4](https://arxiv.org/html/2509.16146v1#Thmlemma4 "Lemma 4 â€£ VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") implies that, within the class of policies defined in ([38](https://arxiv.org/html/2509.16146v1#S6.E38 "In VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), the control constraint Jâ‰¤Jâˆ—âˆ—+VJ\\leq J^{\*\*}+V is equivalent to a power constraint on sts\_{t}: Trâ€‹((Î“+G^)â€‹Î¦)â‰¤V\\text{Tr}((\\Gamma+\\hat{G})\\Phi)\\leq V. This mirrors the equivalence observed in the settings where the controller has noiseless observations.

Report issue for preceding element

Under the input policy ([38](https://arxiv.org/html/2509.16146v1#S6.E38 "In VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), the system evolves according to the following equation:

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | xt+1\=(Aâˆ’Bâ€‹K)â€‹xt+Bâ€‹Kâ€‹et+st+wt.\\displaystyle x\_{t+1}=(A-BK)x\_{t}+BKe\_{t}+s\_{t}+{w}\_{t}. |     | (39) |

Using a similar argument as before shows that the error process {et}\\{e\_{t}\\} is a Markov chain that evolves according to

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | et+1\=(Iâˆ’Lcâ€‹Dc)â€‹Aâ€‹et+(Iâˆ’Lcâ€‹Dc)â€‹wtâˆ’Lcâ€‹qt+1.\\displaystyle e\_{t+1}=(I-L\_{c}D\_{c}){A}e\_{t}+(I-L\_{c}D\_{c})w\_{t}-L\_{c}q\_{t+1}. |     | (40) |

While ete\_{t} and xË‡t\\check{x}\_{t} are uncorrelated, we note that ete\_{t} remains correlated with xtx\_{t}:

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Covâ€‹(et,xt)\=ğ”¼â€‹\[etâ€‹xtâŠ¤\]âˆ’ğ”¼â€‹\[etâ€‹xË‡tâŠ¤\]\=ğ”¼â€‹\[etâ€‹etâŠ¤\]\=Î£câ‰»0.\\displaystyle\\text{Cov}(e\_{t},x\_{t})=\\mathbb{E}\[e\_{t}{x}^{\\top}\_{t}\]-\\mathbb{E}\[e\_{t}\\check{x}^{\\top}\_{t}\]=\\mathbb{E}\[e\_{t}e\_{t}^{\\top}\]=\\Sigma\_{c}\\succ 0. |     |

Recall that, when the controller has perfect observations and takes the input policy ut\=âˆ’Kâ€‹xt+Bâ€ â€‹stu\_{t}=-Kx\_{t}+B^{\\dagger}s\_{t}, the receiver can estimate xt+1âˆ’(Aâˆ’Bâ€‹K)â€‹xtx\_{t+1}-(A-BK)x\_{t} from zt+1z^{t+1} via the Kalman filter and treat this estimate as the channel output at time tt. Now, with noisy observations at the controller, the state estimation at the controller introduces an additional error term ete\_{t} into the state evolution, as shown in ([39](https://arxiv.org/html/2509.16146v1#S6.E39 "In VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")). Because of the correlation between ete\_{t} and xtx\_{t}, the receiver can no longer directly estimate xtx\_{t} using the standard Kalman filter, as it requires the noise to be White Gaussian and independent of the state xtx\_{t}.

Report issue for preceding element

To address this issue, we construct an extended state Ïtâ‰œ\[xt,et\]\\rho\_{t}\\triangleq\[x\_{t},e\_{t}\] and characterize the system from the receiverâ€™s perspective using the following equivalent form:

Report issue for preceding element

|     |     |     |     |     |
| --- | --- | --- | --- | --- |
|     | Ït+1\\displaystyle\\rho\_{t+1} | \=AÏâ€‹Ït+sÂ¯t+wÂ¯t+qÂ¯t+1,\\displaystyle=A\_{\\rho}\\rho\_{t}+\\bar{s}\_{t}+\\bar{w}\_{t}+\\bar{q}\_{t+1}, |     | (41) |
|     | zt\\displaystyle z\_{t} | \=DÏâ€‹Ït+vt,\\displaystyle=D\_{\\rho}\\rho\_{t}+v\_{t}, |     | (42) |

where DÏâ‰œ\[Dâ€‹ 0\]D\_{\\rho}\\triangleq\[D\\ 0\] and

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | AÏâ‰œ\[Aâˆ’Bâ€‹KBâ€‹K0(Iâˆ’Lcâ€‹Dc)â€‹A\],sÂ¯tâ‰œ\[st0\],wÂ¯tâ‰œ\[wt(Iâˆ’Lcâ€‹Dc)â€‹wt\],qÂ¯t+1â‰œ\[0âˆ’Lcâ€‹qt+1\].\\displaystyle A\_{\\rho}\\triangleq\\begin{bmatrix}A-BK&BK\\\\ 0&(I-L\_{c}D\_{c})A\\end{bmatrix},\\ \\bar{s}\_{t}\\triangleq\\begin{bmatrix}s\_{t}\\\\ 0\\end{bmatrix},\\ \\bar{w}\_{t}\\triangleq\\begin{bmatrix}w\_{t}\\\\ (I-L\_{c}D\_{c})w\_{t}\\end{bmatrix},\\ \\bar{q}\_{t+1}\\triangleq\\begin{bmatrix}0\\\\ -L\_{c}q\_{t+1}\\end{bmatrix}. |     | (43) |

The system defined in ([41](https://arxiv.org/html/2509.16146v1#S6.E41 "In VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"))-([42](https://arxiv.org/html/2509.16146v1#S6.E42 "In VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) is equivalent to the one defined by ([39](https://arxiv.org/html/2509.16146v1#S6.E39 "In VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"))-([40](https://arxiv.org/html/2509.16146v1#S6.E40 "In VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) and ([11](https://arxiv.org/html/2509.16146v1#S5.E11 "In V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")). Note that sÂ¯t,wtÂ¯\\bar{s}\_{t},\\bar{w\_{t}}, qÂ¯t+1\\bar{q}\_{t+1} and vtv\_{t} are all independent with each other, and all of them are independent of Ït\\rho\_{t}â€”since ete\_{t} is correlated only with stâˆ’1,wtâˆ’1s^{t-1},w^{t-1}, and qtq^{t}. The covariance matrices of sÂ¯t,wtÂ¯\\bar{s}\_{t},\\bar{w\_{t}}, and qÂ¯t+1\\bar{q}\_{t+1} are given by

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Î¦Â¯\=\[Î¦000\],Î¨wÂ¯\=\[Î¨wÎ¨wâ€‹(Iâˆ’Lcâ€‹Dc)âŠ¤(Iâˆ’Lcâ€‹Dc)â€‹Î¨w(Iâˆ’Lcâ€‹Dc)â€‹Î¨wâ€‹(Iâˆ’Lcâ€‹Dc)âŠ¤\],Î¨qÂ¯\=\[000Lcâ€‹Î¨qâ€‹LcâŠ¤\].\\displaystyle\\bar{\\Phi}=\\begin{bmatrix}\\Phi&0\\\\ 0&0\\end{bmatrix},\\Psi\_{\\bar{w}}=\\begin{bmatrix}\\Psi\_{w}&\\Psi\_{w}(I-L\_{c}D\_{c})^{\\top}\\\\ (I-L\_{c}D\_{c})\\Psi\_{w}&(I-L\_{c}D\_{c})\\Psi\_{w}(I-L\_{c}D\_{c})^{\\top}\\end{bmatrix},\\Psi\_{\\bar{q}}=\\begin{bmatrix}0&0\\\\ 0&L\_{c}\\Psi\_{q}L\_{c}^{\\top}\\end{bmatrix}. |     | (44) |

Under this construction, we can estimate

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | ytâ‰œÏt+1âˆ’AÏâ€‹Ït\=xt+1âˆ’(Aâˆ’Bâ€‹K)â€‹xtâˆ’Bâ€‹Kâ€‹ety\_{t}\\triangleq\\rho\_{t+1}-A\_{\\rho}\\rho\_{t}=x\_{t+1}-(A-BK)x\_{t}-BKe\_{t} |     |

using the standard Kalman filter and smoother described in Section [V-B](https://arxiv.org/html/2509.16146v1#S5.SS2 "V-B Kalman Filter and Smoother â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"). This estimation enables us to translate the implicit channel into a Gaussian channel, as formalized in the following lemma.

Report issue for preceding element

###### Lemma 5 (Channel Translation)

Report issue for preceding element

Consider the input policy ut\=âˆ’Kâ€‹xË‡t|t+Bâ€ â€‹stu\_{t}=-K\\check{x}\_{t|t}+B^{\\dagger}s\_{t}, where stâˆ¼ğ’©â€‹(0,Î¦)s\_{t}\\sim\\mathcal{N}(0,\\Phi) is independent of xË‡t|t\\check{x}\_{t|t}. Then the implicit channel under the control constraint Jâ‰¤Jâˆ—âˆ—+VJ\\leq J^{\*\*}+V is equivalent to the Gaussian channel

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | yÂ¯t\=Dâ€‹st+Î²t,\\displaystyle\\bar{y}\_{t}=Ds\_{t}+\\beta\_{t}, |     |

subject to the input power constraint ğ”¼â€‹\[stâŠ¤â€‹(Î“+G^)â€‹st\]â‰¤V\\mathbb{E}\[s^{\\top}\_{t}(\\Gamma+\\hat{G})s\_{t}\]\\leq V, where the noise term is given by Î²t\=Dâ€‹wt+DÏâ€‹AÏâ€‹Ï„t+vt+1\\beta\_{t}=Dw\_{t}+D\_{\\rho}A\_{\\rho}\\tau\_{t}+v\_{t+1}, and Ï„tâ‰œÏtâˆ’ğ”¼â€‹\[Ït|zt\]\\tau\_{t}\\triangleq\\rho\_{t}-\\mathbb{E}\[\\rho\_{t}|z^{t}\] is the estimation error of the Kalman filter for estimating Ït\\rho\_{t}.

Report issue for preceding element

###### Proof:

Report issue for preceding element

The proof is deferred to Section [VII-C](https://arxiv.org/html/2509.16146v1#S7.SS3 "VII-C Proof of Theorem 4 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"). âˆ

Report issue for preceding element

The key difference between the Gaussian channel in Lemma [5](https://arxiv.org/html/2509.16146v1#Thmlemma5 "Lemma 5 (Channel Translation) â€£ VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") and that in the previous section lies in the noise term. Specifically, we can decompose DÏâ€‹AÏâ€‹Ï„tD\_{\\rho}A\_{\\rho}\\tau\_{t} as follows:

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | DÏâ€‹AÏâ€‹Ï„t\=Dâ€‹(Aâˆ’Bâ€‹K)â€‹Ïƒt+Dâ€‹Bâ€‹Kâ€‹Îµt,\\displaystyle D\_{\\rho}A\_{\\rho}\\tau\_{t}=D(A-BK)\\sigma\_{t}+DBK\\varepsilon\_{t}, |     |

where Ïƒt\=xtâˆ’ğ”¼â€‹\[xt|zt\]\\sigma\_{t}=x\_{t}-\\mathbb{E}\[x\_{t}|z^{t}\] and Îµt\=etâˆ’ğ”¼â€‹\[et|zt\]\\varepsilon\_{t}=e\_{t}-\\mathbb{E}\[e\_{t}|z^{t}\]. Compared with Îºt\\kappa\_{t} in the previous section, the presence of noise in the controllerâ€™s observations introduces an additional noise term, Îµt\\varepsilon\_{t}, which is correlated with Ïƒt\\sigma\_{t}. Nevertheless, building on the basis of the extended linear system ([41](https://arxiv.org/html/2509.16146v1#S6.E41 "In VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"))-([42](https://arxiv.org/html/2509.16146v1#S6.E42 "In VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), these two correlated noises can be treated as a single process, i.e., Ï„t\\tau\_{t}. Since Ï„t\\tau\_{t} is the estimation error of a Kalman filter, by the same argument as before, {Ï„t}\\{\\tau\_{t}\\} forms a Markov chain, implying that the channel noise process {Î²t}\\{\\beta\_{t}\\} is a hidden Markov chain. The capacity of the channel in LemmaÂ [5](https://arxiv.org/html/2509.16146v1#Thmlemma5 "Lemma 5 (Channel Translation) â€£ VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") can thus be analysed using the same approach as in the achievability proof of TheoremÂ [3](https://arxiv.org/html/2509.16146v1#Thmtheorem3 "Theorem 3 â€£ V-A Capacity â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"), leading to a lower bound on Cnoâ€‹(V)C\_{\\text{no}}(V).

Report issue for preceding element

###### Theorem 4

Report issue for preceding element

For any Vâ‰¥0V\\geq 0, with noisy observations at the controller and the receiver, the capacity of the implicit channel under the control constraint Jâ‰¤Jâˆ—âˆ—+VJ\\leq J^{\*\*}+V admits a lower bound Cnoâ€‹(V)â‰¥Cno-lbâ€‹(V)C\_{\\text{no}}(V)\\geq C\_{\\text{no-lb}}(V), where Cno-lbâ€‹(V)C\_{\\text{no-lb}}(V) is given by an optimization problem:

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Cno-lbâ€‹(V):=maxÎ¦âª°0\\displaystyle C\_{\\text{no-lb}}(V):=\\max\_{\\Phi\\succeq 0}\\ | 12â€‹logâ€‹det(DÏâ€‹Î£Ïâ€‹DÏâŠ¤+Î¨v)âˆ’12â€‹logâ€‹det(DÏâ€‹Î¨Ïâ€‹DÏâŠ¤+Î¨v)\\displaystyle\\frac{1}{2}\\log{\\det(D\_{\\rho}\\Sigma\_{\\rho}D\_{\\rho}^{\\top}+\\Psi\_{v})}-\\frac{1}{2}\\log{\\det(D\_{\\rho}\\Psi\_{\\rho}D\_{\\rho}^{\\top}+\\Psi\_{v})} |     |
|     | s.t. | Trâ€‹((Î“+G^)â€‹Î¦)â‰¤V\\displaystyle\\text{Tr}((\\Gamma+\\hat{G})\\Phi)\\leq V |     |
|     |     | Î£Ï\=AÏâ€‹(Î£Ïâˆ’Î£Ïâ€‹DÏâŠ¤â€‹(DÏâ€‹Î£Ïâ€‹DÏâŠ¤+Î¨v)âˆ’1â€‹DÏâ€‹Î£Ï)â€‹AÏâŠ¤+Î¦Â¯+Î¨wÂ¯+Î¨qÂ¯,\\displaystyle\\Sigma\_{\\rho}={A}\_{\\rho}\\left(\\Sigma\_{\\rho}-\\Sigma\_{\\rho}D\_{\\rho}^{\\top}(D\_{\\rho}\\Sigma\_{\\rho}D\_{\\rho}^{\\top}+\\Psi\_{v})^{-1}D\_{\\rho}\\Sigma\_{\\rho}\\right){A}\_{\\rho}^{\\top}+\\bar{\\Phi}+\\Psi\_{\\bar{w}}+\\Psi\_{\\bar{q}}, |     |

where Î¦Â¯,Î¨wÂ¯\\bar{\\Phi},\\Psi\_{\\bar{w}}, and Î¨qÂ¯\\Psi\_{\\bar{q}} are defined in ([44](https://arxiv.org/html/2509.16146v1#S6.E44 "In VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), and Î¨Ï\\Psi\_{\\rho} is given by the discrete-time algebraic Riccati equation:

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Î¨Ï\=AÏâ€‹(Î¨Ïâˆ’Î¨Ïâ€‹DÏâŠ¤â€‹(DÏâ€‹Î¨Ïâ€‹DÏâŠ¤+Î¨v)âˆ’1â€‹DÏâ€‹Î¨Ï)â€‹AÏâŠ¤+Î¨wÂ¯+Î¨qÂ¯.\\displaystyle\\Psi\_{\\rho}={A}\_{\\rho}\\left(\\Psi\_{\\rho}-\\Psi\_{\\rho}D\_{\\rho}^{\\top}(D\_{\\rho}\\Psi\_{\\rho}D\_{\\rho}^{\\top}+\\Psi\_{v})^{-1}D\_{\\rho}\\Psi\_{\\rho}\\right){A}\_{\\rho}^{\\top}+\\Psi\_{\\bar{w}}+\\Psi\_{\\bar{q}}. |     |

###### Proof:

Report issue for preceding element

The proof is deferred to Section [VII-C](https://arxiv.org/html/2509.16146v1#S7.SS3 "VII-C Proof of Theorem 4 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"). âˆ

Report issue for preceding element

The optimization problem in Theorem [4](https://arxiv.org/html/2509.16146v1#Thmtheorem4 "Theorem 4 â€£ VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") has the same form as that in Theorem [3](https://arxiv.org/html/2509.16146v1#Thmtheorem3 "Theorem 3 â€£ V-A Capacity â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"), as it is obtained by restricting attention to linear input policies. Here, Î£Ï\\Sigma\_{\\rho} is the stabilizing estimation error covariance of ğ”¼â€‹\[Ït+1|zt\]\\mathbb{E}\[\\rho\_{t+1}|z^{t}\], while Î¨Ï\\Psi\_{\\rho} corresponds to that of ğ”¼â€‹\[Ït+1|zt,st\]\\mathbb{E}\[\\rho\_{t+1}|z^{t},s^{t}\]. In the special case where the controller has noiseless observations, we have et\=0e\_{t}=0 for all tt. As a result, Î£Ï\=\[Î£â€‹ 0;0 0\]\\Sigma\_{\\rho}=\[\\Sigma\\ 0;0\\ 0\] and Î¨Ï\=\[Î¨Ïƒâ€‹ 0;0 0\]\\Psi\_{\\rho}=\[\\Psi\_{\\sigma}\\ 0;0\\ 0\]. Then it is easy to verify that Cno-lbâ€‹(V)\=Cnorâ€‹(V)C\_{\\text{no-lb}}(V)=C\_{\\text{nor}}(V), meaning that the lower bound is tight in this special case.

Report issue for preceding element

Given the same form of the optimization problem, it is unsurprising that Cno-lbâ€‹(V)C\_{\\text{no-lb}}(V) can also be computed by solving a convex optimization, as in Proposition [1](https://arxiv.org/html/2509.16146v1#Thmproposition1 "Proposition 1 â€£ V-A Capacity â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems").

Report issue for preceding element

###### Proposition 2

Report issue for preceding element

For any Vâ‰¥0V\\geq 0, the lower bound Cno-lbâ€‹(V)C\_{\\text{no-lb}}(V) is given by the following convex optimization:

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Cno-lbâ€‹(V)\=maxÎ¦,Î£Ï\\displaystyle C\_{\\text{no-lb}}(V)=\\max\_{\\Phi,\\Sigma\_{\\rho}}\\ | 12â€‹logâ€‹det(DÏâ€‹Î£Ïâ€‹DÏâŠ¤+Î¨v)âˆ’12â€‹logâ€‹det(DÏâ€‹Î¨Ïâ€‹DÏâŠ¤+Î¨v)\\displaystyle\\frac{1}{2}\\log{\\det(D\_{\\rho}\\Sigma\_{\\rho}D\_{\\rho}^{\\top}+\\Psi\_{v})}-\\frac{1}{2}\\log{\\det(D\_{\\rho}\\Psi\_{\\rho}D\_{\\rho}^{\\top}+\\Psi\_{v})} |     |
|     | s.t. | Trâ€‹((Î“+G^)â€‹Î¦)â‰¤V\\displaystyle\\text{Tr}((\\Gamma+\\hat{G})\\Phi)\\leq V |     |
|     |     | \[DÏâ€‹Î£Ïâ€‹DÏâŠ¤+Î¨vDÏâ€‹Î£Ïâ€‹AÏâŠ¤AÏâ€‹Î£Ïâ€‹DÏâŠ¤AÏâ€‹Î£Ïâ€‹AÏâŠ¤+Î¦Â¯+Î¨wÂ¯+Î¨qÂ¯âˆ’Î£Ï\]âª°0\\displaystyle\\begin{bmatrix}D\_{\\rho}\\Sigma\_{\\rho}D\_{\\rho}^{\\top}+\\Psi\_{v}&D\_{\\rho}\\Sigma\_{\\rho}{A}\_{\\rho}^{\\top}\\\\ {A}\_{\\rho}\\Sigma\_{\\rho}D\_{\\rho}^{\\top}&{A}\_{\\rho}\\Sigma\_{\\rho}{A}\_{\\rho}^{\\top}+\\bar{\\Phi}+\\Psi\_{\\bar{w}}+\\Psi\_{\\bar{q}}-\\Sigma\_{\\rho}\\end{bmatrix}\\succeq 0 |     |
|     |     | Î£Ïâª°0,Î¦âª°0.\\displaystyle\\Sigma\_{\\rho}\\succeq 0,\\Phi\\succeq 0. |     |

###### Proof:

Report issue for preceding element

The proof follows exactly the same argument as that of Proposition [1](https://arxiv.org/html/2509.16146v1#Thmproposition1 "Proposition 1 â€£ V-A Capacity â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") and is omitted for brevity. âˆ

Report issue for preceding element

## VII Proofs

Report issue for preceding element

This section begins with the converse proofs for Theorems [1](https://arxiv.org/html/2509.16146v1#Thmtheorem1 "Theorem 1 â€£ IV-A Capacity â€£ IV Noiseless Observations at the Controller and the Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") and [3](https://arxiv.org/html/2509.16146v1#Thmtheorem3 "Theorem 3 â€£ V-A Capacity â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"), and then presents the proof of Theorem [4](https://arxiv.org/html/2509.16146v1#Thmtheorem4 "Theorem 4 â€£ VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"). Both converse proofs are based on Fanoâ€™s inequality and demonstrate that the mutual information between the message and the receiverâ€™s observation sequence is upper-bounded by the channel capacity. The central step is to demonstrate that this mutual information is maximized by input policies of the form ut\=âˆ’Kâ€‹xt+Bâ€ â€‹stu\_{t}=-Kx\_{t}+B^{\\dagger}s\_{t}. However, in the setting where both the controller and the receiver have noisy observations, we are unable to establish this propertyâ€”constituting the main obstacle to deriving the exact capacity in this case.

Report issue for preceding element

### VII-A Converse Proof of Theorem [1](https://arxiv.org/html/2509.16146v1#Thmtheorem1 "Theorem 1 â€£ IV-A Capacity â€£ IV Noiseless Observations at the Controller and the Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")

Report issue for preceding element

To prove the converse to Theorem [1](https://arxiv.org/html/2509.16146v1#Thmtheorem1 "Theorem 1 â€£ IV-A Capacity â€£ IV Noiseless Observations at the Controller and the Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"), we show that a sequence of (2nâ€‹Rn,n)(2^{nR\_{n}},n) codes with Pe(n)â†’0P\_{e}^{(n)}\\to 0 must have Rnâ‰¤CÂ¯nâ€‹(V)+ÏµnR\_{n}\\leq\\bar{C}\_{n}(V)+\\epsilon\_{n}, where Ïµnâ†’0\\epsilon\_{n}\\to 0 and CÂ¯nâ€‹(V)â†’Câ€‹(V)\\bar{C}\_{n}(V)\\to C(V).

Report issue for preceding element

###### Proof:

Report issue for preceding element

First of all, by Fanoâ€™s inequality,

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | nâ€‹Rn\=Hâ€‹(m)\\displaystyle nR\_{n}=H(m) | \=Hâ€‹(m\|xn+1)+Iâ€‹(m;xn+1)\\displaystyle=H(m\|x^{n+1})+I(m;x^{n+1}) |     |
|     |     | \=Iâ€‹(m;xn+1)+nâ€‹Ïµn,\\displaystyle=I(m;x^{n+1})+n\\epsilon\_{n}, |     |

where Ïµnâ†’0\\epsilon\_{n}\\to 0 if Pe(n)â†’0P\_{e}^{(n)}\\to 0. Now,

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Iâ€‹(m;xn+1)\\displaystyle I(m;x^{n+1}) | \=hâ€‹(xn+1)âˆ’hâ€‹(xn+1\|m)\\displaystyle=h(x^{n+1})-h(x^{n+1}\|m) |     |
|     |     | \=âˆ‘i\=2n+1hâ€‹(xi\|xiâˆ’1)+hâ€‹(x1)âˆ’âˆ‘i\=2n+1hâ€‹(xi\|xiâˆ’1,m)âˆ’hâ€‹(x1\|m)\\displaystyle=\\sum\_{i=2}^{n+1}h(x\_{i}\|x^{i-1})+h(x\_{1})-\\sum\_{i=2}^{n+1}h(x\_{i}\|x^{i-1},m)-h(x\_{1}\|m) |     |
|     |     | \=âˆ‘i\=1nhâ€‹(xi+1\|xi)âˆ’âˆ‘i\=1nhâ€‹(xi+1\|xi,m).\\displaystyle=\\sum\_{i=1}^{n}h(x\_{i+1}\|x^{i})-\\sum\_{i=1}^{n}h(x\_{i+1}\|x^{i},m). |     |

Here, hâ€‹(x1)âˆ’hâ€‹(x1|m)\=0h(x\_{1})-h(x\_{1}|m)=0 because x1x\_{1} is the initial state, which is independent of the message mm. Since uiu\_{i} is determined by xix^{i} and mm, we have

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | hâ€‹(xi+1\|xi,m)\\displaystyle h(x\_{i+1}\|x^{i},m) | \=hâ€‹(Aâ€‹xi+Bâ€‹ui+wi\|m,xi,uiâ€‹(xi,m))\\displaystyle=h(Ax\_{i}+Bu\_{i}+w\_{i}\|m,x^{i},u\_{i}(x^{i},m)) |     |
|     |     | \=hâ€‹(wi).\\displaystyle=h(w\_{i}). |     |

Also, hâ€‹(xi+1|xi)\=hâ€‹(Aâ€‹xi+Bâ€‹ui+wi|xi)\=hâ€‹(Bâ€‹ui+wi|xi)h(x\_{i+1}|x^{i})=h(Ax\_{i}+Bu\_{i}+w\_{i}|x^{i})=h(Bu\_{i}+w\_{i}|x^{i}). We thus have

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Iâ€‹(m;xn+1)\\displaystyle I(m;x^{n+1}) | \=âˆ‘i\=1nhâ€‹(Bâ€‹ui+wi\|xi)âˆ’âˆ‘i\=1nhâ€‹(wi)\\displaystyle=\\sum\_{i=1}^{n}h(Bu\_{i}+w\_{i}\|x^{i})-\\sum\_{i=1}^{n}h(w\_{i}) |     |
|     |     | â‰¤âˆ‘i\=1nh(Bui+wi\|xi)âˆ’n2log(2Ï€e)d1det(Î¨w).\\displaystyle\\leq\\sum\_{i=1}^{n}h(Bu\_{i}+w\_{i}\|x\_{i})-\\frac{n}{2}\\log(2\\pi e)^{d\_{1}}\\det(\\Psi\_{w}). |     |

For nâ‰¥1n\\geq 1, defined a sequence of optimization problems as follows:

Report issue for preceding element

|     |     |     |     |     |
| --- | --- | --- | --- | --- |
|     | CÂ¯nâ€‹(V):=max\\displaystyle\\bar{C}\_{n}(V):=\\max\\ | 1nâˆ‘i\=1n\[h(Bui+wi\|xi)âˆ’12log(2Ï€e)d1det(Î¨w)\]\\displaystyle\\frac{1}{n}\\sum\_{i=1}^{n}\\left\[h(Bu\_{i}+w\_{i}\|x\_{i})-\\frac{1}{2}\\log(2\\pi e)^{d\_{1}}\\det(\\Psi\_{w})\\right\] |     | (45) |
|     | s.t. | Jnâ‰¤Jnâˆ—+V.\\displaystyle J\_{n}\\leq J\_{n}^{\*}+V. |     | (46) |

Then a sequence of (2nâ€‹Rn,n)(2^{nR\_{n}},n) codes satisfying constraint Jnâ‰¤Jnâˆ—+VJ\_{n}\\leq J^{\*}\_{n}+V and Pe(n)â†’0P\_{e}^{(n)}\\to 0 must have

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Rnâ‰¤1nâ€‹Iâ€‹(m;xn+1)+Ïµnâ‰¤CÂ¯nâ€‹(V)+Ïµn,\\displaystyle R\_{n}\\leq\\frac{1}{n}I(m;x^{n+1})+\\epsilon\_{n}\\leq\\bar{C}\_{n}(V)+\\epsilon\_{n}, |     |

where Ïµnâ†’0\\epsilon\_{n}\\to 0 if Pe(n)â†’0P\_{e}^{(n)}\\to 0. It remains to show that CÂ¯nâ€‹(V)â†’Câ€‹(V)\\bar{C}\_{n}(V)\\to C(V) as nâ†’âˆn\\to\\infty. The following lemma plays a central role in solving CÂ¯nâ€‹(V)\\bar{C}\_{n}(V):

Report issue for preceding element

###### Lemma 6

Report issue for preceding element

For a fixed nn, it is sufficient to optimize CÂ¯nâ€‹(V)\\bar{C}\_{n}(V), as defined in ([45](https://arxiv.org/html/2509.16146v1#S7.E45 "In VII-A Converse Proof of Theorem 1 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"))-([46](https://arxiv.org/html/2509.16146v1#S7.E46 "In VII-A Converse Proof of Theorem 1 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), over input policies of the form ut\=âˆ’Ktâ€‹xt+Bâ€ â€‹stu\_{t}=-K\_{t}x\_{t}+B^{\\dagger}s\_{t}, where stâˆ¼ğ’©â€‹(0,Î¦t)s\_{t}\\sim\\mathcal{N}(0,\\Phi\_{t}) is independent of xtx\_{t} and wtw\_{t}.

Report issue for preceding element

###### Proof:

Report issue for preceding element

Proof of Lemma [6](https://arxiv.org/html/2509.16146v1#Thmlemma6 "Lemma 6 â€£ VII-A Converse Proof of Theorem 1 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") is presented immediately after the converse proof. âˆ

Report issue for preceding element

Lemma [6](https://arxiv.org/html/2509.16146v1#Thmlemma6 "Lemma 6 â€£ VII-A Converse Proof of Theorem 1 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") implies that we can focus on ut\=âˆ’Ktâ€‹xt+Bâ€ â€‹stu\_{t}=-K\_{t}x\_{t}+B^{\\dagger}s\_{t}, stâˆ¼ğ’©â€‹(0,Î¦t)s\_{t}\\sim\\mathcal{N}(0,\\Phi\_{t}), for solving the optimization problem. Under this policy,

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | h(But+wt\|xt)\=h(st+wt)\=12log(2Ï€e)d1det(Î¦t+Î¨w).\\displaystyle h(Bu\_{t}+w\_{t}\|x\_{t})=h(s\_{t}+w\_{t})=\\frac{1}{2}\\log(2\\pi e)^{d\_{1}}\\det(\\Phi\_{t}+\\Psi\_{w}). |     |

We thus can convert problem ([45](https://arxiv.org/html/2509.16146v1#S7.E45 "In VII-A Converse Proof of Theorem 1 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"))-([46](https://arxiv.org/html/2509.16146v1#S7.E46 "In VII-A Converse Proof of Theorem 1 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) to an equivalent optimization problem as follows:

Report issue for preceding element

|     |     |     |     |     |
| --- | --- | --- | --- | --- |
|     | CÂ¯nâ€‹(V):=max{Î¦tâ‰¥0}\\displaystyle\\bar{C}\_{n}(V):=\\max\_{\\{\\Phi\_{t}\\geq 0\\}}\\ | 12â€‹nâ€‹âˆ‘t\=1nlogâ€‹det(I+Î¨wâˆ’1â€‹Î¦t)\\displaystyle\\frac{1}{2n}\\sum\_{t=1}^{n}\\log\\det\\left(I+\\Psi\_{w}^{-1}{\\Phi\_{t}}\\right) |     | (47) |
|     | s.t. | 1nâ€‹âˆ‘t\=1nTrâ€‹(Î¦tâ€‹(Î“t+1+G^))â‰¤V.\\displaystyle\\frac{1}{n}\\sum\_{t=1}^{n}\\text{Tr}(\\Phi\_{t}(\\Gamma\_{t+1}+\\hat{G}))\\leq V. |     | (48) |

Since Î“t\=Î“\\Gamma\_{t}=\\Gamma for all tt as nâ†’âˆn\\to\\infty, it is easy to verify that, as nâ†’âˆn\\to\\infty, CÂ¯nâ€‹(V)\\bar{C}\_{n}(V) converges to the following problem:

Report issue for preceding element

|     |     |     |     |     |
| --- | --- | --- | --- | --- |
|     | CÂ¯âˆâ€‹(V)\=maxÎ¦â‰¥0\\displaystyle\\bar{C}\_{\\infty}(V)=\\max\_{\\Phi\\geq 0}\\ | 12â€‹logâ€‹det(I+Î¨wâˆ’1â€‹Î¦)\\displaystyle\\frac{1}{2}\\log\\det\\left(I+\\Psi\_{w}^{-1}{\\Phi}\\right) |     | (49) |
|     | s.t. | Trâ€‹(Î¦â€‹(Î“+G^))â‰¤V.\\displaystyle\\text{Tr}(\\Phi(\\Gamma+\\hat{G}))\\leq V. |     | (50) |

By diagonalizing Î¨wâˆ’1\\Psi\_{w}^{-1} as Î¨wâˆ’1\=Uâ€‹Î›âˆ’1â€‹UâŠ¤\\Psi\_{w}^{-1}=U\\Lambda^{-1}U^{\\top}, the above problem reduces to the problem in the achievability proof. We thus conclude that

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | limnâ†’âˆCÂ¯nâ€‹(V)\=CÂ¯âˆâ€‹(V)\=Câ€‹(V).\\displaystyle\\lim\_{n\\to\\infty}\\bar{C}\_{n}(V)=\\bar{C}\_{\\infty}(V)=C(V). |     |

This completes the converse proof. âˆ

Report issue for preceding element

Next, we prove Lemma [6](https://arxiv.org/html/2509.16146v1#Thmlemma6 "Lemma 6 â€£ VII-A Converse Proof of Theorem 1 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"), a key component of the converse proof.

Report issue for preceding element

###### Proof:

Report issue for preceding element

In general, uiu\_{i} is a deterministic function of historical states xix^{i} and message mm. However, since hâ€‹(Bâ€‹ui+wi|xi)h(Bu\_{i}+w\_{i}|x\_{i}) depends only on the conditional distribution of uiu\_{i} given xix\_{i}, we thus focus on xix\_{i} and treat uiâ€‹(xi)u\_{i}(x\_{i}) as a stochastic function of xix\_{i}. By definition, the nn\-step average control cost can be expressed as

Report issue for preceding element

|     |     |     |     |     |
| --- | --- | --- | --- | --- |
|     | Jn\\displaystyle J\_{n} | \=1nâ€‹âˆ‘t\=1n+1ğ”¼â€‹\[xtâŠ¤â€‹Fâ€‹xt\]+1nâ€‹âˆ‘t\=1nğ”¼â€‹\[utâŠ¤â€‹Gâ€‹ut\]\\displaystyle=\\frac{1}{n}\\sum\_{t=1}^{n+1}\\mathbb{E}\[x^{\\top}\_{t}Fx\_{t}\]+\\frac{1}{n}\\sum\_{t=1}^{n}\\mathbb{E}\[u^{\\top}\_{t}Gu\_{t}\] |     |
|     |     | \=1nâ€‹âˆ‘t\=1n+1\[Trâ€‹(Fâ€‹Î¨xt)+ğ”¼â€‹\[xtâŠ¤\]â€‹Fâ€‹ğ”¼â€‹\[xt\]\]+1nâ€‹âˆ‘t\=1n\[Trâ€‹(Gâ€‹Î¨ut)+ğ”¼â€‹\[utâŠ¤\]â€‹Gâ€‹ğ”¼â€‹\[ut\]\],\\displaystyle=\\frac{1}{n}\\sum\_{t=1}^{n+1}\\left\[\\text{Tr}(F\\Psi\_{x\_{t}})+\\mathbb{E}\[x^{\\top}\_{t}\]F\\mathbb{E}\[x\_{t}\]\\right\]+\\frac{1}{n}\\sum\_{t=1}^{n}\\left\[\\text{Tr}(G\\Psi\_{u\_{t}})+\\mathbb{E}\[u^{\\top}\_{t}\]G\\mathbb{E}\[u\_{t}\]\\right\], |     | (51) |

where Î¨xt\\Psi\_{x\_{t}} and Î¨ut\\Psi\_{u\_{t}} denote the covariance matrices of xtx\_{t} and utu\_{t}, respectively. Equation ([VII-A](https://arxiv.org/html/2509.16146v1#S7.Ex83 "VII-A Converse Proof of Theorem 1 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) suggests that a constraint on JnJ\_{n} effectively translates into restrictions on the mean and covariance of states and inputs. It is known that, for a given covariance, the differential entropy is maximized by a Gaussian distribution. Therefore, problem ([45](https://arxiv.org/html/2509.16146v1#S7.E45 "In VII-A Converse Proof of Theorem 1 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"))-([46](https://arxiv.org/html/2509.16146v1#S7.E46 "In VII-A Converse Proof of Theorem 1 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) can be optimized by a policy in which the conditional distribution of utu\_{t} given xtx\_{t} is Gaussian. We refer to such policies as the type-1 policies and formally define them as follows:

Report issue for preceding element

Type-1 Policies: A policy Ï„\\tau is classified as a type-1 policy if, for any time tt, the conditional distribution of utu\_{t} given xtx\_{t} is a Gaussian distribution ğ’©â€‹(Bâ€ â€‹Î¸tâ€‹(xt),Bâ€ â€‹Î¨tâ€‹(xt)â€‹(Bâ€ )âŠ¤)\\mathcal{N}(B^{\\dagger}\\theta\_{t}(x\_{t}),B^{\\dagger}\\Psi\_{t}(x\_{t})(B^{\\dagger})^{\\top}), where both the mean Î¸t\\theta\_{t} and covariance matrix Î¨t\\Psi\_{t} are functions of the state xtx\_{t}.

Report issue for preceding element

Next, we introduce a subset of type-1 policies, referred to as type-2 policies, which are defined as follows:

Report issue for preceding element

Type-2 Policies: A policy Ï„â€²\\tau^{\\prime} is classified as a type-2 policy if, for any time tt, the conditional distribution of utu\_{t} given xtx\_{t} is a Gaussian distribution ğ’©â€‹(Bâ€ â€‹Î¸tâ€²â€‹(xt),Bâ€ â€‹Î¦tâ€²â€‹(Bâ€ )âŠ¤)\\mathcal{N}(B^{\\dagger}\\theta^{\\prime}\_{t}(x\_{t}),B^{\\dagger}\\Phi^{\\prime}\_{t}(B^{\\dagger})^{\\top}), where the mean Î¸tâ€²\\theta^{\\prime}\_{t} is a function of the state xtx\_{t}, while the covariance matrix Î¦tâ€²\\Phi^{\\prime}\_{t} is independent of xtx\_{t}.

Report issue for preceding element

Now that CÂ¯nâ€‹(V)\\bar{C}\_{n}(V) can be optimized by type-1 policies, we proceed to prove Lemma [6](https://arxiv.org/html/2509.16146v1#Thmlemma6 "Lemma 6 â€£ VII-A Converse Proof of Theorem 1 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") in two steps: (i) Step 1, we show that it is sufficient to optimize CÂ¯nâ€‹(V)\\bar{C}\_{n}(V) over the type-2 policies; (ii) Step 2, we further demonstrate that any type-2 policy has an equivalent linear policy.

Report issue for preceding element

In step 1, we begin by considering an arbitrary type-1 policy Ï„\\tau and an associated type-2 policy Ï„â€²\\tau^{\\prime} satisfying Î¸tâ€²â€‹(xt)\=Î¸tâ€‹(xt)\\theta^{\\prime}\_{t}(x\_{t})=\\theta\_{t}(x\_{t}) and Î¦tâ€²\=Î¦tâ‰œğ”¼â€‹\[Î¨tâ€‹(xt)\]\\Phi^{\\prime}\_{t}=\\Phi\_{t}\\triangleq\\mathbb{E}\[\\Psi\_{t}(x\_{t})\] for all tt. The goal is to show that both policies yield the same control cost, and that Ï„â€²\\tau^{\\prime} achieves an objective value no lower than that of Ï„\\tau. First note that, for a fixed distribution of xtx\_{t}, both policies induce the same marginal distribution of Bâ€‹utBu\_{t}. To see this, define Ïtâ‰œğ”¼â€‹\[Î¸tâ€‹(xt)\]\\rho\_{t}\\triangleq\\mathbb{E}\[\\theta\_{t}(x\_{t})\]. Then clearly, under both policies, ğ”¼â€‹\[Bâ€‹ut\]\=Ït\\mathbb{E}\[Bu\_{t}\]=\\rho\_{t}. An application of the law of total covariance shows that the covariance of Bâ€‹utBu\_{t} is also the same under both policies. In particular, the following holds for both policies:

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Covâ€‹(Bâ€‹ut)\=ğ”¼â€‹\[Covâ€‹(Bâ€‹ut\|xt)\]+Covâ€‹(ğ”¼â€‹\[Bâ€‹ut\|xt\])\=Î¦t+Covâ€‹(Î¸tâ€‹(xt)).\\displaystyle\\text{Cov}(Bu\_{t})=\\mathbb{E}\\left\[\\text{Cov}(Bu\_{t}\|x\_{t})\\right\]+\\text{Cov}\\left(\\mathbb{E}\[Bu\_{t}\|x\_{t}\]\\right)=\\Phi\_{t}+\\text{Cov}(\\theta\_{t}(x\_{t})). |     | (52) |

Therefore, the marginal distribution of Bâ€‹utBu\_{t} under both Ï„\\tau and Ï„â€²\\tau^{\\prime} is ğ’©â€‹(Ït,Î¦t+Covâ€‹(Î¸tâ€‹(xt)))\\mathcal{N}(\\rho\_{t},\\Phi\_{t}+\\text{Cov}(\\theta\_{t}(x\_{t}))).

Report issue for preceding element

We then demonstrate that Ï„\\tau and Ï„â€²\\tau^{\\prime} yield the same control cost for the nn\-step LQG control problem. According to ([VII-A](https://arxiv.org/html/2509.16146v1#S7.Ex83 "VII-A Converse Proof of Theorem 1 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), this can be established by showing that, for any tt, the distributions of xtx\_{t} under the two policies are identical. This claim can be proven using mathematical induction. Initially, note that x1âˆ¼ğ’©â€‹(0,Î¨x)x\_{1}\\sim\\mathcal{N}(0,\\Psi\_{x}) is independent of the control policy, hence the distributions of x1x\_{1} under both policies are identical. Assuming as the induction hypothesis that the distributions of xtx\_{t} under the two policies are identical. Now,

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | xt+1\=Aâ€‹xt+Bâ€‹utâ€‹(xt)+wt.\\displaystyle x\_{t+1}=Ax\_{t}+Bu\_{t}(x\_{t})+w\_{t}. |     |

Denote by ğ’©â€‹(Î½,Î¨)\\mathcal{N}(\\nu,\\Psi) and ğ’©â€‹(Î½â€²,Î¨â€²)\\mathcal{N}(\\nu^{\\prime},\\Psi^{\\prime}) the distributions of Aâ€‹xt+Bâ€‹utAx\_{t}+Bu\_{t} under policies Ï„\\tau and Ï„â€²\\tau^{\\prime}, respectively. We have

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Î½\=Aâ€‹ğ”¼â€‹\[xt\]+ğ”¼â€‹\[ğ”¼â€‹\[Bâ€‹utâ€‹(xt)\|xt\]\]\=Aâ€‹ğ”¼â€‹\[xt\]+Ït\=Î½â€²,\\displaystyle\\nu=A\\mathbb{E}\[x\_{t}\]+\\mathbb{E}\[\\mathbb{E}\[Bu\_{t}(x\_{t})\|x\_{t}\]\]=A\\mathbb{E}\[x\_{t}\]+\\rho\_{t}=\\nu^{\\prime}, |     |

and

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Î¨\\displaystyle\\Psi | \=ğ”¼â€‹\[(Aâ€‹xt+Bâ€‹ut)â€‹(Aâ€‹xt+Bâ€‹ut)âŠ¤\]âˆ’ğ”¼â€‹\[Aâ€‹xt+Bâ€‹ut\]â€‹ğ”¼â€‹\[Aâ€‹xt+Bâ€‹ut\]âŠ¤\\displaystyle=\\mathbb{E}\[(Ax\_{t}+Bu\_{t})(Ax\_{t}+Bu\_{t})^{\\top}\]-\\mathbb{E}\[Ax\_{t}+Bu\_{t}\]\\mathbb{E}\[Ax\_{t}+Bu\_{t}\]^{\\top} |     |
|     |     | \=Aâ€‹ğ”¼â€‹\[xtâ€‹xtâŠ¤\]â€‹AâŠ¤+ğ”¼â€‹\[(Bâ€‹ut)â€‹(Bâ€‹ut)âŠ¤\]+Aâ€‹ğ”¼â€‹\[xtâ€‹utâŠ¤â€‹BâŠ¤\]+ğ”¼â€‹\[Bâ€‹utâ€‹xtâŠ¤\]â€‹AâŠ¤âˆ’Î½â€‹Î½âŠ¤\\displaystyle=A\\mathbb{E}\[x\_{t}x^{\\top}\_{t}\]A^{\\top}+\\mathbb{E}\[(Bu\_{t})(Bu\_{t})^{\\top}\]+A\\mathbb{E}\[x\_{t}u^{\\top}\_{t}B^{\\top}\]+\\mathbb{E}\[Bu\_{t}x^{\\top}\_{t}\]A^{\\top}-\\nu\\nu^{\\top} |     |
|     |     | \=Aâ€‹ğ”¼â€‹\[xtâ€‹xtâŠ¤\]â€‹AâŠ¤+ğ”¼â€‹\[(Bâ€‹ut)â€‹(Bâ€‹ut)âŠ¤\]+Aâ€‹ğ”¼â€‹\[ğ”¼â€‹\[xtâ€‹utâŠ¤â€‹BâŠ¤\|xt\]\]+ğ”¼â€‹\[ğ”¼â€‹\[Bâ€‹utâ€‹xtâŠ¤\|xt\]\]â€‹AâŠ¤âˆ’Î½â€‹Î½âŠ¤\\displaystyle=A\\mathbb{E}\[x\_{t}x^{\\top}\_{t}\]A^{\\top}+\\mathbb{E}\[(Bu\_{t})(Bu\_{t})^{\\top}\]+A\\mathbb{E}\[\\mathbb{E}\[x\_{t}u^{\\top}\_{t}B^{\\top}\|x\_{t}\]\]+\\mathbb{E}\[\\mathbb{E}\[Bu\_{t}x^{\\top}\_{t}\|x\_{t}\]\]A^{\\top}-\\nu\\nu^{\\top} |     |
|     |     | \=Aâ€‹ğ”¼â€‹\[xtâ€‹xtâŠ¤\]â€‹AâŠ¤+ğ”¼â€‹\[(Bâ€‹ut)â€‹(Bâ€‹ut)âŠ¤\]+Aâ€‹ğ”¼â€‹\[xtâ€‹Î¸tâ€‹(xt)âŠ¤\]+ğ”¼â€‹\[Î¸tâ€‹(xt)â€‹xtâŠ¤\]â€‹AâŠ¤âˆ’Î½â€‹Î½âŠ¤\\displaystyle=A\\mathbb{E}\[x\_{t}x^{\\top}\_{t}\]A^{\\top}+\\mathbb{E}\[(Bu\_{t})(Bu\_{t})^{\\top}\]+A\\mathbb{E}\[x\_{t}\\theta\_{t}(x\_{t})^{\\top}\]+\\mathbb{E}\[\\theta\_{t}(x\_{t})x^{\\top}\_{t}\]A^{\\top}-\\nu\\nu^{\\top} |     |
|     |     | \=Î¨â€².\\displaystyle=\\Psi^{\\prime}. |     |

The above implies that the distributions of Aâ€‹xt+Bâ€‹utAx\_{t}+Bu\_{t} under both policies are identical. Since xtx\_{t} is independent of wtw\_{t}, so is utu\_{t}. As a result, the distributions of xt+1x\_{t+1} under policies Ï„\\tau and Ï„â€²\\tau^{\\prime} are identical, completing the inductive step. We thus conclude that, starting from the same initial state distribution, policies Ï„\\tau and Ï„â€²\\tau^{\\prime} produce identical state and (marginal) input distributions at every time step. According to ([VII-A](https://arxiv.org/html/2509.16146v1#S7.Ex83 "VII-A Converse Proof of Theorem 1 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), two policies result in the same control cost if they produce identical state and input distributions at every time step. Hence the control costs of Ï„\\tau and Ï„â€²\\tau^{\\prime} are equal.

Report issue for preceding element

Next, we show that the objective value of Ï„â€²\\tau^{\\prime} is greater than or equal to that of Ï„\\tau. As proved earlier, policies Ï„\\tau and Ï„â€²\\tau^{\\prime} produce identical distributions of xtx\_{t}, âˆ€tâ‰¥1\\forall t\\geq 1. Let ftâ€‹(x)f\_{t}(x) denote the probability density function of xtx\_{t}. Under policy Ï„\\tau,

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | htÏ„â‰œh(But+wt\|xt)\=12âˆ«âˆ’âˆ+âˆft(xt)log(2Ï€e)d1det(Î¨t(xt)+Î¨w)dxt.\\displaystyle h\_{t}^{\\tau}\\triangleq h(Bu\_{t}+w\_{t}\|x\_{t})=\\frac{1}{2}\\int\_{-\\infty}^{+\\infty}f\_{t}(x\_{t})\\log(2\\pi e)^{d\_{1}}\\det(\\Psi\_{t}(x\_{t})+\\Psi\_{w})dx\_{t}. |     |

Under policy Ï„â€²\\tau^{\\prime}, we can express Bâ€‹utâ€‹(xt)\=Î¸tâ€‹(xt)+stBu\_{t}(x\_{t})=\\theta\_{t}(x\_{t})+s\_{t}, where stâˆ¼ğ’©â€‹(0,Î¦t)s\_{t}\\sim\\mathcal{N}(0,\\Phi\_{t}) is independent of xtx\_{t} and wtw\_{t}. Then

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | htÏ„â€²â‰œh(But+wt\|xt)\=h(st+wt)\=12log(2Ï€e)d1det(Î¦t+Î¨w).\\displaystyle h\_{t}^{\\tau^{\\prime}}\\triangleq h(Bu\_{t}+w\_{t}\|x\_{t})=h(s\_{t}+w\_{t})=\\frac{1}{2}\\log(2\\pi e)^{d\_{1}}\\det(\\Phi\_{t}+\\Psi\_{w}). |     |

Since logâ€‹det(â‹…)\\log\\det(\\cdot) is a concave function, Jensenâ€™s inequality implies:

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | htÏ„\\displaystyle h\_{t}^{\\tau} | \=12â€‹ğ”¼â€‹\[logâ€‹det(Î¨tâ€‹(xt)+Î¨w)\]+d12â€‹logâ¡2â€‹Ï€â€‹e\\displaystyle=\\frac{1}{2}\\mathbb{E}\\left\[\\log\\det(\\Psi\_{t}(x\_{t})+\\Psi\_{w})\\right\]+\\frac{d\_{1}}{2}\\log 2\\pi e |     |
|     |     | â‰¤12â€‹logâ€‹det(ğ”¼â€‹\[Î¨tâ€‹(xt)\]+Î¨w)+d12â€‹logâ¡2â€‹Ï€â€‹e\=htÏ„â€².\\displaystyle\\leq\\frac{1}{2}\\log\\det(\\mathbb{E}\[\\Psi\_{t}(x\_{t})\]+\\Psi\_{w})+\\frac{d\_{1}}{2}\\log 2\\pi e=h\_{t}^{\\tau^{\\prime}}. |     |

It follows immediately that the objective value achieved by Ï„â€²\\tau^{\\prime} is at least as large as that of Ï„\\tau. Combining the above arguments together, the optimal value of the optimization problem ([45](https://arxiv.org/html/2509.16146v1#S7.E45 "In VII-A Converse Proof of Theorem 1 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"))-([46](https://arxiv.org/html/2509.16146v1#S7.E46 "In VII-A Converse Proof of Theorem 1 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) can be attained by policies of the form ut\=Bâ€ â€‹Î¸tâ€‹(xt)+Bâ€ â€‹stu\_{t}=B^{\\dagger}\\theta\_{t}(x\_{t})+B^{\\dagger}s\_{t}, where Î¸tâ€‹(â‹…)\\theta\_{t}(\\cdot) is a deterministic function and stâˆ¼ğ’©â€‹(0,Î¦t)s\_{t}\\sim\\mathcal{N}(0,\\Phi\_{t}) is independent of xtx\_{t} and wtw\_{t}. For notation simplicity, we absorb the constant matrix Bâ€ B^{\\dagger} into the first term and express the type-2 policies in the simplified form ut\=Î¸tâ€‹(xt)+Bâ€ â€‹stu\_{t}=\\theta\_{t}(x\_{t})+B^{\\dagger}s\_{t}.

Report issue for preceding element

We then move on to step 2. We will show that, for an arbitrary policy of the form ut\=Î¸tâ€‹(xt)+Bâ€ â€‹stu\_{t}=\\theta\_{t}(x\_{t})+B^{\\dagger}s\_{t} that achieves an objective value CnC\_{n} and constraint value (i.e., control cost) JnJ\_{n} in problem ([45](https://arxiv.org/html/2509.16146v1#S7.E45 "In VII-A Converse Proof of Theorem 1 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"))-([46](https://arxiv.org/html/2509.16146v1#S7.E46 "In VII-A Converse Proof of Theorem 1 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), there exists a linear policy of the form ut\=âˆ’Ktâ€‹xt+Bâ€ â€‹stu\_{t}=-K\_{t}x\_{t}+B^{\\dagger}s\_{t} that achieves the same objective value while attaining a constraint value of as most JnJ\_{n}.

Report issue for preceding element

In particular, let ut\=Î¸tâ€‹(xt)+Bâ€ â€‹stu\_{t}=\\theta\_{t}(x\_{t})+B^{\\dagger}s\_{t}, where stâˆ¼ğ’©â€‹(0,Î¦t)s\_{t}\\sim\\mathcal{N}(0,\\Phi\_{t}) is independent of both xtx\_{t} and wtw\_{t}. By definition, the control cost of this policy for the nn\-step control problem is given by

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Jn\\displaystyle J\_{n} | \=1nâ€‹âˆ‘t\=1n+1ğ”¼â€‹\[xtâŠ¤â€‹Fâ€‹xt\]+1nâ€‹âˆ‘t\=1nğ”¼â€‹\[utâŠ¤â€‹Gâ€‹ut\]\\displaystyle=\\frac{1}{n}\\sum\_{t=1}^{n+1}\\mathbb{E}\[x^{\\top}\_{t}Fx\_{t}\]+\\frac{1}{n}\\sum\_{t=1}^{n}\\mathbb{E}\[u^{\\top}\_{t}Gu\_{t}\] |     |
|     |     | \=1nâ€‹âˆ‘t\=1n+1ğ”¼â€‹\[xtâŠ¤â€‹Fâ€‹xt\]+1nâ€‹âˆ‘t\=1nğ”¼â€‹\[Î¸tâ€‹(xt)âŠ¤â€‹Gâ€‹Î¸tâ€‹(xt)\]+1nâ€‹âˆ‘t\=1nğ”¼â€‹\[(Bâ€ â€‹st)âŠ¤â€‹Gâ€‹(Bâ€ â€‹st)\]\\displaystyle=\\frac{1}{n}\\sum\_{t=1}^{n+1}\\mathbb{E}\\left\[x^{\\top}\_{t}Fx\_{t}\\right\]+\\frac{1}{n}\\sum\_{t=1}^{n}\\mathbb{E}\\left\[\\theta\_{t}(x\_{t})^{\\top}G\\theta\_{t}(x\_{t})\\right\]+\\frac{1}{n}\\sum\_{t=1}^{n}\\mathbb{E}\[(B^{\\dagger}s\_{t})^{\\top}G(B^{\\dagger}s\_{t})\] |     |
|     |     | â‰œJnâ€²+1nâ€‹âˆ‘t\=1nTrâ€‹(Gâ€‹Bâ€ â€‹Î¦tâ€‹(Bâ€ )âŠ¤).\\displaystyle\\triangleq J^{\\prime}\_{n}+\\frac{1}{n}\\sum\_{t=1}^{n}\\text{Tr}(GB^{\\dagger}\\Phi\_{t}(B^{\\dagger})^{\\top}). |     |

Under this policy, the system state evolves as xt+1\=Aâ€‹xt+Bâ€‹Î¸tâ€‹(xt)+st+wtx\_{t+1}=Ax\_{t}+B\\theta\_{t}(x\_{t})+s\_{t}+w\_{t}. By treating sts\_{t} as an additional noise introduced into the system, we can interpret Jnâ€²J^{\\prime}\_{n} as the control cost of policy u^t\=Î¸tâ€‹(xt)\\hat{u}\_{t}=\\theta\_{t}(x\_{t}) in the following system:

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | xt+1\=Aâ€‹xt+Bâ€‹u^t+wtâ€²,\\displaystyle x\_{t+1}=Ax\_{t}+B\\hat{u}\_{t}+w^{\\prime}\_{t}, |     | (53) |

where the noise wtâ€²\=st+wtâˆ¼ğ’©â€‹(0,Î¦t+Î¨w)w^{\\prime}\_{t}=s\_{t}+w\_{t}\\sim\\mathcal{N}(0,\\Phi\_{t}+\\Psi\_{w}) is independent of xtx\_{t}. Denote by Jnâˆ’J\_{n}^{-} the optimal control cost for system ([53](https://arxiv.org/html/2509.16146v1#S7.E53 "In VII-A Converse Proof of Theorem 1 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")). According to the certainty equivalence principle, the optimal feedback gain depends only on the system dynamics matrices AA and BB, and is independent of the noise variance. Hence u^t\=âˆ’Ktâ€‹xt\\hat{u}\_{t}=-K\_{t}x\_{t} is the optimal control policy for system ([53](https://arxiv.org/html/2509.16146v1#S7.E53 "In VII-A Converse Proof of Theorem 1 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), where KtK\_{t} is the same as that defined in ([3](https://arxiv.org/html/2509.16146v1#S3.E3 "In III-A Linear Quadratic-Gaussian (LQG) Control Systems â€£ III System Model and Preliminaries â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")). It follows that

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Jnâˆ’\=1nâ€‹âˆ‘t\=1n+1ğ”¼â€‹\[xtâŠ¤â€‹Fâ€‹xt\]+1nâ€‹âˆ‘t\=1nğ”¼â€‹\[(Ktâ€‹xt)âŠ¤â€‹Gâ€‹Ktâ€‹xt\]â‰¤Jnâ€².\\displaystyle J^{-}\_{n}=\\frac{1}{n}\\sum\_{t=1}^{n+1}\\mathbb{E}\\left\[x^{\\top}\_{t}Fx\_{t}\\right\]+\\frac{1}{n}\\sum\_{t=1}^{n}\\mathbb{E}\\left\[(K\_{t}x\_{t})^{\\top}GK\_{t}x\_{t}\\right\]\\leq J^{\\prime}\_{n}. |     |

Now, applying the linear policy ut\=âˆ’Ktâ€‹xt+Bâ€ â€‹stu\_{t}=-K\_{t}x\_{t}+B^{\\dagger}s\_{t} to the original system ([1](https://arxiv.org/html/2509.16146v1#S3.E1 "In III-A Linear Quadratic-Gaussian (LQG) Control Systems â€£ III System Model and Preliminaries â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) yields the control cost

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Jnâ€²â€²\\displaystyle J^{\\prime\\prime}\_{n} | \=1nâ€‹âˆ‘t\=1n+1ğ”¼â€‹\[xtâŠ¤â€‹Fâ€‹xt\]+1nâ€‹âˆ‘t\=1nğ”¼â€‹\[utâŠ¤â€‹Gâ€‹ut\]\\displaystyle=\\frac{1}{n}\\sum\_{t=1}^{n+1}\\mathbb{E}\[x^{\\top}\_{t}Fx\_{t}\]+\\frac{1}{n}\\sum\_{t=1}^{n}\\mathbb{E}\[u^{\\top}\_{t}Gu\_{t}\] |     |
|     |     | \=1nâ€‹âˆ‘t\=1n+1ğ”¼â€‹\[xtâŠ¤â€‹Fâ€‹xt\]+1nâ€‹âˆ‘t\=1nğ”¼â€‹\[(Ktâ€‹xt)âŠ¤â€‹Gâ€‹Ktâ€‹xt\]+1nâ€‹âˆ‘t\=1nTrâ€‹(Gâ€‹Bâ€ â€‹Î¦tâ€‹(Bâ€ )âŠ¤)\\displaystyle=\\frac{1}{n}\\sum\_{t=1}^{n+1}\\mathbb{E}\\left\[x^{\\top}\_{t}Fx\_{t}\\right\]+\\frac{1}{n}\\sum\_{t=1}^{n}\\mathbb{E}\\left\[(K\_{t}x\_{t})^{\\top}GK\_{t}x\_{t}\\right\]+\\frac{1}{n}\\sum\_{t=1}^{n}\\text{Tr}(GB^{\\dagger}\\Phi\_{t}(B^{\\dagger})^{\\top}) |     |
|     |     | \=Jnâˆ’+1nâ€‹âˆ‘t\=1nTrâ€‹(Gâ€‹Bâ€ â€‹Î¦tâ€‹(Bâ€ )âŠ¤)\\displaystyle=J^{-}\_{n}+\\frac{1}{n}\\sum\_{t=1}^{n}\\text{Tr}(GB^{\\dagger}\\Phi\_{t}(B^{\\dagger})^{\\top}) |     |
|     |     | â‰¤Jnâ€²+1nâ€‹âˆ‘t\=1nTrâ€‹(Gâ€‹Bâ€ â€‹Î¦tâ€‹(Bâ€ )âŠ¤)\=Jn.\\displaystyle\\leq J^{\\prime}\_{n}+\\frac{1}{n}\\sum\_{t=1}^{n}\\text{Tr}(GB^{\\dagger}\\Phi\_{t}(B^{\\dagger})^{\\top})=J\_{n}. |     |

In addition, it is easy to see that

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | hâ€‹(Bâ€‹(âˆ’Ktâ€‹xt+Bâ€ â€‹st)+wt\|xt)\=hâ€‹(Bâ€‹(Î¸tâ€‹(xt)+Bâ€ â€‹st)+wt\|xt)\=hâ€‹(st+wt).\\displaystyle h(B(-K\_{t}x\_{t}+B^{\\dagger}s\_{t})+w\_{t}\|x\_{t})=h(B(\\theta\_{t}(x\_{t})+B^{\\dagger}s\_{t})+w\_{t}\|x\_{t})=h(s\_{t}+w\_{t}). |     |

Therefore, as far as the optimization problem ([45](https://arxiv.org/html/2509.16146v1#S7.E45 "In VII-A Converse Proof of Theorem 1 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"))-([46](https://arxiv.org/html/2509.16146v1#S7.E46 "In VII-A Converse Proof of Theorem 1 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) is concerned, both the policy ut\=Î¸tâ€‹(xt)+Bâ€ â€‹stu\_{t}=\\theta\_{t}(x\_{t})+B^{\\dagger}s\_{t} and the linear policy ut\=âˆ’Ktâ€‹xt+Bâ€ â€‹stu\_{t}=-K\_{t}x\_{t}+B^{\\dagger}s\_{t} achieve the same objective value. However, the linear policy yields a smaller or equivalent constraint value. This implies that CÂ¯nâ€‹(V)\\bar{C}\_{n}(V) defined in ([45](https://arxiv.org/html/2509.16146v1#S7.E45 "In VII-A Converse Proof of Theorem 1 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"))-([46](https://arxiv.org/html/2509.16146v1#S7.E46 "In VII-A Converse Proof of Theorem 1 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) can be achieved by a linear policy of the form ut\=âˆ’Ktâ€‹xt+Bâ€ â€‹st{u}\_{t}=-K\_{t}x\_{t}+B^{\\dagger}s\_{t}, where stâˆ¼ğ’©â€‹(0,Î¦t)s\_{t}\\sim\\mathcal{N}(0,\\Phi\_{t}) is independent of xtx\_{t}. The desired result is established.

Report issue for preceding element

âˆ

Report issue for preceding element

### VII-B Converse Proof of Theorem [3](https://arxiv.org/html/2509.16146v1#Thmtheorem3 "Theorem 3 â€£ V-A Capacity â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")

Report issue for preceding element

This section presents a converse proof for Theorem [3](https://arxiv.org/html/2509.16146v1#Thmtheorem3 "Theorem 3 â€£ V-A Capacity â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"). As usual, we show that a sequence of (2nâ€‹Rn,n)(2^{nR\_{n}},n) codes with Pe(n)â†’0P\_{e}^{(n)}\\to 0 must have Rnâ‰¤CÂ¯nâ€‹(V)+ÏµnR\_{n}\\leq\\bar{C}\_{n}(V)+\\epsilon\_{n}, where Ïµnâ†’0\\epsilon\_{n}\\to 0 and CÂ¯nâ€‹(V)â†’Cnorâ€‹(V)\\bar{C}\_{n}(V)\\to C\_{\\text{nor}}(V) as nâ†’âˆn\\to\\infty.

Report issue for preceding element

###### Proof:

Report issue for preceding element

By Fanoâ€™s inequality,

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | nâ€‹Rn\=Hâ€‹(m)\\displaystyle nR\_{n}=H(m) | \=Hâ€‹(m\|zn+1)+Iâ€‹(m;zn+1)\\displaystyle=H(m\|z^{n+1})+I(m;z^{n+1}) |     |
|     |     | \=Iâ€‹(m;zn+1)+nâ€‹Ïµn,\\displaystyle=I(m;z^{n+1})+n\\epsilon\_{n}, |     |

where Ïµnâ†’0\\epsilon\_{n}\\to 0 if Pe(n)â†’0P\_{e}^{(n)}\\to 0. We thus define a series of optimization problems as follows: for nâ‰¥1n\\geq 1,

Report issue for preceding element

|     |     |     |     |     |
| --- | --- | --- | --- | --- |
|     | C^nâ€‹(V):=max\\displaystyle\\hat{C}\_{n}(V):=\\max\\ | 1nâ€‹Iâ€‹(m;zn+1)\\displaystyle\\frac{1}{n}I(m;z^{n+1}) |     | (54) |
|     | s.t. | Jnâ‰¤Jâˆ—+V.\\displaystyle J\_{n}\\leq J^{\*}+V. |     | (55) |

The goal is to establish an upper bound for C^nâ€‹(V)\\hat{C}\_{n}(V), say C^nâ€‹(V)â‰¤CÂ¯nâ€‹(V)\\hat{C}\_{n}(V)\\leq\\bar{C}\_{n}(V), and show that CÂ¯nâ€‹(V)\\bar{C}\_{n}(V) converges to Cnorâ€‹(V)C\_{\\text{nor}}(V) as nâ†’âˆn\\to\\infty. To this end, we first analyse the form of the optimal input for this optimization problem, as summarized below:

Report issue for preceding element

###### Lemma 7

Report issue for preceding element

For any nâ‰¥1n\\geq 1, C^nâ€‹(V)\\hat{C}\_{n}(V) defined in ([54](https://arxiv.org/html/2509.16146v1#S7.E54 "In VII-B Converse Proof of Theorem 3 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"))-([55](https://arxiv.org/html/2509.16146v1#S7.E55 "In VII-B Converse Proof of Theorem 3 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) can be optimized by policies of the form ut\=âˆ’Kâ€‹xt+Bâ€ â€‹stu\_{t}=-Kx\_{t}+B^{\\dagger}s\_{t}, where stâˆ¼ğ’©â€‹(0,Î¦)s\_{t}\\sim\\mathcal{N}(0,\\Phi) is independent of {wi}\\{w\_{i}\\} and {xi}\\{x\_{i}\\}.

Report issue for preceding element

###### Proof:

Report issue for preceding element

Proof of the lemma is presented immediately after the converse proof. âˆ

Report issue for preceding element

Lemma [7](https://arxiv.org/html/2509.16146v1#Thmlemma7 "Lemma 7 â€£ VII-B Converse Proof of Theorem 3 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") allows us to focus on the class of input policies taking the form ut\=âˆ’Kâ€‹xt+Bâ€ â€‹stu\_{t}=-Kx\_{t}+B^{\\dagger}s\_{t}, which could significantly simplify the problem. Let us first rewrite Iâ€‹(m;zn+1)I(m;z^{n+1}) as follows

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Iâ€‹(m;zn+1)\\displaystyle I(m;z^{n+1}) | \=hâ€‹(zn+1)âˆ’hâ€‹(zn+1\|m)\\displaystyle=h(z^{n+1})-h(z^{n+1}\|m) |     |
|     |     | \=hâ€‹(z1)âˆ’hâ€‹(z1\|m)+âˆ‘t\=1n\[hâ€‹(zt+1\|zt)âˆ’hâ€‹(zt+1\|zt,m)\].\\displaystyle=h(z\_{1})-h(z\_{1}\|m)+\\sum\_{t=1}^{n}\[h(z\_{t+1}\|z^{t})-h(z\_{t+1}\|z^{t},m)\]. |     |

Note that hâ€‹(z1)âˆ’hâ€‹(z1|m)\=0h(z\_{1})-h(z\_{1}|m)=0 because z1z\_{1} and mm are independent. Under the policy ut\=âˆ’Kâ€‹xt+Bâ€ â€‹stu\_{t}=-Kx\_{t}+B^{\\dagger}s\_{t}, we have

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | hâ€‹(zt+1\|zt)\\displaystyle h(z\_{t+1}\|z^{t}) | \=hâ€‹(Dâ€‹(AÂ¯â€‹xt+st+wt)+vt+1\|zt)\\displaystyle=h(D(\\bar{A}x\_{t}+s\_{t}+w\_{t})+v\_{t+1}\|z^{t}) |     |
|     |     | \=hâ€‹(Dâ€‹(AÂ¯â€‹(x^t\|t+Ïƒt)+st+wt)+vt+1\|zt,x^t\|t)\\displaystyle=h(D(\\bar{A}(\\hat{x}\_{t\|t}+\\sigma\_{t})+s\_{t}+w\_{t})+v\_{t+1}\|z^{t},\\hat{x}\_{t\|t}) |     |
|     |     | \=hâ€‹(Dâ€‹(AÂ¯â€‹Ïƒt+st+wt)+vt+1),\\displaystyle=h(D(\\bar{A}\\sigma\_{t}+s\_{t}+w\_{t})+v\_{t+1}), |     |

where AÂ¯\=Aâˆ’Bâ€‹K,x^t|t\=ğ”¼â€‹\[xt|zt\]\\bar{A}=A-BK,\\hat{x}\_{t|t}=\\mathbb{E}\[x\_{t}|z^{t}\] and Ïƒt\=xtâˆ’x^t|t\\sigma\_{t}=x\_{t}-\\hat{x}\_{t|t}. Since st,wts\_{t},w\_{t} and vt+1v\_{t+1} are all independent of ztz^{t} and xtx\_{t}, they are also independent of Ïƒt\\sigma\_{t}. Also, we have

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | hâ€‹(zt+1\|zt,m)\\displaystyle h(z\_{t+1}\|z^{t},m) | \=hâ€‹(Dâ€‹(AÂ¯â€‹xt+st+wt)+vt+1\|zt,m)\\displaystyle=h(D(\\bar{A}x\_{t}+s\_{t}+w\_{t})+v\_{t+1}\|z^{t},m) |     |
|     |     | â‰¥hâ€‹(Dâ€‹(AÂ¯â€‹xt+st+wt)+vt+1\|zt,st,m)\\displaystyle\\geq h(D(\\bar{A}x\_{t}+s\_{t}+w\_{t})+v\_{t+1}\|z^{t},s^{t},m) |     |
|     |     | \=hâ€‹(Dâ€‹(AÂ¯â€‹(xÂ¯t+ÏƒÂ¯t)+wt)+vt+1\|zt,st,xÂ¯t,m)\\displaystyle=h(D(\\bar{A}(\\bar{x}\_{t}+\\bar{\\sigma}\_{t})+w\_{t})+v\_{t+1}\|z^{t},s^{t},\\bar{x}\_{t},m) |     |
|     |     | \=hâ€‹(Dâ€‹(AÂ¯â€‹ÏƒÂ¯t+wt)+vt+1),\\displaystyle=h(D(\\bar{A}\\bar{\\sigma}\_{t}+w\_{t})+v\_{t+1}), |     |

where xÂ¯t\=ğ”¼â€‹\[xt|zt,st\]\\bar{x}\_{t}=\\mathbb{E}\[x\_{t}|z^{t},s^{t}\] and ÏƒÂ¯t\=xtâˆ’xÂ¯t\\bar{\\sigma}\_{t}=x\_{t}-\\bar{x}\_{t}. Similarly, ÏƒÂ¯t\\bar{\\sigma}\_{t} is independent of wtw\_{t} and vt+1v\_{t+1}. Note that both x^t\\hat{x}\_{t} and xÂ¯t\\bar{x}\_{t} can be computed by Kalman filter. Denote by Î£t|t\\Sigma\_{t|t} and Î¨t|t\\Psi\_{t|t} the covariance of Ïƒt\\sigma\_{t} and ÏƒÂ¯t\\bar{\\sigma}\_{t}, respectively. We thus have

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | 1nâ€‹Iâ€‹(m;zn+1)â‰¤12â€‹nâ€‹âˆ‘t\=1nlogâ¡Dâ€‹(AÂ¯â€‹Î£t\|tâ€‹AÂ¯âŠ¤+Î¦+Î¨w)â€‹DâŠ¤+Î¨vDâ€‹(AÂ¯â€‹Î¨t\|tâ€‹AÂ¯âŠ¤+Î¨w)â€‹DâŠ¤+Î¨v.\\displaystyle\\frac{1}{n}I(m;z^{n+1})\\leq\\frac{1}{2n}\\sum\_{t=1}^{n}\\log\\frac{D(\\bar{A}\\Sigma\_{t\|t}\\bar{A}^{\\top}+\\Phi+\\Psi\_{w})D^{\\top}+\\Psi\_{v}}{D(\\bar{A}\\Psi\_{t\|t}\\bar{A}^{\\top}+\\Psi\_{w})D^{\\top}+\\Psi\_{v}}. |     | (56) |

We can thus define CÂ¯nâ€‹(V)\\bar{C}\_{n}(V) as the maximization problem whose objective is the right-hand side of ([56](https://arxiv.org/html/2509.16146v1#S7.E56 "In VII-B Converse Proof of Theorem 3 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), subject to the constraint in ([55](https://arxiv.org/html/2509.16146v1#S7.E55 "In VII-B Converse Proof of Theorem 3 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")). Under this construction, we have Rnâ‰¤C^nâ€‹(V)â‰¤CÂ¯nâ€‹(V)R\_{n}\\leq\\hat{C}\_{n}(V)\\leq\\bar{C}\_{n}(V) for all nn.

Report issue for preceding element

As we discussed in the achievability proof, as tâ†’âˆt\\to\\infty, Î£t+1|t\=AÂ¯â€‹Î£t|tâ€‹AÂ¯âŠ¤+Î¦+Î¨w\\Sigma\_{t+1|t}=\\bar{A}\\Sigma\_{t|t}\\bar{A}^{\\top}+\\Phi+\\Psi\_{w} converges to Î£{\\Sigma} given in ([16](https://arxiv.org/html/2509.16146v1#S5.E16 "In V-B Kalman Filter and Smoother â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), and Î¨t+1|t\=AÂ¯â€‹Î¨t|tâ€‹AÂ¯âŠ¤+Î¨w\\Psi\_{t+1|t}=\\bar{A}\\Psi\_{t|t}\\bar{A}^{\\top}+\\Psi\_{w} converges to Î¨Ïƒ{\\Psi}\_{\\sigma} given in ([28](https://arxiv.org/html/2509.16146v1#S5.E28 "In V-C Achievability Proof â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")). Consequently,

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | limnâ†’âˆ1nâ€‹Iâ€‹(m;zn+1)â‰¤12â€‹logâ¡det(Î¨v+Dâ€‹Î£â€‹DâŠ¤)det(Î¨v+Dâ€‹Î¨Ïƒâ€‹DâŠ¤).\\displaystyle\\lim\_{n\\to\\infty}\\frac{1}{n}I(m;z^{n+1})\\leq\\frac{1}{2}\\log\\frac{\\det(\\Psi\_{v}+D\\Sigma D^{\\top})}{\\det(\\Psi\_{v}+D\\Psi\_{\\sigma}D^{\\top})}. |     |

Then, as nâ†’âˆn\\to\\infty, CÂ¯nâ€‹(V)\\bar{C}\_{n}(V) defined by ([54](https://arxiv.org/html/2509.16146v1#S7.E54 "In VII-B Converse Proof of Theorem 3 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"))-([55](https://arxiv.org/html/2509.16146v1#S7.E55 "In VII-B Converse Proof of Theorem 3 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) converges to the following problem:

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | CÂ¯âˆâ€‹(V):=maxÎ¦â‰¥0\\displaystyle\\bar{C}\_{\\infty}(V):=\\max\_{\\Phi\\geq 0}\\ | 12â€‹logâ¡det(Î¨v+Dâ€‹Î£â€‹DâŠ¤)det(Î¨v+Dâ€‹Î¨Ïƒâ€‹DâŠ¤)\\displaystyle\\frac{1}{2}\\log\\frac{\\det(\\Psi\_{v}+D\\Sigma D^{\\top})}{\\det(\\Psi\_{v}+D\\Psi\_{\\sigma}D^{\\top})} |     |
|     | s.t. | Trâ€‹((Î“+G^)â€‹Î¦)â‰¤V,\\displaystyle\\text{Tr}((\\Gamma+\\hat{G})\\Phi)\\leq V, |     |

where, by definition, Î¨Ïƒ\\Psi\_{\\sigma} and Î£\\Sigma are given by

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Î¨Ïƒ\\displaystyle\\Psi\_{\\sigma} | \=AÂ¯â€‹(Î¨Ïƒâˆ’Î¨Ïƒâ€‹DâŠ¤â€‹(Dâ€‹Î¨Ïƒâ€‹DâŠ¤+Î¨v)âˆ’1â€‹Dâ€‹Î¨Ïƒ)â€‹AÂ¯+Î¨w,\\displaystyle=\\bar{A}(\\Psi\_{\\sigma}-\\Psi\_{\\sigma}D^{\\top}(D\\Psi\_{\\sigma}D^{\\top}+\\Psi\_{v})^{-1}D\\Psi\_{\\sigma})\\bar{A}+\\Psi\_{w}, |     |
|     | Î£\\displaystyle\\Sigma | \=AÂ¯â€‹(Î£âˆ’Î£â€‹DâŠ¤â€‹(Dâ€‹Î£â€‹DâŠ¤+Î¨v)âˆ’1â€‹Dâ€‹Î£)â€‹AÂ¯âŠ¤+Î¨w+Î¦.\\displaystyle=\\bar{A}\\left(\\Sigma-\\Sigma D^{\\top}(D\\Sigma D^{\\top}+\\Psi\_{v})^{-1}D\\Sigma\\right)\\bar{A}^{\\top}+\\Psi\_{w}+\\Phi. |     |

Note that Î¨Ïƒ\\Psi\_{\\sigma} is independent of Î¦\\Phi, while Î£\\Sigma is a function of Î¦\\Phi. It follows immediately that CÂ¯âˆâ€‹(V)\=Cnrâ€‹(V)\\bar{C}\_{\\infty}(V)=C\_{\\text{nr}}(V). This completes the converse proof. âˆ

Report issue for preceding element

Lemma [7](https://arxiv.org/html/2509.16146v1#Thmlemma7 "Lemma 7 â€£ VII-B Converse Proof of Theorem 3 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") plays a central role in the converse proof presented above. Its proof is given below.

Report issue for preceding element

###### Proof:

Report issue for preceding element

We first decompose Iâ€‹(m;zn+1)I(m;z^{n+1}) as follows:

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Iâ€‹(m;zn+1)\\displaystyle I(m;z^{n+1}) | \=Iâ€‹(m;xn+1)âˆ’Iâ€‹(m;xn+1\|zn+1)\\displaystyle=I(m;x^{n+1})-I(m;x^{n+1}\|z^{n+1}) |     |
|     |     | \=hâ€‹(xn+1)âˆ’hâ€‹(xn+1\|m)âˆ’\[hâ€‹(xn+1\|zn+1)âˆ’hâ€‹(xn+1\|m,zn+1)\].\\displaystyle=h(x^{n+1})-h(x^{n+1}\|m)-\[h(x^{n+1}\|z^{n+1})-h(x^{n+1}\|m,z^{n+1})\]. |     |

It is easy to see that hâ€‹(xn+1|m)h(x^{n+1}|m) and hâ€‹(xn+1|zn+1)h(x^{n+1}|z^{n+1}) are independent of the input policy:

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | hâ€‹(xn+1\|m)\\displaystyle h(x^{n+1}\|m) | \=hâ€‹(x1\|m)+âˆ‘t\=1nhâ€‹(xt+1\|xt,m)\\displaystyle=h(x\_{1}\|m)+\\sum\_{t=1}^{n}h(x\_{t+1}\|x^{t},m) |     |
|     |     | \=hâ€‹(x1)+âˆ‘t\=1nhâ€‹(Aâ€‹xt+Bâ€‹ut+wt\|xt,m,ut)\\displaystyle=h(x\_{1})+\\sum\_{t=1}^{n}h(Ax\_{t}+Bu\_{t}+w\_{t}\|x^{t},m,u\_{t}) |     |
|     |     | \=hâ€‹(x1)+âˆ‘t\=1nhâ€‹(wt).\\displaystyle=h(x\_{1})+\\sum\_{t=1}^{n}h(w\_{t}). |     |

The second equality holds because utu\_{t} is a function of xtx^{t} and mm. For hâ€‹(xn+1|zn+1)h(x^{n+1}|z^{n+1}), an application of the chain rule yields

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | hâ€‹(xn+1\|zn+1)\\displaystyle h(x^{n+1}\|z^{n+1}) | \=hâ€‹(x1\|zn+1)+âˆ‘t\=1nhâ€‹(xt+1\|xt,zn+1)\\displaystyle=h(x\_{1}\|z^{n+1})+\\sum\_{t=1}^{n}h(x\_{t+1}\|x^{t},z^{n+1}) |     |
|     |     | \=hâ€‹(Dâˆ’1â€‹(z1âˆ’v1)\|zn+1)+âˆ‘t\=1nhâ€‹(Dâˆ’1â€‹(zt+1âˆ’vt+1)\|xt,zn+1)\\displaystyle=h(D^{-1}(z\_{1}-v\_{1})\|z^{n+1})+\\sum\_{t=1}^{n}h(D^{-1}(z\_{t+1}-v\_{t+1})\|x^{t},z^{n+1}) |     |
|     |     | \=âˆ‘t\=1n+1hâ€‹(Dâˆ’1â€‹vt).\\displaystyle=\\sum\_{t=1}^{n+1}h(D^{-1}v\_{t}). |     |

We proceed to show that hâ€‹(xn+1|zn+1,m)h(x^{n+1}|z^{n+1},m) is also independent of the input. An application of the chain rule yields

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | hâ€‹(xn+1\|zn+1,m)\=hâ€‹(x1\|zn+1,m)+âˆ‘t\=1nhâ€‹(xt+1\|xt,zn+1,m).\\displaystyle h(x^{n+1}\|z^{n+1},m)=h(x\_{1}\|z^{n+1},m)+\\sum\_{t=1}^{n}h(x\_{t+1}\|x^{t},z^{n+1},m). |     |

Clearly hâ€‹(x1|zn+1,m)h(x\_{1}|z^{n+1},m) is independent of the input policy. For the remaining terms, note that both pâ€‹(xt+1|xt,m)p(x\_{t+1}|x^{t},m) and pâ€‹(xt+1|zn+1)p(x\_{t+1}|z^{n+1}) are Gaussian with covariance matrices that are constants. In particular, we have

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | pâ€‹(xt+1\|xt,m)\\displaystyle p(x\_{t+1}\|x^{t},m) | \=ğ’©â€‹(xt+1;Aâ€‹xt+Bâ€‹ut,Î¨w),\\displaystyle=\\mathcal{N}(x\_{t+1};Ax\_{t}+Bu\_{t},\\Psi\_{w}), |     |
|     | pâ€‹(xt+1\|zn+1)\\displaystyle p(x\_{t+1}\|z^{n+1}) | \=ğ’©â€‹(xt+1;Dâˆ’1â€‹zt+1,Dâˆ’1â€‹Î¨vâ€‹(Dâˆ’1)âŠ¤).\\displaystyle=\\mathcal{N}(x^{t+1};D^{-1}z\_{t+1},D^{-1}\\Psi\_{v}(D^{-1})^{\\top}). |     |

From the standard Gaussian fusion rule,

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | pâ€‹(xt+1\|zn+1,xt,m)\=ğ’©â€‹(xt+1;Î¼f,Î£f)âˆpâ€‹(xt+1\|xt,m)â€‹pâ€‹(xt+1\|zn+1),\\displaystyle p(x\_{t+1}\|z^{n+1},x^{t},m)=\\mathcal{N}(x^{t+1};\\mu\_{f},\\Sigma\_{f})\\propto p(x\_{t+1}\|x^{t},m)p(x\_{t+1}\|z^{n+1}), |     |

where Î£fâˆ’1\=Î¨wâˆ’1+\[Dâˆ’1â€‹Î¨vâ€‹(Dâˆ’1)âŠ¤\]âˆ’1\\Sigma\_{f}^{-1}=\\Psi\_{w}^{-1}+\[D^{-1}\\Psi\_{v}(D^{-1})^{\\top}\]^{-1}. Since Î£f\\Sigma\_{f} a constant and independent of the input policy, hâ€‹(xt+1|xt,zn+1,m)h(x\_{t+1}|x^{t},z^{n+1},m) is also independent of the input policy for all tt, implying that hâ€‹(xn+1|zn+1,m)h(x^{n+1}|z^{n+1},m) is independent of the input policy. We thus have

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | argâ¡maxpâ€‹(un)â¡Iâ€‹(m;zn+1)\=argâ¡maxpâ€‹(un)â¡hâ€‹(xn+1).\\displaystyle\\arg\\max\_{p(u^{n})}I(m;z^{n+1})=\\arg\\max\_{p(u^{n})}h(x^{n+1}). |     | (57) |

Now,

Report issue for preceding element

|     |     |     |     |     |
| --- | --- | --- | --- | --- |
|     | maxpâ€‹(un)â¡hâ€‹(xn+1)\\displaystyle\\max\_{p(u^{n})}h(x^{n+1}) | \=maxpâ€‹(un)â¡hâ€‹(x1)+âˆ‘t\=1nhâ€‹(Aâ€‹xt+Bâ€‹ut+wt\|xt)\\displaystyle=\\max\_{p(u^{n})}h(x\_{1})+\\sum\_{t=1}^{n}h(Ax\_{t}+Bu\_{t}+w\_{t}\|x^{t}) |     | (58) |
|     |     | â‰¤maxpâ€‹(un)â¡hâ€‹(x1)+âˆ‘t\=1nhâ€‹(Bâ€‹ut+wt\|xt).\\displaystyle\\leq\\max\_{p(u^{n})}h(x\_{1})+\\sum\_{t=1}^{n}h(Bu\_{t}+w\_{t}\|x\_{t}). |     | (59) |

The inequality holds with equality if the objective hâ€‹(x1)+âˆ‘t\=1nhâ€‹(Bâ€‹ut+wt|xt)h(x\_{1})+\\sum\_{t=1}^{n}h(Bu\_{t}+w\_{t}|x\_{t}) is maximized by a Markov policy (i.e., when utu\_{t} is conditionally independent of xtâˆ’1x^{t-1} given xtx\_{t}). This condition is indeed satisfied, as shown in the converse proof of Theorem [1](https://arxiv.org/html/2509.16146v1#Thmtheorem1 "Theorem 1 â€£ IV-A Capacity â€£ IV Noiseless Observations at the Controller and the Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"). In particular, Lemma [6](https://arxiv.org/html/2509.16146v1#Thmlemma6 "Lemma 6 â€£ VII-A Converse Proof of Theorem 1 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") implies that that the objective in ([59](https://arxiv.org/html/2509.16146v1#S7.E59 "In VII-B Converse Proof of Theorem 3 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), subject to the constraint Jnâ‰¤Jâˆ—+VJ\_{n}\\leq J^{\*}+V, is maximized by the stationary Markov policy ut\=âˆ’Kâ€‹xt+Bâ€ â€‹stu\_{t}=-Kx\_{t}+B^{\\dagger}s\_{t}, where stâˆ¼ğ’©â€‹(0,Î¦)s\_{t}\\sim\\mathcal{N}(0,\\Phi) is independent of xtx\_{t}. We thus conclude that, under the constraint Jnâ‰¤Jâˆ—+VJ\_{n}\\leq J^{\*}+V, Iâ€‹(m;zn+1)I(m;z^{n+1}) is also maximized by the policy ut\=âˆ’Kâ€‹xt+Bâ€ â€‹stu\_{t}=-Kx\_{t}+B^{\\dagger}s\_{t}.

Report issue for preceding element

âˆ

Report issue for preceding element

### VII-C Proof of Theorem [4](https://arxiv.org/html/2509.16146v1#Thmtheorem4 "Theorem 4 â€£ VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")

Report issue for preceding element

Thi section presents the proofs of Theorem [4](https://arxiv.org/html/2509.16146v1#Thmtheorem4 "Theorem 4 â€£ VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") and Lemma [5](https://arxiv.org/html/2509.16146v1#Thmlemma5 "Lemma 5 (Channel Translation) â€£ VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"). The lower bound Cno-lbâ€‹(V)C\_{\\text{no-lb}}(V) in Theorem [4](https://arxiv.org/html/2509.16146v1#Thmtheorem4 "Theorem 4 â€£ VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") corresponds to the capacity of the Gaussian channel stated in Lemma [5](https://arxiv.org/html/2509.16146v1#Thmlemma5 "Lemma 5 (Channel Translation) â€£ VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"), subject to the control constraint Jâ‰¤Jâˆ—âˆ—+VJ\\leq J^{\*\*}+V. According to Lemma [4](https://arxiv.org/html/2509.16146v1#Thmlemma4 "Lemma 4 â€£ VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"), the control constraint is equivalent to an input power constraint Trâ€‹(Î¦â€‹(Î“+G^))â‰¤V\\text{Tr}(\\Phi(\\Gamma+\\hat{G}))\\leq V. Before proving Theorem [4](https://arxiv.org/html/2509.16146v1#Thmtheorem4 "Theorem 4 â€£ VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"), we first establish Lemma [5](https://arxiv.org/html/2509.16146v1#Thmlemma5 "Lemma 5 (Channel Translation) â€£ VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"), as some arguments in this proof are useful in the subsequent derivations.

Report issue for preceding element

###### Proof:

Report issue for preceding element

Since we have fixed the input policy to be ut\=âˆ’Kâ€‹xË‡t|t+Bâ€ â€‹stu\_{t}=-K\\check{x}\_{t|t}+B^{\\dagger}s\_{t}, the key question is how the receiver can construct a channel output from its observations without losing any information about the input. We begin with the linear system defined in ([41](https://arxiv.org/html/2509.16146v1#S6.E41 "In VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"))â€“([42](https://arxiv.org/html/2509.16146v1#S6.E42 "In VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), which provides an equivalent representation of the system from the receiverâ€™s perspective. For ease of reading, we restate the system equations ([41](https://arxiv.org/html/2509.16146v1#S6.E41 "In VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"))â€“([42](https://arxiv.org/html/2509.16146v1#S6.E42 "In VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) below:

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Ït+1\\displaystyle\\rho\_{t+1} | \=AÏâ€‹Ït+sÂ¯t+wÂ¯t+qÂ¯t+1,\\displaystyle=A\_{\\rho}\\rho\_{t}+\\bar{s}\_{t}+\\bar{w}\_{t}+\\bar{q}\_{t+1}, |     |
|     | zt\\displaystyle z\_{t} | \=DÏâ€‹Ït+vt.\\displaystyle=D\_{\\rho}\\rho\_{t}+v\_{t}. |     |

In this new system, estimates of state Ï^t|t\=ğ”¼â€‹\[Ït|zt\]\\hat{\\rho}\_{t|t}=\\mathbb{E}\[\\rho\_{t}|z^{t}\] and Ï^t|t+1\=ğ”¼â€‹\[Ït|zt+1\]\\hat{\\rho}\_{t|t+1}=\\mathbb{E}\[\\rho\_{t}|z^{t+1}\] can be computed using the standard Kalman filter and smoother, respectively. In particular, in the prediction stage, the Kalman filter computes Ï^t+1|t\=AÏâ€‹Ï^t|t\\hat{\\rho}\_{t+1|t}=A\_{\\rho}\\hat{\\rho}\_{t|t} and the associated estimation error covariance matrix

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Î£t+1\|t\=AÏâ€‹Î£t\|tâ€‹AÏâŠ¤+Î¦Â¯+Î¨wÂ¯+Î¨qÂ¯.\\displaystyle\\Sigma\_{t+1\|t}=A\_{\\rho}\\Sigma\_{t\|t}A\_{\\rho}^{\\top}+\\bar{\\Phi}+\\Psi\_{\\bar{w}}+\\Psi\_{\\bar{q}}. |     |

Upon receiving the new observation zt+1z\_{t+1}, the Kalman filter updates the estimate as follows:

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Ï^t+1\|t+1\=Ï^t+1\|t+Lt+1â€‹(zt+1âˆ’DÏâ€‹Ï^t+1\|t),\\displaystyle\\hat{\\rho}\_{t+1\|t+1}=\\hat{\\rho}\_{t+1\|t}+L\_{t+1}(z\_{t+1}-D\_{\\rho}\\hat{\\rho}\_{t+1\|t}), |     |

where L\_t+1 = Î£\_t+1â€”t D\_Ï^âŠ¤(D\_ÏÎ£\_t+1â€”tD\_Ï^âŠ¤+ Î¨\_v )^-1. The associated estimation error is given by Î£\_t+1â€”t+1= (I-L\_t+1D\_Ï)Î£\_t+1â€”t. As tâ†’âˆt\\to\\infty, Î£t+1|t\\Sigma\_{t+1|t} converges to Î£Ï\\Sigma\_{\\rho}, which is determined by the DARE:

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Î£Ï\=AÏâ€‹(Î£Ïâˆ’Î£Ïâ€‹DÏâŠ¤â€‹(DÏâ€‹Î£Ïâ€‹DÏâŠ¤+Î¨v)âˆ’1â€‹DÏâ€‹Î£Ï)â€‹AÏâŠ¤+Î¦Â¯+Î¨wÂ¯+Î¨qÂ¯.\\displaystyle\\Sigma\_{\\rho}={A}\_{\\rho}\\left(\\Sigma\_{\\rho}-\\Sigma\_{\\rho}D\_{\\rho}^{\\top}(D\_{\\rho}\\Sigma\_{\\rho}D\_{\\rho}^{\\top}+\\Psi\_{v})^{-1}D\_{\\rho}\\Sigma\_{\\rho}\\right){A}\_{\\rho}^{\\top}+\\bar{\\Phi}+\\Psi\_{\\bar{w}}+\\Psi\_{\\bar{q}}. |     | (60) |

Accordingly,

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | LÏâ‰œlimtâ†’âˆLt\=Î£Ïâ€‹DÏâŠ¤â€‹(DÏâ€‹Î£Ïâ€‹DÏâŠ¤+Î¨v)âˆ’1,\\displaystyle L\_{\\rho}\\triangleq\\lim\_{t\\to\\infty}L\_{t}=\\Sigma\_{\\rho}D\_{\\rho}^{\\top}(D\_{\\rho}\\Sigma\_{\\rho}D\_{\\rho}^{\\top}+\\Psi\_{v})^{-1}, |     |
|     | Î£~Ïâ‰œlimtâ†’âˆÎ£t\|t\=(Iâˆ’LÏâ€‹DÏ)â€‹Î£Ï.\\displaystyle\\tilde{\\Sigma}\_{\\rho}\\triangleq\\lim\_{t\\to\\infty}\\Sigma\_{t\|t}=(I-L\_{\\rho}D\_{\\rho})\\Sigma\_{\\rho}. |     |

As in Section [V-B](https://arxiv.org/html/2509.16146v1#S5.SS2 "V-B Kalman Filter and Smoother â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"), the smoothing problem can be solved by the Kalman smoother, which computes

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Ï^t\|t+1\=Ï^t\|t+Qtâ€‹(Ï^t+1\|t+1âˆ’AÏâ€‹Ï^t\|t),\\displaystyle\\hat{\\rho}\_{t\|t+1}=\\hat{\\rho}\_{t\|t}+Q\_{t}\\left(\\hat{\\rho}\_{t+1\|t+1}-{A}\_{\\rho}\\hat{\\rho}\_{t\|t}\\right), |     | (61) |

where the smooth gain Qt\=Î£t|tâ€‹AÏâŠ¤â€‹Î£t+1|tâˆ’1Q\_{t}=\\Sigma\_{t|t}{A}\_{\\rho}^{\\top}\\Sigma\_{t+1|t}^{-1}. Since Î£t+1|t\\Sigma\_{t+1|t} and Î£t|t\\Sigma\_{t|t} converge, it is clear that QtQ\_{t} also converges as tâ†’âˆt\\to\\infty:

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | QÏâ‰œlimtâ†’âˆQt\=(Iâˆ’LÏâ€‹DÏ)â€‹Î£Ïâ€‹AÏâŠ¤â€‹Î£Ïâˆ’1.\\displaystyle Q\_{\\rho}\\triangleq\\lim\_{t\\to\\infty}Q\_{t}=(I-L\_{\\rho}D\_{\\rho})\\Sigma\_{\\rho}{A}\_{\\rho}^{\\top}\\Sigma\_{\\rho}^{-1}. |     | (62) |

Note that

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Î£t+1\|t\=Covâ€‹(Ïtâˆ’Ï^t+1\|t)\=\[Covâ€‹(xtâˆ’x^t+1\|t)ğ”¼â€‹\[(xtâˆ’x^t+1\|t)â€‹(etâˆ’e^t+1\|t)âŠ¤\]ğ”¼â€‹\[(etâˆ’e^t+1\|t)â€‹(xtâˆ’x^t+1\|t)âŠ¤\]Covâ€‹(etâˆ’e^t+1\|t)\].\\displaystyle\\Sigma\_{t+1\|t}=\\text{Cov}(\\rho\_{t}-\\hat{\\rho}\_{t+1\|t})=\\begin{bmatrix}\\text{Cov}(x\_{t}-\\hat{x}\_{t+1\|t})&\\mathbb{E}\[(x\_{t}-\\hat{x}\_{t+1\|t})(e\_{t}-\\hat{e}\_{t+1\|t})^{\\top}\]\\\\ \\mathbb{E}\[(e\_{t}-\\hat{e}\_{t+1\|t})(x\_{t}-\\hat{x}\_{t+1\|t})^{\\top}\]&\\text{Cov}(e\_{t}-\\hat{e}\_{t+1\|t})\\end{bmatrix}. |     |

We thus can write Î£Ï\\Sigma\_{\\rho} as a block matrix as follows:

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Î£Ïâ‰œ\[Î£11Î£12Î£21Î£22\],\\displaystyle\\Sigma\_{\\rho}\\triangleq\\begin{bmatrix}\\Sigma\_{11}&\\Sigma\_{12}\\\\ \\Sigma\_{21}&\\Sigma\_{22}\\end{bmatrix}, |     |

where Î£11\=Covâ€‹(xtâˆ’x^t+1|t)âˆˆâ„d1Ã—d1\\Sigma\_{11}=\\text{Cov}(x\_{t}-\\hat{x}\_{t+1|t})\\in\\mathbb{R}^{d\_{1}\\times d\_{1}} and Î£22\=Covâ€‹(etâˆ’e^t+1|t)âˆˆâ„d1Ã—d1\\Sigma\_{22}=\\text{Cov}(e\_{t}-\\hat{e}\_{t+1|t})\\in\\mathbb{R}^{d\_{1}\\times d\_{1}} are both positive definite. As a result, we can also write

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | LÏ\=\[LÏâ€‹1LÏâ€‹2\]â‰œ\[Î£11â€‹DâŠ¤â€‹(Dâ€‹Î£11â€‹DâŠ¤+Î¨v)âˆ’1Î£21â€‹DâŠ¤â€‹(Dâ€‹Î£11â€‹DâŠ¤+Î¨v)âˆ’1\],\\displaystyle L\_{\\rho}=\\begin{bmatrix}L\_{\\rho 1}\\\\ L\_{\\rho 2}\\end{bmatrix}\\triangleq\\begin{bmatrix}\\Sigma\_{11}D^{\\top}(D\\Sigma\_{11}D^{\\top}+\\Psi\_{v})^{-1}\\\\ \\Sigma\_{21}D^{\\top}(D\\Sigma\_{11}D^{\\top}+\\Psi\_{v})^{-1}\\end{bmatrix}, |     | (63) |

and

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Î£~Ï\=\[(Iâˆ’LÏâ€‹1â€‹D)â€‹Î£11(Iâˆ’LÏâ€‹1â€‹D)â€‹Î£12(Iâˆ’LÏâ€‹2â€‹D)â€‹Î£21(Iâˆ’LÏâ€‹2â€‹D)â€‹Î£22\].\\displaystyle\\tilde{\\Sigma}\_{\\rho}=\\begin{bmatrix}(I-L\_{\\rho 1}D)\\Sigma\_{11}&(I-L\_{\\rho 1}D)\\Sigma\_{12}\\\\ (I-L\_{\\rho 2}D)\\Sigma\_{21}&(I-L\_{\\rho 2}D)\\Sigma\_{22}\\end{bmatrix}. |     | (64) |

Now, let us define

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | ytâ‰œÏt+1âˆ’AÏâ€‹Ït\=sÂ¯t+wÂ¯t+qÂ¯t+1\=\[st+wt(Iâˆ’Lcâ€‹Dc)â€‹wtâˆ’Lcâ€‹qt+1\].\\displaystyle{y}\_{t}\\triangleq\\rho\_{t+1}-A\_{\\rho}\\rho\_{t}=\\bar{s}\_{t}+\\bar{w}\_{t}+\\bar{q}\_{t+1}=\\begin{bmatrix}s\_{t}+w\_{t}\\\\ (I-L\_{c}D\_{c})w\_{t}-L\_{c}q\_{t+1}\\end{bmatrix}. |     |

Then yty\_{t} can be estimated from zt+1z^{t+1} using the Kalman filter and smoother defined above, that is,

Report issue for preceding element

|     |     |     |     |     |
| --- | --- | --- | --- | --- |
|     | y^tâ‰œğ”¼â€‹\[yt\|zt+1\]\\displaystyle\\hat{y}\_{t}\\triangleq\\mathbb{E}\[{y}\_{t}\|z^{t+1}\] | \=Ï^t+1\|t+1âˆ’AÏâ€‹Ï^t\|t+1\\displaystyle=\\hat{\\rho}\_{t+1\|t+1}-A\_{\\rho}\\hat{\\rho}\_{t\|t+1} |     |
|     |     | \=(Iâˆ’AÏâ€‹QÏ)â€‹LÏâ€‹(zt+1âˆ’DÏâ€‹AÏâ€‹Ï^t\|t).\\displaystyle=(I-A\_{\\rho}Q\_{\\rho})L\_{\\rho}(z\_{t+1}-D\_{\\rho}A\_{\\rho}\\hat{\\rho}\_{t\|t}). |     | (65) |

Denote by Î·t\=ytâˆ’y^t\\eta\_{t}={y}\_{t}-\\hat{y}\_{t} the estimation error. Then we obtain an equivalent channel

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | y^t\=sÂ¯t+wÂ¯t+qÂ¯t+1âˆ’Î·t.\\displaystyle\\hat{y}\_{t}=\\bar{s}\_{t}+\\bar{w}\_{t}+\\bar{q}\_{t+1}-\\eta\_{t}. |     |

The following lemma can be derived using the same argument as in Lemma [3](https://arxiv.org/html/2509.16146v1#Thmlemma3 "Lemma 3 â€£ V-C Achievability Proof â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"), we thus present it without proof.

Report issue for preceding element

###### Lemma 8

Report issue for preceding element

Let Ï„t\=Ïtâˆ’Ï^t|t\\tau\_{t}=\\rho\_{t}-\\hat{\\rho}\_{t|t} denote the estimation error of the Kalman filter for the system defined in ([41](https://arxiv.org/html/2509.16146v1#S6.E41 "In VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"))-([42](https://arxiv.org/html/2509.16146v1#S6.E42 "In VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")). Then {Ï„t:tâ‰¥1}\\{\\tau\_{t}:t\\geq 1\\} forms a Markov chain that evolves according to

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Ï„t+1\=(Iâˆ’LÏâ€‹DÏ)â€‹AÏâ€‹Ï„tâˆ’LÏâ€‹vt+1+(Iâˆ’LÏâ€‹DÏ)â€‹(sÂ¯t+wÂ¯t+qÂ¯t+1).\\displaystyle\\tau\_{t+1}=(I-L\_{\\rho}D\_{\\rho})A\_{\\rho}\\tau\_{t}-L\_{\\rho}v\_{t+1}+(I-L\_{\\rho}D\_{\\rho})(\\bar{s}\_{t}+\\bar{w}\_{t}+\\bar{q}\_{t+1}). |     |

Moreover, for any tâ‰¥1t\\geq 1,

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | y^t\=(Iâˆ’AÏâ€‹QÏ)â€‹LÏâ€‹\[DÏâ€‹(sÂ¯t+wÂ¯t+qÂ¯t+1+AÏâ€‹Ï„t)+vt+1\].\\displaystyle\\hat{y}\_{t}=(I-A\_{\\rho}Q\_{\\rho})L\_{\\rho}\[D\_{\\rho}(\\bar{s}\_{t}+\\bar{w}\_{t}+\\bar{q}\_{t+1}+A\_{\\rho}\\tau\_{t})+v\_{t+1}\]. |     | (66) |

Lemma [8](https://arxiv.org/html/2509.16146v1#Thmlemma8 "Lemma 8 â€£ VII-C Proof of Theorem 4 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") shows that, under the policy ut\=âˆ’Kâ€‹xË‡t|t+Bâ€ â€‹stu\_{t}=-K\\check{x}\_{t|t}+B^{\\dagger}s\_{t}, the implicit channel can be equivalently translated into a Gaussian channel, as defined in ([66](https://arxiv.org/html/2509.16146v1#S7.E66 "In Lemma 8 â€£ VII-C Proof of Theorem 4 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")). This channel can be further simplified by noting that: (i) from ([63](https://arxiv.org/html/2509.16146v1#S7.E63 "In VII-C Proof of Theorem 4 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), LÏâˆˆâ„2â€‹d1Ã—d1L\_{\\rho}\\in\\mathbb{R}^{2d\_{1}\\times d\_{1}} has rank d1d\_{1} (i.e., full rank); and (ii) using the same argument as in ([V-C](https://arxiv.org/html/2509.16146v1#S5.Ex35 "V-C Achievability Proof â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), (Iâˆ’AÏâ€‹QÏ)(I-A\_{\\rho}Q\_{\\rho}) is invertible. As a result, the channel in ([66](https://arxiv.org/html/2509.16146v1#S7.E66 "In Lemma 8 â€£ VII-C Proof of Theorem 4 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) is equivalent to the following:

Report issue for preceding element

|     |     |     |     |     |
| --- | --- | --- | --- | --- |
|     | yÂ¯tâ‰œLÏâ€ â€‹(Iâˆ’AÏâ€‹QÏ)âˆ’1â€‹y^t\\displaystyle\\bar{y}\_{t}\\triangleq L\_{\\rho}^{\\dagger}(I-A\_{\\rho}Q\_{\\rho})^{-1}\\hat{y}\_{t} | \=DÏâ€‹(sÂ¯t+wÂ¯t+qÂ¯t+1+AÏâ€‹Ï„t)+vt+1,\\displaystyle=D\_{\\rho}(\\bar{s}\_{t}+\\bar{w}\_{t}+\\bar{q}\_{t+1}+A\_{\\rho}\\tau\_{t})+v\_{t+1}, |     |
|     |     | \=Dâ€‹(st+wt)+DÏâ€‹AÏâ€‹Ï„t+vt+1,\\displaystyle=D(s\_{t}+w\_{t})+D\_{\\rho}A\_{\\rho}\\tau\_{t}+v\_{t+1}, |     | (67) |

where LÏâ€ \=(LÏâŠ¤â€‹LÏ)âˆ’1â€‹LÏâŠ¤L\_{\\rho}^{\\dagger}=(L\_{\\rho}^{\\top}L\_{\\rho})^{-1}L\_{\\rho}^{\\top} is the left inverse of LÏL\_{\\rho}.

Report issue for preceding element

As in the achievability proof of Theorem [3](https://arxiv.org/html/2509.16146v1#Thmtheorem3 "Theorem 3 â€£ V-A Capacity â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"), we can also show that this translation does not loss any information about sns^{n}. That is,

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Iâ€‹(sn;zn+1,yÂ¯n)\=Iâ€‹(sn;yÂ¯n)\=Iâ€‹(sn;zn+1).\\displaystyle I(s^{n};z^{n+1},\\bar{y}^{n})=I(s^{n};\\bar{y}^{n})=I(s^{n};z^{n+1}). |     | (68) |

Since Iâ€‹(sn;yÂ¯n|zn+1)\=0I(s^{n};\\bar{y}^{n}|z^{n+1})=0, the key step is to show

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Iâ€‹(sn;zn+1\|yÂ¯n)\=Iâ€‹(sn;z1\|yÂ¯n)+âˆ‘t\=1nIâ€‹(sn;zt+1\|zt,yÂ¯n)\=0.\\displaystyle I(s^{n};z^{n+1}\|\\bar{y}^{n})=I(s^{n};z\_{1}\|\\bar{y}^{n})+\\sum\_{t=1}^{n}I(s^{n};z\_{t+1}\|z^{t},\\bar{y}^{n})=0. |     |

This holds because ([VII-C](https://arxiv.org/html/2509.16146v1#S7.Ex141 "VII-C Proof of Theorem 4 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) suggests that yÂ¯t\=zt+1âˆ’DÏâ€‹AÏâ€‹Ï^t|t\\bar{y}\_{t}=z\_{t+1}-D\_{\\rho}A\_{\\rho}\\hat{\\rho}\_{t|t}, meaning that zt+1z\_{t+1} can be determined by ztz^{t} and yÂ¯t\\bar{y}\_{t}. This completes the proof. âˆ

Report issue for preceding element

Now we are ready to prove Theorem [4](https://arxiv.org/html/2509.16146v1#Thmtheorem4 "Theorem 4 â€£ VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems").

Report issue for preceding element

###### Proof:

Report issue for preceding element

Lemma [5](https://arxiv.org/html/2509.16146v1#Thmlemma5 "Lemma 5 (Channel Translation) â€£ VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") establishes that, when the input policy is restricted to the form ut\=âˆ’Kâ€‹xË‡t|t+Bâ€ â€‹stu\_{t}=-K\\check{x}\_{t|t}+B^{\\dagger}s\_{t}, the implicit channel becomes equivalent to a Gaussian channel. Therefore, the capacity of this Gaussian channel serves as a lower bound for the capacity of the implicit channel. In this proof, we derive the capacity of the channel in ([VII-C](https://arxiv.org/html/2509.16146v1#S7.Ex144 "VII-C Proof of Theorem 4 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")). The derivation closely follows the same reasoning as in the achievability proof of Theorem [3](https://arxiv.org/html/2509.16146v1#Thmtheorem3 "Theorem 3 â€£ V-A Capacity â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"), and thus some details are omitted for brevity. First, let Î²t\=Dâ€‹wt+DÏâ€‹AÏâ€‹Ï„t+vt+1\\beta\_{t}=Dw\_{t}+D\_{\\rho}A\_{\\rho}\\tau\_{t}+v\_{t+1}, then according to ([VII-C](https://arxiv.org/html/2509.16146v1#S7.Ex144 "VII-C Proof of Theorem 4 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) and ([68](https://arxiv.org/html/2509.16146v1#S7.E68 "In VII-C Proof of Theorem 4 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")),

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | 1nâ€‹Iâ€‹(sn;yÂ¯n)\=1nâ€‹Iâ€‹(sn;yÂ¯n,zn+1)\\displaystyle\\frac{1}{n}I({s}^{n};\\bar{y}^{n})=\\frac{1}{n}I({s}^{n};\\bar{y}^{n},z^{n+1}) | \=1nâ€‹âˆ‘t\=1n\[hâ€‹(yÂ¯t\|zt)âˆ’hâ€‹(Î²t\|zt,sn)\]\\displaystyle=\\frac{1}{n}\\sum\_{t=1}^{n}\\left\[h(\\bar{y}\_{t}\|z^{t})-h({\\beta}\_{t}\|z^{t},{s}^{n})\\right\] |     |
|     |     | \=12â€‹nâ€‹âˆ‘t\=1nlogâ€‹det(Covâ€‹(yÂ¯tâˆ’y~t))âˆ’logâ€‹det(Covâ€‹(Î²tâˆ’Î²~t)),\\displaystyle=\\frac{1}{2n}\\sum\_{t=1}^{n}\\log\\det({\\text{Cov}}(\\bar{y}\_{t}-{\\tilde{y}}\_{t}))-\\log\\det({\\text{Cov}}({\\beta}\_{t}-{\\tilde{\\beta}}\_{t})), |     |

where y~tâ‰œğ”¼â€‹\[yÂ¯t|zt\]\\tilde{y}\_{t}\\triangleq\\mathbb{E}\[\\bar{y}\_{t}|z^{t}\] and Î²~tâ‰œğ”¼â€‹\[Î²t|zt,sn\]\\tilde{\\beta}\_{t}\\triangleq\\mathbb{E}\[{\\beta}\_{t}|z^{t},{s}^{n}\]. Without loss of optimality, in the remainder of this proof, we assume all the Kalman filters are already in the steady-state; hence each estimation error covariance has converged to its steady-state value. Since Ï^t|t\=ğ”¼â€‹\[Ït|zt\]\\hat{\\rho}\_{t|t}=\\mathbb{E}\[\\rho\_{t}|z^{t}\] is a function of ztz^{t}, we have

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | y~t\=ğ”¼â€‹\[yÂ¯t\|zt\]\\displaystyle\\tilde{y}\_{t}=\\mathbb{E}\[\\bar{y}\_{t}\|z^{t}\] | \=ğ”¼â€‹\[DÏâ€‹(sÂ¯t+wÂ¯t+qÂ¯t+1+AÏâ€‹Ï„t)+vt+1\|zt\]\\displaystyle=\\mathbb{E}\[D\_{\\rho}(\\bar{s}\_{t}+\\bar{w}\_{t}+\\bar{q}\_{t+1}+A\_{\\rho}\\tau\_{t})+v\_{t+1}\|z^{t}\] |     |
|     |     | \=DÏâ€‹AÏâ€‹ğ”¼â€‹\[(Ïtâˆ’Ï^t\|t)\|zt\]\=0.\\displaystyle=D\_{\\rho}A\_{\\rho}\\mathbb{E}\[(\\rho\_{t}-\\hat{\\rho}\_{t\|t})\|z^{t}\]=0. |     |

It follows that

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Covâ€‹(yÂ¯tâˆ’y~t)\=Covâ€‹(yÂ¯t)\\displaystyle{\\text{Cov}}(\\bar{y}\_{t}-{\\tilde{y}}\_{t})=\\text{Cov}(\\bar{y}\_{t}) | \=\[DÏâ€‹(Î¦Â¯+Î¨wÂ¯+Î¨qÂ¯+AÏâ€‹Î£~Ïâ€‹AÏâŠ¤)â€‹DÏâŠ¤+Î¨v\]\\displaystyle=\[D\_{\\rho}(\\bar{\\Phi}+\\Psi\_{\\bar{w}}+\\Psi\_{\\bar{q}}+A\_{\\rho}\\tilde{\\Sigma}\_{\\rho}A\_{\\rho}^{\\top})D\_{\\rho}^{\\top}+\\Psi\_{v}\] |     |
|     |     | \=DÏâ€‹Î£Ïâ€‹DÏâŠ¤+Î¨v.\\displaystyle=D\_{\\rho}\\Sigma\_{\\rho}D\_{\\rho}^{\\top}+\\Psi\_{v}. |     |

Similarly,

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Î²~t\=ğ”¼â€‹\[Î²t\|zt,sn\]\=DÏâ€‹AÏâ€‹(ğ”¼â€‹\[Ït\|zt,sÂ¯n\]âˆ’Ï^t\|t).\\displaystyle\\tilde{\\beta}\_{t}=\\mathbb{E}\[{\\beta}\_{t}\|z^{t},{s}^{n}\]=D\_{\\rho}A\_{\\rho}(\\mathbb{E}\[\\rho\_{t}\|z^{t},\\bar{s}^{n}\]-\\hat{\\rho}\_{t\|t}). |     |

Let ÏÂ¯t|t\=ğ”¼â€‹\[Ït|zt,sÂ¯n\]\=ğ”¼â€‹\[Ït|zt,sÂ¯tâˆ’1\]\\bar{\\rho}\_{t|t}=\\mathbb{E}\[\\rho\_{t}|z^{t},\\bar{s}^{n}\]=\\mathbb{E}\[\\rho\_{t}|z^{t},\\bar{s}^{t-1}\] and ÏƒÂ¯t\=Ïtâˆ’ÏÂ¯t|t\\bar{\\sigma}\_{t}=\\rho\_{t}-\\bar{\\rho}\_{t|t}. Then

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Covâ€‹(Î²tâˆ’Î²~t)\\displaystyle{\\text{Cov}}({\\beta}\_{t}-{\\tilde{\\beta}}\_{t}) | \=Covâ€‹(DÏâ€‹(wÂ¯t+qÂ¯t+1+AÏâ€‹(Ïtâˆ’Ï^t\|tâˆ’ÏÂ¯t\|t+Ï^t\|t))+vt+1)\\displaystyle=\\text{Cov}(D\_{\\rho}(\\bar{w}\_{t}+\\bar{q}\_{t+1}+A\_{\\rho}(\\rho\_{t}-\\hat{\\rho}\_{t\|t}-\\bar{\\rho}\_{t\|t}+\\hat{\\rho}\_{t\|t}))+v\_{t+1}) |     |
|     |     | \=Covâ€‹(DÏâ€‹(wÂ¯t+qÂ¯t+1+AÏâ€‹ÏƒÂ¯t)+vt+1)\\displaystyle=\\text{Cov}(D\_{\\rho}(\\bar{w}\_{t}+\\bar{q}\_{t+1}+A\_{\\rho}\\bar{\\sigma}\_{t})+v\_{t+1}) |     |
|     |     | \=DÏâ€‹Î¨Ïâ€‹DÏâŠ¤+Î¨v,\\displaystyle=D\_{\\rho}\\Psi\_{\\rho}D\_{\\rho}^{\\top}+\\Psi\_{v}, |     |

where Î¨Ï\\Psi\_{\\rho} is the steady-state value of the estimation error covariance Covâ€‹(Ïtâˆ’ğ”¼â€‹\[Ït|ztâˆ’1,sÂ¯tâˆ’1\])\\text{Cov}(\\rho\_{t}-\\mathbb{E}\[\\rho\_{t}|z^{t-1},\\bar{s}^{t-1}\]), which is determined by the following DARE:

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Î¨Ï\=AÏâ€‹(Î¨Ïâˆ’Î¨Ïâ€‹DÏâŠ¤â€‹(DÏâ€‹Î¨Ïâ€‹DÏâŠ¤+Î¨v)âˆ’1â€‹DÏâ€‹Î¨Ï)â€‹AÏâŠ¤+Î¨wÂ¯+Î¨qÂ¯.\\displaystyle\\Psi\_{\\rho}={A}\_{\\rho}\\left(\\Psi\_{\\rho}-\\Psi\_{\\rho}D\_{\\rho}^{\\top}(D\_{\\rho}\\Psi\_{\\rho}D\_{\\rho}^{\\top}+\\Psi\_{v})^{-1}D\_{\\rho}\\Psi\_{\\rho}\\right){A}\_{\\rho}^{\\top}+\\Psi\_{\\bar{w}}+\\Psi\_{\\bar{q}}. |     |

Since Lemma [4](https://arxiv.org/html/2509.16146v1#Thmlemma4 "Lemma 4 â€£ VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") has established that the control constraint is equivalent to an input power constraint, it is well-know that the capacity of the Gaussian channel yÂ¯t\=Dâ€‹st+Î²t\\bar{y}\_{t}=Ds\_{t}+\\beta\_{t} is given by

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | maxpâ€‹(sn)â€‹limnâ†’âˆ1nâ€‹Iâ€‹(sn;yÂ¯n)\=maxÎ¦âª°0â¡12â€‹logâ¡det(DÏâ€‹Î£Ïâ€‹DÏâŠ¤+Î¨v)det(DÏâ€‹Î¨Ïâ€‹DÏâŠ¤+Î¨v),\\displaystyle\\max\_{p(s^{n})}\\lim\_{n\\to\\infty}\\frac{1}{n}I(s^{n};\\bar{y}^{n})=\\max\_{\\Phi\\succeq 0}\\frac{1}{2}\\log\\frac{\\det(D\_{\\rho}\\Sigma\_{\\rho}D\_{\\rho}^{\\top}+\\Psi\_{v})}{\\det(D\_{\\rho}\\Psi\_{\\rho}D\_{\\rho}^{\\top}+\\Psi\_{v})}, |     |

subject to the input power constraint Trâ€‹((Î“+G^)â€‹Î¦)\\text{Tr}((\\Gamma+\\hat{G})\\Phi). The desired results follow immediately.

Report issue for preceding element

âˆ

Report issue for preceding element

## VIII Conclusion and Future Work

Report issue for preceding element

In this paper, we studied implicit communication in LQG control systems. By defining the control system as an implicit communication channel, we demonstrated that information can be transmitted from the controller to a receiver that observes the system stateâ€”without using explicit communication channelsâ€”while simultaneously maintaining the control cost within a given level. Specifically, information is encoded into the control inputs and then be decoded by the receiver from noiseless or noisy observations of the state. We formulated the implicit communication problem as a co-design of control and channel coding, and formalized the trade-off between control and communication as the implicit channel capacity, subject to a constraint on control performance. The main contributions of this paper are theoretical characterizations of this implicit channel capacity in three settings. We started from the simplest setting where both the controller and the receiver have noiseless observations of the system state, and derived a closed-form expression for the channel capacity. We then extended the analysis to the setting where the receiver has noisy observations, characterizing the channel capacity as the solution to a finite-dimensional convex optimization. Finally, we studied the general setting where both the controller and the receiver have noisy observations, and established a lower bound on the channel capacity.

Report issue for preceding element

Our analysis reveals two key insights into implicit communication in LQG control systems. First, when the controller has noiseless observations, the capacity-achieving input policy satisfies a separation principle, meaning that the control and channel coding tasks can be addressed independently without loss of optimality. Second, under this input policy, the implicit channel becomes equivalent to a Gaussian MIMO channel, allowing existing channel codes to be applied in implicit communication. These two properties significantly simplifies the practical coding problem and demonstrate that implicit communication can be effectively realized in practical scenarios.

Report issue for preceding element

This work opens a promising new avenue of research at the intersection of control and communication, with many interesting problems remaining to be explored in future work. On the theoretical side, the current point-to-point implicit communication model can be extended to networked settings \[[52](https://arxiv.org/html/2509.16146v1#bib.bib52)\]. For instance, when there are multiple receivers, the implicit channel may take the form of a broadcast channel; when multiple controllers are involvedâ€”as in decentralized control systems \[[53](https://arxiv.org/html/2509.16146v1#bib.bib53)\]â€”the channel becomes a multiple-access channel. These models are particularly relevant for multi-agent systems. Characterizing the capacities of such implicit channels is both interesting and fundamental from an information-theoretic perspective.

Report issue for preceding element

On the application side, exploring how this implicit communication framework can be practically deployed in real-world scenariosâ€”such as autonomous driving, swarm robotics, and human-robot interactionâ€”is a promising direction. Moreover, its application in multi-agent systems raises a profound question: if one agent communicates implicitly with others at the cost of degrading its own control performance, can this communication, in turn, improve the performance of the overall system? Examples from nature suggest a positive answer, but a theoretical understanding of this phenomenon in artificial systems remains an open and challenging problem requiring further investigation.

Report issue for preceding element

## Appendix A

Report issue for preceding element

In this appendix, we present proofs for Section [IV](https://arxiv.org/html/2509.16146v1#S4 "IV Noiseless Observations at the Controller and the Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems").

Report issue for preceding element

### A.1 Proof of Lemma [1](https://arxiv.org/html/2509.16146v1#Thmlemma1 "Lemma 1 â€£ IV-A Capacity â€£ IV Noiseless Observations at the Controller and the Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")

Report issue for preceding element

###### Proof:

Report issue for preceding element

Let KK be the optimal control gain and Î“\\Gamma be the solution to the DARE, as defined in ([7](https://arxiv.org/html/2509.16146v1#S3.E7 "In III-A Linear Quadratic-Gaussian (LQG) Control Systems â€£ III System Model and Preliminaries â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) and ([8](https://arxiv.org/html/2509.16146v1#S3.E8 "In III-A Linear Quadratic-Gaussian (LQG) Control Systems â€£ III System Model and Preliminaries â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), respectively. Then the optimal control cost, achieved by ut\=âˆ’Kâ€‹xtu\_{t}=-Kx\_{t}, is given by

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Jâˆ—\=Trâ€‹(Î“â€‹Î¨w)\=Trâ€‹(Î›â€‹UâŠ¤â€‹Î“â€‹U).\\displaystyle J^{\*}=\\text{Tr}(\\Gamma\\Psi\_{w})=\\text{Tr}(\\Lambda U^{\\top}{\\Gamma}U). |     |

Consider a sub-optimal control policy ut\=âˆ’Kâ€‹xt+Bâ€ â€‹stu\_{t}=-Kx\_{t}+B^{\\dagger}s\_{t}, where stâˆ¼ğ’©â€‹(0,Î¨s)s\_{t}\\sim\\mathcal{N}(0,\\Psi\_{s}) is independent of xtx\_{t} and wtw\_{t}. The control cost under this policy is given by (see discussions around ([A.2 Proof of Lemma 2](https://arxiv.org/html/2509.16146v1#Sx1.Ex160 "A.2 Proof of Lemma 2 â€£ Appendix A â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) and ([72](https://arxiv.org/html/2509.16146v1#Sx1.E72 "In A.2 Proof of Lemma 2 â€£ Appendix A â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) in the proof of Lemma [2](https://arxiv.org/html/2509.16146v1#Thmlemma2 "Lemma 2 â€£ IV-A Capacity â€£ IV Noiseless Observations at the Controller and the Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"))

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | J\=Jâˆ—+Trâ€‹((Î“+G^)â€‹Î¨s)\=Jâˆ—+Trâ€‹(Î“^â€‹Î¨^s)\=Jâˆ—+âˆ‘i\=1d1Î“^â€‹(i,i)â€‹Î¨^sâ€‹(i,i),\\displaystyle J=J^{\*}+\\text{Tr}((\\Gamma+\\hat{G})\\Psi\_{s})=J^{\*}+\\text{Tr}(\\hat{\\Gamma}\\hat{\\Psi}\_{s})=J^{\*}+\\sum\_{i=1}^{d\_{1}}\\hat{\\Gamma}(i,i)\\hat{\\Psi}\_{s}(i,i), |     | (69) |

where Î¨^s\=UâŠ¤â€‹Î¨sâ€‹U\\hat{\\Psi}\_{s}=U^{\\top}{\\Psi}\_{s}U. Suppose that Î“^\\hat{\\Gamma} has kk negative diagonal entries. Without loss of generality, assume that the first kk diagonal entries are negative. Consider a choice of Î¨^s\\hat{\\Psi}\_{s} satisfying Î¨^sâ€‹(i,i)\>0\\hat{\\Psi}\_{s}(i,i)>0 for 1â‰¤iâ‰¤k1\\leq i\\leq k and Î¨^sâ€‹(i,i)\=0\\hat{\\Psi}\_{s}(i,i)=0 for i\>ki>k. Then the policy ut\=âˆ’Kâ€‹xt+Bâ€ â€‹stu\_{t}=-Kx\_{t}+B^{\\dagger}s\_{t} results in a control cost:

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | J\=Jâˆ—+âˆ‘i\=1kÎ“^â€‹(i,i)â€‹Î¨^sâ€‹(i,i)<Jâˆ—.\\displaystyle J=J^{\*}+\\sum\_{i=1}^{k}\\hat{\\Gamma}(i,i)\\hat{\\Psi}\_{s}(i,i)<J^{\*}. |     | (70) |

which is strictly smaller than Jâˆ—J^{\*}. However, this contradicts the assumption that ut\=âˆ’Kâ€‹xtu\_{t}=-Kx\_{t} is an optimal policy while ut\=âˆ’Kâ€‹xt+Bâ€ â€‹stu\_{t}=-Kx\_{t}+B^{\\dagger}s\_{t} is a sub-optimal policy. Therefore, the assumption that Î“^\\hat{\\Gamma} has negative diagonal entries must be false, completing the proof.

Report issue for preceding element

âˆ

Report issue for preceding element

### A.2 Proof of Lemma [2](https://arxiv.org/html/2509.16146v1#Thmlemma2 "Lemma 2 â€£ IV-A Capacity â€£ IV Noiseless Observations at the Controller and the Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")

Report issue for preceding element

###### Proof:

Report issue for preceding element

Let sts\_{t} follow the Gaussian distribution ğ’©â€‹(0,Î¦)\\mathcal{N}(0,\\Phi). The control cost of the policy ut\=âˆ’Kâ€‹xt+Bâ€ â€‹stu\_{t}=-Kx\_{t}+B^{\\dagger}s\_{t}, denoted by JJ, can be determined by the Bellman equation:

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | fâ€‹(x)+J\=xâŠ¤â€‹Fâ€‹x+ğ”¼â€‹\[uâŠ¤â€‹Gâ€‹u\]+ğ”¼â€‹\[fâ€‹(z)\]\\displaystyle f(x)+J=x^{\\top}Fx+\\mathbb{E}\[u^{\\top}Gu\]+\\mathbb{E}\[f(z)\] |     |

where fâ€‹(x)f(x) is the differential value function and zz is the next state. We can show that fâ€‹(x)\=xâ€‹Î“â€‹xâŠ¤f(x)=x\\Gamma x^{\\top}, where Î“\\Gamma is defined in ([8](https://arxiv.org/html/2509.16146v1#S3.E8 "In III-A Linear Quadratic-Gaussian (LQG) Control Systems â€£ III System Model and Preliminaries â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")). To see this, substituting fâ€‹(x)\=xâ€‹Î“â€‹xâŠ¤f(x)=x\\Gamma x^{\\top} and u\=âˆ’Kâ€‹x+Bâ€ â€‹su=-Kx+B^{\\dagger}s into the Bellman equation yields

Report issue for preceding element

|     |     |     |     |     |
| --- | --- | --- | --- | --- |
|     | xâŠ¤â€‹Î“â€‹x+J\\displaystyle x^{\\top}\\Gamma x+J | \=xâŠ¤â€‹Fâ€‹x+xâŠ¤â€‹KâŠ¤â€‹Gâ€‹Kâ€‹x+ğ”¼â€‹\[(Bâ€ â€‹st)âŠ¤â€‹Gâ€‹Bâ€ â€‹st\]+ğ”¼â€‹\[zâŠ¤â€‹Î“â€‹z\]\\displaystyle=x^{\\top}Fx+x^{\\top}K^{\\top}GKx+\\mathbb{E}\\left\[(B^{\\dagger}s\_{t})^{\\top}GB^{\\dagger}s\_{t}\\right\]+\\mathbb{E}\[z^{\\top}\\Gamma z\] |     |
|     |     | \=xâŠ¤â€‹Fâ€‹x+xâŠ¤â€‹KâŠ¤â€‹Gâ€‹Kâ€‹x+ğ”¼â€‹\[(Bâ€ â€‹st)âŠ¤â€‹Gâ€‹Bâ€ â€‹st\]+xâŠ¤â€‹(Aâˆ’Bâ€‹K)âŠ¤â€‹Î“â€‹(Aâˆ’Bâ€‹K)â€‹x+ğ”¼â€‹\[(w+s)âŠ¤â€‹Î“â€‹(w+s)\]\\displaystyle=x^{\\top}Fx+x^{\\top}K^{\\top}GKx+\\mathbb{E}\\left\[(B^{\\dagger}s\_{t})^{\\top}GB^{\\dagger}s\_{t}\\right\]+x^{\\top}(A-BK)^{\\top}\\Gamma(A-BK)x+\\mathbb{E}\[(w+s)^{\\top}\\Gamma(w+s)\] |     |
|     |     | \=xâŠ¤â€‹\[F+KâŠ¤â€‹Gâ€‹K+(Aâˆ’Bâ€‹K)âŠ¤â€‹Î“â€‹(Aâˆ’Bâ€‹K)\]â€‹x+Trâ€‹(Gâ€‹Bâ€ â€‹Î¦â€‹(Bâ€ )âŠ¤)+Trâ€‹(Î“â€‹(Î¨w+Î¦)).\\displaystyle=x^{\\top}\[F+K^{\\top}GK+(A-BK)^{\\top}\\Gamma(A-BK)\]x+\\text{Tr}(GB^{\\dagger}\\Phi(B^{\\dagger})^{\\top})+\\text{Tr}(\\Gamma(\\Psi\_{w}+\\Phi)). |     | (71) |

Using the expression of KK defined in ([7](https://arxiv.org/html/2509.16146v1#S3.E7 "In III-A Linear Quadratic-Gaussian (LQG) Control Systems â€£ III System Model and Preliminaries â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), we can derive

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | F+KâŠ¤â€‹Gâ€‹K+(Aâˆ’Bâ€‹K)âŠ¤â€‹Î“â€‹(Aâˆ’Bâ€‹K)\=F+AâŠ¤â€‹(Î“âˆ’Î“â€‹Bâ€‹(G+BâŠ¤â€‹Î“â€‹B)âˆ’1â€‹BâŠ¤â€‹Î“)â€‹A\=Î“.\\displaystyle F+K^{\\top}GK+(A-BK)^{\\top}\\Gamma(A-BK)=F+A^{\\top}(\\Gamma-\\Gamma B(G+B^{\\top}\\Gamma B)^{-1}B^{\\top}\\Gamma)A=\\Gamma. |     |

The last equality follows from the DARE given in ([8](https://arxiv.org/html/2509.16146v1#S3.E8 "In III-A Linear Quadratic-Gaussian (LQG) Control Systems â€£ III System Model and Preliminaries â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")). This verifies that indeed fâ€‹(x)\=xâ€‹Î“â€‹xâŠ¤f(x)=x\\Gamma x^{\\top} and that

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | J\=Trâ€‹(Î“â€‹(Î¨w+Î¦))+Trâ€‹(Gâ€‹Bâ€ â€‹Î¦â€‹(Bâ€ )âŠ¤)\=Jâˆ—+Trâ€‹((Î“+G^)â€‹Î¦),\\displaystyle J=\\text{Tr}(\\Gamma(\\Psi\_{w}+\\Phi))+\\text{Tr}(GB^{\\dagger}\\Phi(B^{\\dagger})^{\\top})=J^{\*}+\\text{Tr}((\\Gamma+\\hat{G})\\Phi), |     | (72) |

where G^â‰œ(Bâ€ )âŠ¤â€‹Gâ€‹Bâ€ \\hat{G}\\triangleq(B^{\\dagger})^{\\top}GB^{\\dagger}. This completes the proof. âˆ

Report issue for preceding element

### A.3 Proof of Theorem [2](https://arxiv.org/html/2509.16146v1#Thmtheorem2 "Theorem 2 â€£ IV-A Capacity â€£ IV Noiseless Observations at the Controller and the Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")

Report issue for preceding element

###### Proof:

Report issue for preceding element

According to ([49](https://arxiv.org/html/2509.16146v1#S7.E49 "In VII-A Converse Proof of Theorem 1 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"))-([50](https://arxiv.org/html/2509.16146v1#S7.E50 "In VII-A Converse Proof of Theorem 1 â€£ VII Proofs â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")), the capacity is given by

Report issue for preceding element

|     |     |     |     |     |
| --- | --- | --- | --- | --- |
|     | Câ€‹(V)\=maxÎ¦â‰¥0\\displaystyle{C}(V)=\\max\_{\\Phi\\geq 0}\\ | 12â€‹logâ€‹det(I+Î¨wâˆ’1â€‹Î¦)\\displaystyle\\frac{1}{2}\\log\\det\\left(I+\\Psi\_{w}^{-1}{\\Phi}\\right) |     | (73) |
|     | s.t.\\displaystyle s.t.\\ | Trâ€‹(Î¦â€‹(Î“+G^))â‰¤V.\\displaystyle\\text{Tr}(\\Phi(\\Gamma+\\hat{G}))\\leq V. |     | (74) |

If the system is a scalar system, then det(I+Î¨wâˆ’1â€‹Î¦)\=1+Î¦/Î¨w\\det\\left(I+\\Psi\_{w}^{-1}{\\Phi}\\right)=1+\\Phi/\\Psi\_{w} and Trâ€‹(Î¦â€‹(Î“+G^))\=Î¦â€‹(Î“+G^)\\text{Tr}(\\Phi(\\Gamma+\\hat{G}))=\\Phi(\\Gamma+\\hat{G}). By KKT conditions, the optimal value is achieved by a Î¦\\Phi that satisfies the equality of the constraint, that is Î¦\=V/(Î“+G^)\\Phi=V/(\\Gamma+\\hat{G}). Substituting it into the objective function yields

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Câ€‹(V)\=12â€‹logâ¡(1+VÎ¨wâ€‹(Î“+G^))\=12â€‹logâ¡(1+VJâˆ—+Bâˆ’2â€‹Gâ€‹Î¨w).\\displaystyle C(V)=\\frac{1}{2}\\log\\left(1+\\frac{V}{\\Psi\_{w}(\\Gamma+\\hat{G})}\\right)=\\frac{1}{2}\\log\\left(1+\\frac{V}{J^{\*}+B^{-2}G\\Psi\_{w}}\\right). |     |

This completes the proof. âˆ

Report issue for preceding element

## Appendix B

Report issue for preceding element

This appendix presents proofs for Section [V](https://arxiv.org/html/2509.16146v1#S5 "V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems").

Report issue for preceding element

### B.1 Proof of Lemma [3](https://arxiv.org/html/2509.16146v1#Thmlemma3 "Lemma 3 â€£ V-C Achievability Proof â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")

Report issue for preceding element

###### Proof:

Report issue for preceding element

First, it is easy to see that {Ïƒt:tâ‰¥1}\\{\\sigma\_{t}:t\\geq 1\\} forms a Markov chain:

Report issue for preceding element

|     |     |     |     |     |
| --- | --- | --- | --- | --- |
|     | Ïƒt+1\\displaystyle\\sigma\_{t+1} | \=xt+1âˆ’x^t+1\|t+t\\displaystyle=x\_{t+1}-\\hat{x}\_{t+1\|t+t} |     |
|     |     | \=AÂ¯â€‹xt+st+wtâˆ’AÂ¯â€‹x^t\|tâˆ’Lâ€‹(zt+1âˆ’Dâ€‹AÂ¯â€‹x^t\|t)\\displaystyle=\\bar{A}x\_{t}+s\_{t}+{w}\_{t}-\\bar{A}\\hat{x}\_{t\|t}-L(z\_{t+1}-D\\bar{A}\\hat{x}\_{t\|t}) |     |
|     |     | \=(Iâˆ’Lâ€‹D)â€‹AÂ¯â€‹Ïƒtâˆ’Lâ€‹vt+1+(Iâˆ’Lâ€‹D)â€‹(st+wt).\\displaystyle=(I-LD)\\bar{A}\\sigma\_{t}-Lv\_{t+1}+(I-LD)(s\_{t}+w\_{t}). |     | (75) |

The last line holds because Dâ€‹AÂ¯â€‹xt\=Dâ€‹(xt+1âˆ’stâˆ’wt)\=zt+1âˆ’vt+1âˆ’Dâ€‹(st+wt)D\\bar{A}{x}\_{t}=D(x\_{t+1}-s\_{t}-{w}\_{t})=z\_{t+1}-v\_{t+1}-D(s\_{t}+{w}\_{t}). We note that Ïƒt\\sigma\_{t} depends on ztz^{t} and is independent of st,wts\_{t},w\_{t}, and vt+1v\_{t+1}.

Report issue for preceding element

Let Îµtâ‰œxtâˆ’x^t|t+1\\varepsilon\_{t}\\triangleq x\_{t}-\\hat{x}\_{t|t+1} denote the estimation error of the Kalman smoother. Then according to ([19](https://arxiv.org/html/2509.16146v1#S5.E19 "In V-B Kalman Filter and Smoother â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")),

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Îµt\\displaystyle\\varepsilon\_{t} | \=xtâˆ’x^t\|tâˆ’Qâ€‹(x^t+1\|t+1âˆ’AÂ¯â€‹x^t\|t)\\displaystyle=x\_{t}-\\hat{x}\_{t\|t}-Q\\left(\\hat{x}\_{t+1\|t+1}-\\bar{A}\\hat{x}\_{t\|t}\\right) |     |
|     |     | \=Ïƒtâˆ’Qâ€‹Lâ€‹(zt+1âˆ’Dâ€‹AÂ¯â€‹x^t\|t)\\displaystyle=\\sigma\_{t}-QL(z\_{t+1}-D\\bar{A}\\hat{x}\_{t\|t}) |     |
|     |     | \=(Iâˆ’Qâ€‹Lâ€‹Dâ€‹AÂ¯)â€‹Ïƒtâˆ’Qâ€‹Lâ€‹(vt+1+Dâ€‹(st+wt)).\\displaystyle=(I-QLD\\bar{A})\\sigma\_{t}-QL(v\_{t+1}+D(s\_{t}+{w}\_{t})). |     |

Define the estimation error Î·tâ‰œytâˆ’y^t\\eta\_{t}\\triangleq y\_{t}-\\hat{y}\_{t}. Then it can be written as

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | Î·t\\displaystyle\\eta\_{t} | \=xt+1âˆ’x^t+1\|t+1âˆ’AÂ¯â€‹(xtâˆ’x^t\|t+1)\\displaystyle=x\_{t+1}-\\hat{x}\_{t+1\|t+1}-\\bar{A}\\left(x\_{t}-\\hat{x}\_{t\|t+1}\\right) |     |
|     |     | \=Ïƒt+1âˆ’AÂ¯â€‹Îµt\\displaystyle=\\sigma\_{t+1}-\\bar{A}\\varepsilon\_{t} |     |
|     |     | \=(AÂ¯â€‹Qâˆ’I)â€‹Lâ€‹Dâ€‹AÂ¯â€‹Ïƒt+(AÂ¯â€‹Qâˆ’I)â€‹Lâ€‹vt+1+(AÂ¯â€‹Qâ€‹Lâ€‹D+Iâˆ’Lâ€‹D)â€‹(st+wt).\\displaystyle=(\\bar{A}Q-I)LD\\bar{A}\\sigma\_{t}+(\\bar{A}Q-I)Lv\_{t+1}+(\\bar{A}QLD+I-LD)(s\_{t}+{w}\_{t}). |     |

We thus have

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | y^t\\displaystyle\\hat{y}\_{t} | \=ytâˆ’Î·t\=st+wtâˆ’Î·t\\displaystyle=y\_{t}-\\eta\_{t}=s\_{t}+{w}\_{t}-\\eta\_{t} |     |
|     |     | \=(Iâˆ’AÂ¯â€‹Q)â€‹Lâ€‹Dâ€‹AÂ¯â€‹Ïƒt+(Iâˆ’AÂ¯â€‹Q)â€‹Lâ€‹vt+1+(Iâˆ’AÂ¯â€‹Q)â€‹Lâ€‹Dâ€‹(st+wt)\\displaystyle=(I-\\bar{A}Q)LD\\bar{A}\\sigma\_{t}+(I-\\bar{A}Q)Lv\_{t+1}+(I-\\bar{A}Q)LD(s\_{t}+w\_{t}) |     |
|     |     | \=(Iâˆ’AÂ¯â€‹Q)â€‹Lâ€‹\[Dâ€‹st+vt+1+Dâ€‹wt+Dâ€‹AÂ¯â€‹Ïƒt\].\\displaystyle=(I-\\bar{A}Q)L\[Ds\_{t}+v\_{t+1}+Dw\_{t}+D\\bar{A}\\sigma\_{t}\]. |     |

âˆ

Report issue for preceding element

### B.2 Proof of Proposition [1](https://arxiv.org/html/2509.16146v1#Thmproposition1 "Proposition 1 â€£ V-A Capacity â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")

Report issue for preceding element

###### Proof:

Report issue for preceding element

For ease of reference, we refer to the optimization problems defined in Theorem [3](https://arxiv.org/html/2509.16146v1#Thmtheorem3 "Theorem 3 â€£ V-A Capacity â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") and Proposition [1](https://arxiv.org/html/2509.16146v1#Thmproposition1 "Proposition 1 â€£ V-A Capacity â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems") as ğšƒğŸ¹\\mathtt{T3} and ğ™¿ğŸ·\\mathtt{P1}, respectively. Since ğšƒğŸ¹\\mathtt{T3} and ğ™¿ğŸ·\\mathtt{P1} share the same objective function, it suffices to show that they have the same optimal solution. First, define a function

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | fâ€‹(Î£,Î¦)â‰œAÂ¯â€‹(Î£âˆ’Î£â€‹DâŠ¤â€‹(Dâ€‹Î£â€‹DâŠ¤+Î¨v)âˆ’1â€‹Dâ€‹Î£)â€‹AÂ¯âŠ¤+Î¨w+Î¦.\\displaystyle f(\\Sigma,\\Phi)\\triangleq\\bar{A}\\left(\\Sigma-\\Sigma D^{\\top}(D\\Sigma D^{\\top}+\\Psi\_{v})^{-1}D\\Sigma\\right)\\bar{A}^{\\top}+\\Psi\_{{w}}+\\Phi. |     |

Under this definition, the constraint ([14](https://arxiv.org/html/2509.16146v1#S5.E14 "In Theorem 3 â€£ V-A Capacity â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) becomes fâ€‹(Î£,Î¦)\=Î£f(\\Sigma,\\Phi)=\\Sigma. We now relax this equality to an inequality:

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | fâ€‹(Î£,Î¦)âˆ’Î£âª°0.\\displaystyle f(\\Sigma,\\Phi)-\\Sigma\\succeq 0. |     | (76) |

Note that Dâ€‹Î£â€‹DâŠ¤+Î¨vD\\Sigma D^{\\top}+\\Psi\_{v} is PD if Î£\\Sigma is PSD. Then by Schur complement for PSD matrices, ([76](https://arxiv.org/html/2509.16146v1#Sx2.E76 "In B.2 Proof of Proposition 1 â€£ Appendix B â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) is equivalent to

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Dâ€‹Î£â€‹DâŠ¤+Î¨vâª°0â€‹Â andÂ â€‹\[Dâ€‹Î£â€‹DâŠ¤+Î¨vDâ€‹Î£â€‹AÂ¯âŠ¤AÂ¯â€‹Î£â€‹DâŠ¤AÂ¯â€‹Î£â€‹AÂ¯âŠ¤+Î¨w+Î¦âˆ’Î£\]âª°0.\\displaystyle D\\Sigma D^{\\top}+\\Psi\_{v}\\succeq 0\\text{ and }\\begin{bmatrix}D\\Sigma D^{\\top}+\\Psi\_{v}&D\\Sigma\\bar{A}^{\\top}\\\\ \\bar{A}\\Sigma D^{\\top}&\\bar{A}\\Sigma\\bar{A}^{\\top}+\\Psi\_{w}+\\Phi-\\Sigma\\end{bmatrix}\\succeq 0. |     |

Therefore, problem ğ™¿ğŸ·\\mathtt{P1} is equivalent to a relaxed version of ğšƒğŸ¹\\mathtt{T3}, where the equality constraint ([14](https://arxiv.org/html/2509.16146v1#S5.E14 "In Theorem 3 â€£ V-A Capacity â€£ V Noisy Observations at Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) is replaced by the relaxed inequality ([76](https://arxiv.org/html/2509.16146v1#Sx2.E76 "In B.2 Proof of Proposition 1 â€£ Appendix B â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")).

Report issue for preceding element

Before proceeding, we state a standard result about the discrete-time algebraic Riccati equation.

Report issue for preceding element

Fact 1: Given that fâ€‹(Î£,Î¦)âˆ’Î£\=0f(\\Sigma,\\Phi)-\\Sigma=0 and fâ€‹(Î£â€²,Î¦â€²)âˆ’Î£â€²\=0f(\\Sigma^{\\prime},\\Phi^{\\prime})-\\Sigma^{\\prime}=0. If Î¦âª°Î¦â€²\\Phi\\succeq\\Phi^{\\prime}, then Î£âª°Î£â€²\\Sigma\\succeq\\Sigma^{\\prime}.

Report issue for preceding element

The proof of Fact 1 is straightforward. Note that Î£\\Sigma is the fixed point of the discrete recursion: Î£t+1\=fâ€‹(Î£t,Î¦)\\Sigma\_{t+1}=f(\\Sigma\_{t},\\Phi). If Î¦âª°Î¦â€²\\Phi\\succeq\\Phi^{\\prime} and initializing two recursions from the same PSD matrix Î£0\=Î£0â€²\\Sigma\_{0}=\\Sigma^{\\prime}\_{0}, then we can show by induction that

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Î£t+1\=fâ€‹(Î£t,Î¦)âª°Î£t+1â€²\=fâ€‹(Î£tâ€²,Î¦â€²),âˆ€tâ‰¥0.\\displaystyle\\Sigma\_{t+1}=f(\\Sigma\_{t},\\Phi)\\succeq\\Sigma^{\\prime}\_{t+1}=f(\\Sigma^{\\prime}\_{t},\\Phi^{\\prime}),\\ \\forall t\\geq 0. |     |

It follows that Î£\=Î£âˆâª°Î£â€²\=Î£âˆâ€²\\Sigma=\\Sigma\_{\\infty}\\succeq\\Sigma^{\\prime}=\\Sigma^{\\prime}\_{\\infty}.

Report issue for preceding element

Now, suppose that a tuple (Î£0,Î¦1)(\\Sigma\_{0},\\Phi\_{1}) is an optimal solution to ğ™¿ğŸ·\\mathtt{P1}. If fâ€‹(Î£0,Î¦1)âˆ’Î£0\=0f(\\Sigma\_{0},\\Phi\_{1})-\\Sigma\_{0}=0, then this tuple is also an optimal solution to the problem ğšƒğŸ¹\\mathtt{T3}. We consider the non-trivial case in which the inequality does not hold with equality:

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | Î”Î¦â‰œfâ€‹(Î£0,Î¦1)âˆ’Î£0âª°0.\\displaystyle\\Delta\_{\\Phi}\\triangleq f(\\Sigma\_{0},\\Phi\_{1})-\\Sigma\_{0}\\succeq 0. |     |

Let Î¦0\=Î¦1âˆ’Î”Î¦\\Phi\_{0}=\\Phi\_{1}-\\Delta\_{\\Phi}, then we have fâ€‹(Î£0,Î¦0)âˆ’Î£0\=0f(\\Sigma\_{0},\\Phi\_{0})-\\Sigma\_{0}=0. For Î¦1\\Phi\_{1}, there also exists a PSD matrix Î£1\\Sigma\_{1} satisfying fâ€‹(Î£1,Î¦1)âˆ’Î£1\=0f(\\Sigma\_{1},\\Phi\_{1})-\\Sigma\_{1}=0. Since Î¦1âª°Î¦0\\Phi\_{1}\\succeq\\Phi\_{0}, it follows from Fact 1 that Î£1âª°Î£0\\Sigma\_{1}\\succeq\\Sigma\_{0}. Note that the tuple (Î£1,Î¦1)(\\Sigma\_{1},\\Phi\_{1}) is a valid solution to both problems ğ™¿ğŸ·\\mathtt{P1} and ğšƒğŸ¹\\mathtt{T3}. It follows from Dâ€‹Î£1â€‹DâŠ¤+Î¨vâª°Dâ€‹Î£0â€‹DâŠ¤+Î¨vâ‰»0D\\Sigma\_{1}D^{\\top}+\\Psi\_{v}\\succeq D\\Sigma\_{0}D^{\\top}+\\Psi\_{v}\\succ 0 that

Report issue for preceding element

|     |     |     |
| --- | --- | --- |
|     | logâ€‹det(Dâ€‹Î£1â€‹DâŠ¤+Î¨v)â‰¥logâ€‹det(Dâ€‹Î£0â€‹DâŠ¤+Î¨v).\\displaystyle\\log{\\det(D\\Sigma\_{1}D^{\\top}+\\Psi\_{v})}\\geq\\log{\\det(D\\Sigma\_{0}D^{\\top}+\\Psi\_{v}}). |     |

Since (Î£0,Î¦1)(\\Sigma\_{0},\\Phi\_{1}) is assumed to be an optimal solution to ğ™¿ğŸ·\\mathtt{P1}, the above inequality must hold with equality.

Report issue for preceding element

We thus obtain the following conclusion: if (Î£,Î¦)(\\Sigma,\\Phi) is an optimal solution to problem ğ™¿ğŸ·\\mathtt{P1}, then one of the following must hold:

Report issue for preceding element

*   (i)
    
    fâ€‹(Î£,Î¦)âˆ’Î£\=0f(\\Sigma,\\Phi)-\\Sigma=0, in which case (Î£,Î¦)(\\Sigma,\\Phi) is also an optimal solution to problem ğšƒğŸ¹\\mathtt{T3}.
    
    Report issue for preceding element
    
*   (ii)
    
    There exists a PSD matrix Î£â€²âª°Î£\\Sigma^{\\prime}\\succeq\\Sigma such that fâ€‹(Î£â€²,Î¦)âˆ’Î£â€²\=0f(\\Sigma^{\\prime},\\Phi)-\\Sigma^{\\prime}=0 and (Î£â€²,Î¦)(\\Sigma^{\\prime},\\Phi) yields the same objective value. In this case, (Î£â€²,Î¦)(\\Sigma^{\\prime},\\Phi) is an optimal solution to both problems.
    
    Report issue for preceding element
    

In both cases, the two optimization problems share an identical optimal solution. This completes the proof.

Report issue for preceding element

âˆ

Report issue for preceding element

## Appendix C

Report issue for preceding element

The appendix presents proofs for Section [VI](https://arxiv.org/html/2509.16146v1#S6 "VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems").

Report issue for preceding element

### C.1 Proof of Lemma [4](https://arxiv.org/html/2509.16146v1#Thmlemma4 "Lemma 4 â€£ VI-B A Lower Bound on the Capacity â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")

Report issue for preceding element

###### Proof:

Report issue for preceding element

For ease of notation, we will write xË‡t|t\\check{x}\_{t|t} as xË‡t\\check{x}\_{t} whenever the context is clear. We prove this lemma using a similar argument as in Lemma [2](https://arxiv.org/html/2509.16146v1#Thmlemma2 "Lemma 2 â€£ IV-A Capacity â€£ IV Noiseless Observations at the Controller and the Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"). That is, we begin by assuming that the differential value function under the policy ut\=âˆ’Kâ€‹xË‡t+Bâ€ â€‹stu\_{t}=-K\\check{x}\_{t}+B^{\\dagger}s\_{t} takes the quadratic form fâ€‹(xË‡t)\=xË‡tâŠ¤â€‹Î“â€‹xË‡tf(\\check{x}\_{t})=\\check{x}\_{t}^{\\top}\\Gamma\\check{x}\_{t}. Then we show that this function indeed satisfies the Bellman equation. The corresponding average control cost is subsequently derived from the Bellman equation. First, substituting fâ€‹(xË‡t)\=xË‡tâŠ¤â€‹Î“â€‹xË‡tf(\\check{x}\_{t})=\\check{x}\_{t}^{\\top}\\Gamma\\check{x}\_{t} into the Bellman equation yields

Report issue for preceding element

|     |     |     |     |     |
| --- | --- | --- | --- | --- |
|     | xË‡tâŠ¤â€‹Î“â€‹xË‡t+J\\displaystyle\\check{x}\_{t}^{\\top}\\Gamma\\check{x}\_{t}+J | \=(xË‡t+et)âŠ¤â€‹Fâ€‹(xË‡t+et)+xË‡tâŠ¤â€‹KâŠ¤â€‹Gâ€‹Kâ€‹xË‡t+ğ”¼â€‹\[(Bâ€ â€‹st)âŠ¤â€‹Gâ€‹Bâ€ â€‹st\]+ğ”¼â€‹\[xË‡t+1âŠ¤â€‹Î“â€‹xË‡t+1\].\\displaystyle=(\\check{x}\_{t}+e\_{t})^{\\top}F(\\check{x}\_{t}+e\_{t})+\\check{x}\_{t}^{\\top}K^{\\top}GK\\check{x}\_{t}+\\mathbb{E}\\left\[(B^{\\dagger}s\_{t})^{\\top}GB^{\\dagger}s\_{t}\\right\]+\\mathbb{E}\[\\check{x}\_{t+1}^{\\top}\\Gamma\\check{x}\_{t+1}\]. |     | (77) |

Without loss of optimality, we assume the Kalman filter is already in the steady-state. Then according to the Kalman filter formulas,

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | xË‡t+1\\displaystyle\\check{x}\_{t+1} | \=(Iâˆ’Lcâ€‹Dc)â€‹(Aâ€‹xË‡t+Bâ€‹ut)+Lcâ€‹ot+1\\displaystyle=(I-L\_{c}D\_{c})(A\\check{x}\_{t}+Bu\_{t})+L\_{c}o\_{t+1} |     |
|     |     | \=(Iâˆ’Lcâ€‹Dc)â€‹(Aâ€‹xË‡t+Bâ€‹ut)+Lcâ€‹(Dcâ€‹(Aâ€‹xt+Bâ€‹ut+wt)+qt+1)\\displaystyle=(I-L\_{c}D\_{c})(A\\check{x}\_{t}+Bu\_{t})+L\_{c}(D\_{c}(Ax\_{t}+Bu\_{t}+w\_{t})+q\_{t+1}) |     |
|     |     | \=Aâ€‹xË‡t+Bâ€‹ut+Lcâ€‹Dcâ€‹(Aâ€‹et+wt)+Lcâ€‹qt+1.\\displaystyle=A\\check{x}\_{t}+Bu\_{t}+L\_{c}D\_{c}(Ae\_{t}+w\_{t})+L\_{c}q\_{t+1}. |     |

Note that Covâ€‹(Dcâ€‹(Aâ€‹et+wt))\=Dcâ€‹(Aâ€‹Î£~câ€‹AâŠ¤+Î¨w)â€‹DcâŠ¤\=Dcâ€‹Î£câ€‹DcâŠ¤\\text{Cov}(D\_{c}(Ae\_{t}+w\_{t}))=D\_{c}(A\\tilde{\\Sigma}\_{c}A^{\\top}+\\Psi\_{w})D^{\\top}\_{c}=D\_{c}\\Sigma\_{c}D^{\\top}\_{c}. It follows that

Report issue for preceding element

|     |     |     |     |
| --- | --- | --- | --- |
|     | ğ”¼â€‹\[xË‡t+1âŠ¤â€‹Î“â€‹xË‡t+1\]\\displaystyle\\mathbb{E}\[\\check{x}\_{t+1}^{\\top}\\Gamma\\check{x}\_{t+1}\] | \=ğ”¼â€‹\[(Aâ€‹xË‡t+Bâ€‹ut)âŠ¤â€‹Î“â€‹(Aâ€‹xË‡t+Bâ€‹ut)\]+Trâ€‹(Î“â€‹Lcâ€‹(Dcâ€‹Î£câ€‹DcâŠ¤+Î¨q)â€‹LcâŠ¤)\\displaystyle=\\mathbb{E}\[(A\\check{x}\_{t}+Bu\_{t})^{\\top}\\Gamma(A\\check{x}\_{t}+Bu\_{t})\]+\\text{Tr}(\\Gamma L\_{c}(D\_{c}\\Sigma\_{c}D\_{c}^{\\top}+\\Psi\_{q})L\_{c}^{\\top}) |     |
|     |     | \=xË‡tâŠ¤â€‹(Aâˆ’Bâ€‹K)âŠ¤â€‹Î“â€‹(Aâˆ’Bâ€‹K)â€‹xË‡t+ğ”¼â€‹\[stâŠ¤â€‹Î“â€‹st\]+Trâ€‹(Î“â€‹Lcâ€‹(Dcâ€‹Î£câ€‹DcâŠ¤+Î¨q)â€‹LcâŠ¤).\\displaystyle=\\check{x}^{\\top}\_{t}(A-BK)^{\\top}\\Gamma(A-BK)\\check{x}\_{t}+\\mathbb{E}\[s^{\\top}\_{t}\\Gamma s\_{t}\]+\\text{Tr}(\\Gamma L\_{c}(D\_{c}\\Sigma\_{c}D\_{c}^{\\top}+\\Psi\_{q})L\_{c}^{\\top}). |     |

Since Lc\=Î£câ€‹DcâŠ¤â€‹(Dcâ€‹Î£câ€‹DcâŠ¤+Î¨q)âˆ’1L\_{c}=\\Sigma\_{c}D\_{c}^{\\top}(D\_{c}\\Sigma\_{c}D\_{c}^{\\top}+\\Psi\_{q})^{-1} and Î£~c\=(Iâˆ’Lcâ€‹Dc)â€‹Î£c\\tilde{\\Sigma}\_{c}=(I-L\_{c}D\_{c})\\Sigma\_{c}, we have Tr(Î“L\_c (D\_c Î£\_cD\_c^âŠ¤+ Î¨\_q) L\_c^âŠ¤) = Tr(Î“Î£\_cD\_c^âŠ¤L\_c^âŠ¤) = Tr(Î“(Î£\_c - ~Î£\_c)). Substituting the above into ([77](https://arxiv.org/html/2509.16146v1#Sx3.E77 "In C.1 Proof of Lemma 4 â€£ Appendix C â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) yields

Report issue for preceding element

|     |     |     |     |     |
| --- | --- | --- | --- | --- |
|     | xË‡tâŠ¤â€‹Î“â€‹xË‡t+J\=\\displaystyle\\check{x}\_{t}^{\\top}\\Gamma\\check{x}\_{t}+J= | xË‡tâŠ¤â€‹\[F+KâŠ¤â€‹Gâ€‹K+(Aâˆ’Bâ€‹K)âŠ¤â€‹Î“â€‹(Aâˆ’Bâ€‹K)\]â€‹xË‡t+ğ”¼â€‹\[etâŠ¤â€‹Fâ€‹xË‡t\]+ğ”¼â€‹\[xË‡tâŠ¤â€‹Fâ€‹et\]\\displaystyle\\check{x}^{\\top}\_{t}\[F+K^{\\top}GK+(A-BK)^{\\top}\\Gamma(A-BK)\]\\check{x}\_{t}+\\mathbb{E}\[e\_{t}^{\\top}F\\check{x}\_{t}\]+\\mathbb{E}\[\\check{x}\_{t}^{\\top}Fe\_{t}\] |     |
|     |     | +Trâ€‹(Gâ€‹Bâ€ â€‹Î¦â€‹(Bâ€ )âŠ¤)+Trâ€‹(Fâ€‹Î£~c)+Trâ€‹(Î“â€‹Î¦)+Trâ€‹(Î“â€‹(Î£câˆ’Î£~c)).\\displaystyle+\\text{Tr}(GB^{\\dagger}\\Phi(B^{\\dagger})^{\\top})+\\text{Tr}(F\\tilde{\\Sigma}\_{c})+\\text{Tr}(\\Gamma\\Phi)+\\text{Tr}(\\Gamma(\\Sigma\_{c}-\\tilde{\\Sigma}\_{c})). |     | (78) |

It is well-known that, in Kalman filter, the estimation error ete\_{t} and the estimate of state xË‡t\\check{x}\_{t} are uncorrelated. We thus have ğ”¼â€‹\[etâŠ¤â€‹Fâ€‹xË‡t\]\=ğ”¼â€‹\[xË‡tâŠ¤â€‹Fâ€‹et\]\=0\\mathbb{E}\[e\_{t}^{\\top}F\\check{x}\_{t}\]=\\mathbb{E}\[\\check{x}\_{t}^{\\top}Fe\_{t}\]=0. Furthermore, as discussed in the proof of Lemma [2](https://arxiv.org/html/2509.16146v1#Thmlemma2 "Lemma 2 â€£ IV-A Capacity â€£ IV Noiseless Observations at the Controller and the Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems"), ([C.1 Proof of Lemma 4](https://arxiv.org/html/2509.16146v1#Sx3.Ex185 "C.1 Proof of Lemma 4 â€£ Appendix C â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) holds if Î“= F+K^âŠ¤GK + (A-BK)^âŠ¤Î“(A-BK), which is the same as that defined in ([8](https://arxiv.org/html/2509.16146v1#S3.E8 "In III-A Linear Quadratic-Gaussian (LQG) Control Systems â€£ III System Model and Preliminaries â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")). This verifies that fâ€‹(xË‡t)\=xË‡tâŠ¤â€‹Î“â€‹xË‡tf(\\check{x}\_{t})=\\check{x}\_{t}^{\\top}\\Gamma\\check{x}\_{t} is the differential value function. It follows immediately from the Bellman equation ([C.1 Proof of Lemma 4](https://arxiv.org/html/2509.16146v1#Sx3.Ex185 "C.1 Proof of Lemma 4 â€£ Appendix C â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) and Eq. ([37](https://arxiv.org/html/2509.16146v1#S6.E37 "In VI-A Optimal Control and Kalman Filtering â€£ VI Noisy Observations at Controller and Receiver â€£ Implicit Communication in Linear Quadratic Gaussian Control Systems")) that J = Tr(GB^â€ Î¦(B^â€ )^âŠ¤) + Tr(F~Î£\_c) + Tr(Î“Î¦) + Tr(Î“(Î£\_c - ~Î£\_c)) = J^\*\* + Tr((B^â€ )^âŠ¤GB^â€ Î¦) + Tr(Î“Î¦). This completes the proof. âˆ

Report issue for preceding element

## References

Report issue for preceding element

*   \[1\]â†‘ M.Â Ballerini, N.Â Cabibbo, R.Â Candelier, A.Â Cavagna, E.Â Cisbani, I.Â Giardina, V.Â Lecomte, A.Â Orlandi, G.Â Parisi, A.Â Procaccini _etÂ al._, â€œInteraction ruling animal collective behavior depends on topological rather than metric distance: Evidence from a field study,â€ _Proceedings of the national academy of sciences_, vol. 105, no.Â 4, pp. 1232â€“1237, 2008.
*   \[2\]â†‘ Y.Â Katz, K.Â TunstrÃ¸m, C.Â C. Ioannou, C.Â Huepe, and I.Â D. Couzin, â€œInferring the structure and dynamics of interactions in schooling fish,â€ _Proceedings of the National Academy of Sciences_, vol. 108, no.Â 46, pp. 18â€‰720â€“18â€‰725, 2011.
*   \[3\]â†‘ S.Â Trenholm, _Thinking Through Communication: An Introduction to the Study of Human Communication (9th ed.)_.â€ƒRoutledge, 2020.
*   \[4\]â†‘ G.Â Beattie, _Rethinking body language: How hand movements reveal hidden thoughts_.â€ƒRoutledge, 2016.
*   \[5\]â†‘ C.Â M. Waters and B.Â L. Bassler, â€œQuorum sensing: cell-to-cell communication in bacteria,â€ _Annual Review of Cell and Developmental Biology_, vol.Â 21, no.Â 1, pp. 319â€“346, 2005.
*   \[6\]â†‘ W.Â von Thienen, D.Â Metzler, D.-H. Choe, and V.Â Witte, â€œPheromone communication in ants: a detailed analysis of concentration-dependent decisions in three species,â€ _Behavioral ecology and sociobiology_, vol.Â 68, pp. 1611â€“1627, 2014.
*   \[7\]â†‘ S.Â Sayin, E.Â Couzin-Fuchs, I.Â Petelski, Y.Â GÃ¼nzel, M.Â Salahshour, C.-Y. Lee, J.Â M. Graving, L.Â Li, O.Â Deussen, G.Â A. Sword, and I.Â D. Couzin, â€œThe behavioral mechanisms governing collective motion in swarming locusts,â€ _Science_, vol. 387, no. 6737, pp. 995â€“1000, 2025. \[Online\]. Available: https://www.science.org/doi/abs/10.1126/science.adq7832
*   \[8\]â†‘ J.Â F. Fisac, E.Â Bronstein, E.Â Stefansson, D.Â Sadigh, S.Â S. Sastry, and A.Â D. Dragan, â€œHierarchical game-theoretic planning for autonomous vehicles,â€ in _2019 International conference on robotics and automation (ICRA)_.â€ƒIEEE, 2019, pp. 9590â€“9596.
*   \[9\]â†‘ W.Â Schwarting, A.Â Pierson, J.Â Alonso-Mora, S.Â Karaman, and D.Â Rus, â€œSocial behavior for autonomous vehicles,â€ _Proceedings of the National Academy of Sciences_, vol. 116, no.Â 50, pp. 24â€‰972â€“24â€‰978, 2019.
*   \[10\]â†‘ R.Â A. Knepper, C.Â I. Mavrogiannis, J.Â Proft, and C.Â Liang, â€œImplicit communication in a joint action,â€ in _Proceedings of the 2017 acm/ieee international conference on human-robot interaction_, 2017, pp. 283â€“292.
*   \[11\]â†‘ C.Â Breazeal, C.Â D. Kidd, A.Â L. Thomaz, G.Â Hoffman, and M.Â Berlin, â€œEffects of nonverbal communication on efficiency and robustness in human-robot teamwork,â€ in _2005 IEEE/RSJ international conference on intelligent robots and systems_.â€ƒIEEE, 2005, pp. 708â€“713.
*   \[12\]â†‘ A.Â D. Dragan, K.Â C. Lee, and S.Â S. Srinivasa, â€œLegibility and predictability of robot motion,â€ in _2013 8th ACM/IEEE International Conference on Human-Robot Interaction (HRI)_.â€ƒIEEE, 2013, pp. 301â€“308.
*   \[13\]â†‘ J.Â Connor, B.Â Champion, and M.Â A. Joordens, â€œCurrent algorithms, communication methods and designs for underwater swarm robotics: A review,â€ _IEEE Sensors Journal_, vol.Â 21, no.Â 1, pp. 153â€“169, 2020.
*   \[14\]â†‘ F.Â Berlinger, M.Â Gauci, and R.Â Nagpal, â€œImplicit coordination for 3D underwater collective behaviors in a fish-inspired robot swarm,â€ _Science Robotics_, vol.Â 6, no.Â 50, p. eabd8668, 2021. \[Online\]. Available: https://www.science.org/doi/abs/10.1126/scirobotics.abd8668
*   \[15\]â†‘ A.Â Dâ€™Angelo and E.Â Pagello, â€œMaking collective behaviours to work through implicit communication,â€ in _Proceedings of the 2005 IEEE International Conference on Robotics and Automation_.â€ƒIEEE, 2005, pp. 81â€“86.
*   \[16\]â†‘ C.Â Liang, J.Â Proft, E.Â Andersen, and R.Â A. Knepper, â€œImplicit communication of actionable information in human-AI teams,â€ in _Proceedings of the 2019 CHI conference on human factors in computing systems_, 2019, pp. 1â€“13.
*   \[17\]â†‘ Z.Â Tian, S.Â Zou, I.Â Davies, T.Â Warr, L.Â Wu, H.Â B. Ammar, and J.Â Wang, â€œLearning to communicate implicitly by actions,â€ in _Proceedings of the AAAI conference on artificial intelligence_, vol.Â 34, no.Â 05, 2020, pp. 7261â€“7268.
*   \[18\]â†‘ U.Â Stegmann, _Animal communication theory: Information and influence_.â€ƒCambridge University Press, 2013.
*   \[19\]â†‘ N.Â Albuquerque, D.Â S. Mills, K.Â Guo, A.Â Wilkinson, and B.Â Resende, â€œDogs can infer implicit information from human emotional expressions,â€ _Animal cognition_, vol.Â 25, no.Â 2, pp. 231â€“240, 2022.
*   \[20\]â†‘ M.Â L. Patterson, A.Â J. Fridlund, and C.Â Crivelli, â€œFour misconceptions about nonverbal communication,â€ _Perspectives on Psychological Science_, vol.Â 18, no.Â 6, pp. 1388â€“1411, 2023.
*   \[21\]â†‘ M.Â A. Denham and A.Â J. Onwuegbuzie, â€œBeyond words: Using nonverbal communication data in research to enhance thick description and interpretation,â€ _International Journal of Qualitative Methods_, vol.Â 12, no.Â 1, pp. 670â€“696, 2013.
*   \[22\]â†‘ S.Â Shaw, E.Â Wenzel, A.Â Walker, and G.Â Sartoretti, â€œForMIC: Foraging via multiagent RL with implicit communication,â€ _IEEE Robotics and Automation Letters_, vol.Â 7, no.Â 2, pp. 4877â€“4884, 2022.
*   \[23\]â†‘ H.Â Wang, B.Â Chen, T.Â Zhang, and B.Â Wang, â€œLearning to communicate through implicit communication channels,â€ in _The Thirteenth International Conference on Learning Representations_, 2025.
*   \[24\]â†‘ S.Â Sokota, C.Â A.Â S. DeÂ Witt, M.Â Igl, L.Â M. Zintgraf, P.Â Torr, M.Â Strohmeier, Z.Â Kolter, S.Â Whiteson, and J.Â Foerster, â€œCommunicating via Markov decision processes,â€ in _International Conference on Machine Learning_.â€ƒPMLR, 2022, pp. 20â€‰314â€“20â€‰328.
*   \[25\]â†‘ Y.Â Che, A.Â M. Okamura, and D.Â Sadigh, â€œEfficient and trustworthy social navigation via explicit and implicit robotâ€“human communication,â€ _IEEE Transactions on Robotics_, vol.Â 36, no.Â 3, pp. 692â€“707, 2020.
*   \[26\]â†‘ D.Â Dey and J.Â Terken, â€œPedestrian interaction with vehicles: roles of explicit and implicit communication,â€ in _Proceedings of the 9th international conference on automotive user interfaces and interactive vehicular applications_, 2017, pp. 109â€“113.
*   \[27\]â†‘ S.Â Li and X.Â Zhang, â€œImplicit intention communication in humanâ€“robot interaction through visual behavior studies,â€ _IEEE Transactions on Human-Machine Systems_, vol.Â 47, no.Â 4, pp. 437â€“448, 2017.
*   \[28\]â†‘ H.Â Wu, G.Â Chen, and D.Â Gunduz, â€œActions speak louder than words: Rate-reward trade-off in Markov decision processes,â€ in _The Thirteenth International Conference on Learning Representations_, 2025.
*   \[29\]â†‘ H.Â H. Permuter, H.Â Asnani, and T.Â Weissman, â€œCapacity of a POST channel with and without feedback,â€ _IEEE Transactions on Information Theory_, vol.Â 60, no.Â 10, pp. 6041â€“6057, 2014.
*   \[30\]â†‘ T.Â M. Cover and S.Â Pombra, â€œGaussian feedback capacity,â€ _IEEE Transactions on Information Theory_, vol.Â 35, no.Â 1, pp. 37â€“43, 2002.
*   \[31\]â†‘ S.Â VerdÃº _etÂ al._, â€œA general formula for channel capacity,â€ _IEEE Transactions on Information Theory_, vol.Â 40, no.Â 4, pp. 1147â€“1157, 1994.
*   \[32\]â†‘ Y.-H. Kim, â€œFeedback capacity of stationary Gaussian channels,â€ _IEEE Transactions on Information Theory_, vol.Â 56, no.Â 1, pp. 57â€“85, 2009.
*   \[33\]â†‘ L.Â Brandenburg and A.Â Wyner, â€œCapacity of the Gaussian channel with memory: The multivariate case,â€ _Bell System Technical Journal_, vol.Â 53, no.Â 5, pp. 745â€“778, 1974.
*   \[34\]â†‘ E.Â Telatar, â€œCapacity of multi-antenna Gaussian channels,â€ _European transactions on telecommunications_, vol.Â 10, no.Â 6, pp. 585â€“595, 1999.
*   \[35\]â†‘ O.Â Sabag, V.Â Kostina, and B.Â Hassibi, â€œFeedback capacity of MIMO Gaussian channels,â€ _IEEE Transactions on Information Theory_, vol.Â 69, no.Â 10, pp. 6121â€“6136, 2023.
*   \[36\]â†‘ D.-M. Arnold, H.-A. Loeliger, P.Â O. Vontobel, A.Â Kavcic, and W.Â Zeng, â€œSimulation-based computation of information rates for channels with memory,â€ _IEEE Transactions on information theory_, vol.Â 52, no.Â 8, pp. 3498â€“3508, 2006.
*   \[37\]â†‘ A.Â Feutrill and M.Â Roughan, â€œA review of Shannon and differential entropy rate estimation,â€ _Entropy_, vol.Â 23, no.Â 8, p. 1046, 2021.
*   \[38\]â†‘ W.Â Hirt and J.Â L. Massey, â€œCapacity of the discrete-time Gaussian channel with intersymbol interference,â€ _IEEE Transactions on Information Theory_, vol.Â 34, no.Â 3, pp. 38â€“38, 2002.
*   \[39\]â†‘ S.Â Loyka and C.Â D. Charalambous, â€œOn the capacity of Gaussian MIMO channels with memory,â€ _IEEE Communications Letters_, vol.Â 26, no.Â 8, pp. 1760â€“1763, 2022.
*   \[40\]â†‘ S.Â Shamai, L.Â Ozarow, and A.Â Wyner, â€œInformation rates for a discrete-time Gaussian channel with intersymbol interference and stationary inputs,â€ _IEEE Transactions on Information Theory_, vol.Â 37, no.Â 6, pp. 1527â€“1539, 1991.
*   \[41\]â†‘ S.Â Tatikonda and S.Â Mitter, â€œControl under communication constraints,â€ _IEEE Transactions on Automatic Control_, vol.Â 49, no.Â 7, pp. 1056â€“1068, 2004.
*   \[42\]â†‘ â€”â€”, â€œControl over noisy channels,â€ _IEEE Transactions on Automatic Control_, vol.Â 49, no.Â 7, pp. 1196â€“1201, 2004.
*   \[43\]â†‘ O.Â Sabag, P.Â Tian, V.Â Kostina, and B.Â Hassibi, â€œReducing the LQG cost with minimal communication,â€ _IEEE Transactions on Automatic Control_, vol.Â 68, no.Â 9, pp. 5258â€“5270, 2022.
*   \[44\]â†‘ R.Â A. Gupta and M.-Y. Chow, â€œNetworked control system: Overview and research trends,â€ _IEEE transactions on industrial electronics_, vol.Â 57, no.Â 7, pp. 2527â€“2535, 2009.
*   \[45\]â†‘ V.Â Kostina and B.Â Hassibi, â€œRate-cost tradeoffs in control,â€ _IEEE Transactions on Automatic Control_, vol.Â 64, no.Â 11, pp. 4525â€“4540, 2019.
*   \[46\]â†‘ M.Â Grant and S.Â Boyd, â€œCVX: Matlab software for disciplined convex programming, version 2.1,â€ https://cvxr.com/cvx, Mar. 2014.
*   \[47\]â†‘ â€”â€”, _Graph implementations for nonsmooth convex programs_, ser. Lecture Notes in Control and Information Sciences, V.Â Blondel, S.Â Boyd, and H.Â Kimura, Eds.â€ƒSpringer-Verlag Limited, 2008.
*   \[48\]â†‘ S.Â P. Boyd and L.Â Vandenberghe, _Convex optimization_.â€ƒCambridge university press, 2004.
*   \[49\]â†‘ R.Â Kalman, â€œA new approach to linear filtering and prediction problems,â€ _Trans. ASME, D_, vol.Â 82, pp. 35â€“44, 1960.
*   \[50\]â†‘ V.Â Krishnamurthy, _Partially observed Markov decision processes_.â€ƒCambridge university press, 2016.
*   \[51\]â†‘ H.Â E. Rauch, F.Â Tung, and C.Â T. Striebel, â€œMaximum likelihood estimates of linear dynamic systems,â€ _AIAA journal_, vol.Â 3, no.Â 8, pp. 1445â€“1450, 1965.
*   \[52\]â†‘ A.Â ElÂ Gamal and Y.-H. Kim, _Network information theory_.â€ƒCambridge university press, 2011.
*   \[53\]â†‘ B.-Z. Kurtaran and R.Â Sivan, â€œLinear-quadratic-Gaussian control with one-step-delay sharing pattern,â€ _IEEE Transactions on Automatic Control_, vol.Â 19, no.Â 5, pp. 571â€“574, 1974.